사용한 사이트
# 김준수
 # INTJ 자료
 - 'https://namu.wiki/w/INTJ' # 나무위키
 # INTP 자료
 - 'https://namu.wiki/w/INTP' # 나무위키
 - 'https://ddnews.co.kr/intp-%ED%8A%B9%EC%A7%95/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
    %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
    %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 # ENTJ 자료
 - 'https://namu.wiki/w/ENTJ' # 나무위키
 - 'https://ddnews.co.kr/entj-%ED%8A%B9%EC%A7%95/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
    %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C
    -%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹사이트
 # ENTP 자료
 - 'https://namu.wiki/w/ENTP' # 나무위키
 - 'https://gall.dcinside.com/mgallery/board/view/?id=entj&no=11&page=1' # 마이너 갤러리
 - 'https://ddnews.co.kr/entp-%ED%8A%B9%EC%A7%95-%EC%97%B0%EC%98%88-%EA%B6%81%ED%95%A9/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
      %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
      %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트

# 김동환
 # ISTJ
 - 'https://namu.wiki/w/ISTJ' # 나무위키
 - 'https://ddnews.co.kr/istj-%ED%8A%B9%EC%A7%95/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
      %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-
      %EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹사이트
 - 'https://loveohgu.tistory.com/16?category=843580' # 마니의 바람
 # ISFJ
 - 'https://namu.wiki/w/ISFJ' # 나무위키
 - 'https://ddnews.co.kr/isfj-%ed%8a%b9%ec%a7%95-%ec%97%b0%ec%95%a0-%ea%b6%81%ed%95%a9/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
      %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-
      %EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹사이트
 - 'https://loveohgu.tistory.com/17' # 마니의 바람
 # ESTJ
 - 'https://namu.wiki/w/ESTJ' # 나무위키
 - '''https://socialspeaker.tistory.com/entry/ESTJ-%EC%9C%A0%ED%98%95-
     %ED%8A%B9%EC%A7%95-%EC%B4%9D%EC%A0%95%EB%A6%AC%ED%8C%A9%ED%8F%AD-%EC%9E%A5%EB%8B%A8%EC%A0%90-
     %EC%97%B0%EC%95%A0-%EA%B6%81%ED%95%A9-%EC%A7%81%EC%97%85-%EC%97%B0%EC%98%88%EC%9D%B8-MBTI-
     %EC%84%B1%EA%B2%A9-%EC%9C%A0%ED%98%95-%ED%85%8C%EC%8A%A4%ED%8A%B8''' # 살구 꿀팁
 - 'https://ddnews.co.kr/estj-%ed%8a%b9%ec%a7%95-%ec%84%b1%ea%b2%a9-%ec%a7%81%ec%97%85-%ea%b6%81%ed%95%a9/' # 뚝딱 뉴스
 - 'https://www.cosmopolitan.co.kr/article/49638' # 웹 사이트
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
      %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-
      %EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹사이트
 - 'https://loveohgu.tistory.com/18?category=843580' # 마니의 바람
 # ESFJ
 - 'https://namu.wiki/w/ESFJ' # 나무위키
 - 'https://ddnews.co.kr/esfj-%ed%8a%b9%ec%a7%95-%ea%b6%81%ed%95%a9-%ec%97%b0%ec%95%a0/' # 뚝딱 뉴스
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
      %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-
      %EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹사이트
 - 'https://loveohgu.tistory.com/19?category=843580' # 마니의 바람
 
# 고승환
 # ISTP
 - 'https://namu.wiki/w/ISTP' # 나무위키
 - 'https://ddnews.co.kr/istp-%ED%8A%B9%EC%A7%95/' # 뚝딱 뉴스
 - 'https://blog.naver.com/PostView.naver?blogId=vbvb15&logNo=222577340086&redirect=Dlog&widgetTypeCall=true&directAccess=false' # 해커스
 - '''http://thelstream.com/mbti-%EA%B0%81-%EC%9C%A0%ED%98%95%EC%97%90%EA%B2%8C-%EC%A2%8B%EC%9D%80-
    %EC%B9%9C%EA%B5%AC%EA%B0%80-%EB%90%98%EC%96%B4-%EC%A3%BC%EB%8A%94-%EB%B2%95/''' # 엘스트림
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
     %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C
      -%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 # ISFP
 - 'https://namu.wiki/w/ISFP' # 나무위키
 - 'https://ddnews.co.kr/isfp-%ed%8a%b9%ec%a7%95-%ec%97%b0%ec%95%a0-%ea%b6%81%ed%95%a9/' # 뚝딱 뉴스
 - '''https://blog.naver.com/PostView.naver?blogId=vbvb15&logNo=
     222577340086&redirect=Dlog&widgetTypeCall=true&directAccess=false''' # 해커스
 - '''http://thelstream.com/mbti-%EA%B0%81-%EC%9C%A0%ED%98%95%EC%97%90%EA%B2%8C-
     %EC%A2%8B%EC%9D%80-%EC%B9%9C%EA%B5%AC%EA%B0%80-%EB%90%98%EC%96%B4-
     %EC%A3%BC%EB%8A%94-%EB%B2%95/''' # 엘스트림
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
     %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
     %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 # ESTP
 - 'https://namu.wiki/w/ESTP' # 나무위키
 - 'https://ddnews.co.kr/estp-%ED%8A%B9%EC%A7%95/' # 뚝딱 뉴스
 - '''https://blog.naver.com/PostView.naver?blogId=vbvb15&logNo
     =222577340086&redirect=Dlog&widgetTypeCall=true&directAccess=false''' # 해커스
 - '''http://thelstream.com/mbti-%EA%B0%81-%EC%9C%A0%ED%98%95%EC%97%90%EA%B2%8C-
     %EC%A2%8B%EC%9D%80-%EC%B9%9C%EA%B5%AC%EA%B0%80-%EB%90%98%EC%96%B4-
     %EC%A3%BC%EB%8A%94-%EB%B2%95/''' # 엘스트림
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-%EC%97%85%EB%AC%B4-
      %EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-%EC%83%9D%ED%99%9C-
      %EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/'''
 - 'https://www.cosmopolitan.co.kr/article/49638' # 웹 사이트
 # ESFP
 - 'https://namu.wiki/w/ESFP' # 나무위키
 - 'https://ddnews.co.kr/esfp-%ED%8A%B9%EC%A7%95-%EC%97%B0%EC%95%A0-%EA%B6%81%ED%95%A9/' # 뚝딱 뉴스
 - '''https://blog.naver.com/PostView.naver?blogId=vbvb15&logNo=222577340086&
     redirect=Dlog&widgetTypeCall=true&directAccess=false''' # 해커스
 - '''http://thelstream.com/mbti-%EA%B0%81-%EC%9C%A0%ED%98%95%EC%97%90%EA%B2%8C-
     %EC%A2%8B%EC%9D%80-%EC%B9%9C%EA%B5%AC%EA%B0%80-%EB%90%98%EC%96%B4-
     %EC%A3%BC%EB%8A%94-%EB%B2%95/''' # 엘스트림
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
     %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
     %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트

# 양민승
 # INTJ 자료
 - 'https://namu.wiki/w/INFJ' # 나무 위키
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
      %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
      %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 - '''https://onegreen.tistory.com/entry/mbti-%EC%97%B0%EC%95%A0-%EC%
      9D%B4%EC%83%81%ED%98%95-%EC%8D%B8-%EA%B3%A0%EB%B0%B1''' # 일상을그리는그린이
 # INFP
 - 'https://namu.wiki/w/INFP' # 나무 위키
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
      %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
      %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 - '''https://onegreen.tistory.com/entry/mbti-%EC%97%B0%EC%95%A0-%EC%
      9D%B4%EC%83%81%ED%98%95-%EC%8D%B8-%EA%B3%A0%EB%B0%B1''' # 일상을그리는그린이
 # ENFP
 - 'https://namu.wiki/w/ENFP' # 나무 위키
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
      %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
      %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 - '''https://onegreen.tistory.com/entry/mbti-%EC%97%B0%EC%95%A0-%EC%
      9D%B4%EC%83%81%ED%98%95-%EC%8D%B8-%EA%B3%A0%EB%B0%B1''' # 일상을그리는그린이
 #ENFJ
 - 'https://namu.wiki/w/ENFJ' # 나무 위키
 - '''https://www.tutormong.com/mbti-%EC%9C%A0%ED%98%95%EB%B3%84-
      %EC%97%85%EB%AC%B4-%EC%8A%A4%ED%83%80%EC%9D%BC-%EC%A7%81%EC%9E%A5-
      %EC%83%9D%ED%99%9C-%EC%B6%94%EC%B2%9C-%EC%A7%81%EC%97%85%EC%9D%80/''' # 웹 사이트
 - '''https://onegreen.tistory.com/entry/mbti-%EC%97%B0%EC%95%A0-%EC%
      9D%B4%EC%83%81%ED%98%95-%EC%8D%B8-%EA%B3%A0%EB%B0%B1''' # 일상을그리는그린이
 
------------------------------MBTI 웹크롤링------------------------------------

## 웹 크롤링 코드
 # 김동환/고승한/김준수/양민승 작업
from selenium import webdriver
from bs4 import BeautifulSoup as bs
import pandas as pd
from pandas import Series, DataFrame
import pickle

url = '사용한 URL 입력' # 사용할 웹주소 입력
driver =  webdriver.Chrome('c:/data/chromedriver.exe') # 크롬 드라이버
driver.get(url) # URL 불러오기
driver.implicitly_wait(2) # 대기 2초
html = driver.page_source # 현제 화면 스크린 샷
driver.quit()
soup = bs(html,'html.parser') # 정제 작업
 
# 웹 페이지에서 자바스크립트를 사용하여 자동으로 코드가 변경됨
# 당일 페이지에서 코드 재확인 필요 함

a = [] # 일반적인 특징
for i in soup.select('div.Cu17X2-n > ul._9L63zbN1')[0] : # 웹페이 소스 입력
    a.append(i.text.strip())

b = [] # 부모
for i in soup.select('div.Cu17X2-n > ul._9L63zbN1')[1] : # 웹페이 소스 입력
    b.append(i.text.strip())

c = [] # 아이
for i in soup.select('div.Cu17X2-n > ul._9L63zbN1')[2] : # 웹페이 소스 입력
    c.append(i.text.strip())

d = [] # 장단점
for i in soup.select('table._a5b5640faca9f1712f81cb0b01f8ea51')[4].select('div.g8DLeknN'): # 웹페이 소스 입력
    d.append(i.text.strip())
 
# pickle을 사용하여 데이터 저장 작업 진행 코드
with open("c:/data/ESFP.pikl","wb") as file:
    pickle.dump(ESFP_dict,file)
# 저장한 데이터 확인 작업 코드
with open("c:/data/ESFP.pikl","rb") as file:
    ESFP_dict = pickle.load(file)

--------------------------데이터 취합 작업--------------------------------------

## 데이터 수집 자료 불러오기 작업(220423)
 # 고승한/김준수/양민승 작업
import pickle

with open('C:/data/final_project/dong/esfj_a.pkl',"rb") as file:
    esfj = pickle.load(file)
with open('C:/data/final_project/dong/estj_a.pkl',"rb") as file:
    estj = pickle.load(file)
with open('C:/data/final_project/dong/isfj_a.pkl',"rb") as file:
    isfj = pickle.load(file)
with open('C:/data/final_project/dong/istj_a.pkl',"rb") as file:
    istj = pickle.load(file)
with open('C:/data/final_project/jun/ENTJ/a_ENTJ.txt',"rb") as file:
    entj = pickle.load(file)    
with open('C:/data/final_project/jun/ENTP/a_ENTP .txt',"rb") as file:
    entp = pickle.load(file)
with open('C:/data/final_project/jun/INTJ/c_INTJ.txt',"rb") as file:
    intj = pickle.load(file)  
with open('C:/data/final_project/jun/INTP/name_INTP.txt',"rb") as file:
    intp = pickle.load(file)
with open('C:/data/final_project/ko/ESFP.pikl',"rb") as file:
    esfp = pickle.load(file)
    esfp = esfp['a']
with open('C:/data/final_project/ko/ESTP.pikl',"rb") as file:
    estp = pickle.load(file)
    estp = estp['a']
with open('C:/data/final_project/ko/ISFP.pikl',"rb") as file:
    isfp = pickle.load(file)
    isfp = isfp['a']
with open('C:/data/final_project/ko/ISTP.pikl',"rb") as file:
    istp = pickle.load(file)
    istp = istp['a']
with open('C:/data/final_project/yang/ENFJ_1.pkl',"rb") as file:
    enfj = pickle.load(file)
    enfj = enfj['ENFJ특성'][0][0]
with open('C:/data/final_project/yang/ENFP_1.pkl',"rb") as file:
    enfp = pickle.load(file)
    enfp = enfp['ENFP특성'][0]
with open('C:/data/final_project/yang/INFJ_1.pkl',"rb") as file:
    infj = pickle.load(file)
    infj = infj['INFJ특성'][0][0]
with open('C:/data/final_project/yang/INFP_1.pkl',"rb") as file:
    infp = pickle.load(file)
    infp = infp['INFP특성'][0]
    
-------------------------------------------------------------------------------

## 불러온 데이터 DataFrame 작업
from pandas import Series, DataFrame
import pandas as pd
import csv

mbti_df = DataFrame()
mbti_df['ESFP'] = [' '.join(esfp)]
mbti_df['ESTP'] = [' '.join(estp)]
mbti_df['ISFP'] = [' '.join(isfp)]
mbti_df['ISTP'] = [' '.join(istp)]
mbti_df['ENTJ'] = [' '.join(entj)]
mbti_df['ENTP'] = [' '.join(entp)]
mbti_df['INTJ'] = [' '.join(intj)]
mbti_df['INTP'] = [' '.join(intp)]
mbti_df['ESFJ'] = [' '.join(esfj)]
mbti_df['ESTJ'] = [' '.join(estj)]
mbti_df['ISFJ'] = [' '.join(isfj)]
mbti_df['ISTJ'] = [' '.join(istj)]
mbti_df['ENFJ'] = [' '.join(enfj)]
mbti_df['ENFP'] = [' '.join(enfp)]
mbti_df['INFJ'] = [' '.join(infj)]
mbti_df['INFP'] = [' '.join(infp)]

new_mbti_df = mbti_df.T
new_mbti_df.reset_index(inplace=True)
new_mbti_df.columns = ['mbti','test']

# 1차 파일 저장
mbti_df.to_csv('c:/data/MBTI_a.csv')
# 데이터 확인
pd.read_csv('c:/data/MBTI_a.csv')

---------------------------MBTI 1차 정제 작업-----------------------------------

## MBTI.CSV_a파일 정제작업(220425)
 # 양민승/고승한 작업 진행
from pandas import Series, DataFrame
import pandas as pd
import re
import csv

mbti = pd.read_csv("c:/data/MBTI_a.csv")

# 특수문제 제거 및 공백 제거
mbti.test = mbti.test.replace(r'[一-龥]|[A-Za-z0-9]|\[.+?\]|[\(\)]|[^\w]',r' ', regex=True)
mbti.test = mbti.test.replace(r'\s{2,}',r' ', regex=True).str.strip()
mbti.test

# 2차 데이터 저장
mbti.to_csv("c:/data/MBTI_a_1.csv")
# 2차 데이터 확인
pd.read_csv('c:/data/MBTI_a_1.csv')

-----------------------------MBTI 2차 정제 작업-------------------------------

## MBTI_a_1파일 정제작업(220426~27)
# 담당 : 고승한/양민승/김준수
from pandas import Series, DataFrame
import pandas as pd
import re

mbti = pd.read_csv('c:/data/MBTI_a_1.csv')

# 인덱스 0번(ESFP) ~ 7번(INTP)까지 전처리한 내용이다.
# 양민승
mbti['test'][0].split(' ')
mbti['mbti'][0]

ESFP = [['신나고 재미있는 성격이다.'],
        ['오감과 인지능력이 발달되어 있다.'],
        ['사교적인 성격으로 사람들과 쉽게 친해진다.'],
        ['외향적인 성격이 가장 강한 편이다.'],
        ['인생을 즐겁게 살려고 한다.'],
        ['지나간 일은 잘 잊어버리는 편이다.'],
        ['뒤끝이 긴 사람들을 불편해하는 편이다.'],
        ['타인을 즐겁게 해주는 일을 잘한다.'],
        ['자신의 이야기를 잘 털어놓는다.'],
        ['책임감이 높은 편은 아니지만 중요한 일은 잘 처리한다.'],
        ['호불호가 분명하며, 표정이 얼굴에 잘 드러난다.'],
        ['정이 많고 건망증이 심하다.'],
        ['생각이 단순한 편이다.'],
        ['사람들이랑 같이 있는것을 좋아한다.'],
        ['조직생활보다는 자유로운 일에서 능력을 발휘한다.'],
        ['말을 많이 하지만 하고 싶은 말은 하지 못한다.'],
        ['내성적인 사람들과도 잘 어울린다.'],
        ['개성적인 매력이 있다.'],
        ['현재를 즐기며 산다.'],
        ['계획적이지 않고 충동적인 면이 있다.'],
        ['행복도가 가장 높은 편이다.'],
        ['문과계열로 지원하는것이 유리하다.']]

mbti['test'][1].split(' ')
mbti['mbti'][1]

ESTP = [['내기를 좋아한다.'],
        ['삶을 즐기며 스릴을 좋아한다.'],
        ['생각과 행동을 빠르게 하는 편이다.'],
        ['현실적이기 때문에 감정적이거나 우유부단하지 않다.'],
        ['모든 유형중 가장 감각적이다.'],
        ['창작물에서 가장 자주 나오는 유형이다.'],
        ['무대의 중심에 서는 것을 즐긴다.'],
        ['문제 해결능력이 매우 좋은 편이다.'],
        ['문제를 유발하는 능력도 매우 좋은 편이다.'],
        ['오감이 잘 발달되어 있다.'],
        ['촉이 매우 좋은 편이다.'],
        ['시각적 정보를 예민하게 받아들인다.'],
        ['관찰력이 뛰어나다.'],
        ['선입견이 없는 편이고 있는 그대로를 바라보며 분석한다.'],
        ['성향이 겉으로 잘 드러나지 않는다.'],
        ['현재시기를 가장 중요하게 여긴다.'],
        ['이론보다는 체험을 통해 경험하는 것을 좋아한다.'],
        ['문과계열로 지원하는 것이 유리하다.'],
        ['대학교 평균 학점이 가장 낮다.'],
        ['직업을 선생님으로 선택하면 매우 유리하다.']]

mbti['test'][2].split(' ')
mbti['mbti'][2]

ISFP = [['다른 사람들 부탁을 잘 들어준다.'],
        ['사람을 잘 믿고 의심하지 않는다.'],
        ['타인과의 갈등을 싫어하고 조화롭게 지내려고 한다.'],
        ['통화보다 메시지를 선호한다.'],
        ['혼자만의 시간을 즐긴다.'],
        ['인내심이 좋다.'],
        ['강요와 압박을 싫어한다.'],
        ['생각은 많은데 행동이 부족하다.'],
        ['편견이 없고 다양한 시각을 가진다.'],
        ['자신의 의견을 말하기 어려워 한다.'],
        ['본인이 하고자 하는 일에 열정적으로 몰두한다.'],
        ['본인의 입장이 확고한 편이다.'],
        ['겉으로는 부드러워 보이지만 속으로는 완고한 편이다.'],
        ['음악이나 영화, 패션에 관심을 많이 가진다.'],
        ['평소에 성실하다는 평가를 많이 받는다.'],
        ['편안한 분위기에서 능력을 발휘한다.'],
        ['배려형 개인주의 성격으로 조용히 사는 편이다.'],
        ['싫은 티를 크게 내지 않은 편이다.'],
        ['프라이버시를 존중하는 편이다.'],
        ['자신의 감정을 소중하게 여긴다.'],
        ['자연적, 목가적, 전원적인 것을 추구한다.'],
        ['리드하는것을 좋아하지 않는다.'],
        ['감정이입 능력이 뛰어나다.'],
        ['예술적 감각이 뛰어나며 호기심이 많다.'],
        ['겸손하며 자기 성찰이 뛰어나다.'],
        ['적응력이 좋다.']]

mbti['test'][3].split(' ')
mbti['mbti'][3]

ISTP = [['상대방 기분에 맞춰주려고 마음에 없는 얘기를 하지 않는 편이다.'],
        ['일반적으로는 조용한 편이다.'],
        ['겉으로는 완만해보이지만 속은 완고한 편이다.'],
        ['틀에 박히고 통념적인 생활을 싫어한다.'],
        ['타인의 일에 무관심한 편이다.'],
        ['고집이 세고 주관이 뚜렷하다.'],
        ['말이 없고 내색을 하지 않는다.'],
        ['객관적인 원리에 관심이 많다.'],
        ['맹목적이고 감정적인 것을 싫어한다.'],
        ['타인에 대한 마음을 표현하기 어려워 한다.'],
        ['능력과 배려, 논리적인 사고를 지녔다.'],
        ['어느 성격하고도 문제를 잘 잃으키지 않는다.'],
        ['시사적인 분석이나 문제에 열중한다.'],
        ['자신이 관심없는 분야 외에는 신경쓰지 않는다.'],
        ['생각은 적극적이나 행동은 소극적이다.'],
        ['무작정 노력하는 것보다는 효율적으로 능률을 높인다.']]

mbti['test'][4].split(' ')
mbti['mbti'][4]        

ENTJ = [['타고난 지도자이다.'],
        ['체계적,조직적,계획적이다.'],
        ['일은 일대로 하고 욕은 욕대로 먹을 수 있다.'],
        ['완벽주의를 추구하는 성향이다.'],
        ['상상력과 호기심이 풍부하다.'],
        ['논리적 비판에 대한 수용이 빠르다.'],
        ['지적능력 향상의 욕구가 강하다.'],
        ['감정표현을 솔직하게 한다.'],
        ['일을 진행할 때 같이 하는 사람보다 일 자체에 집중한다.'],
        ['인기있는 사람 보다는 능력 있는 사람이 되고 싶어한다.'],
        ['계획을 하면 항상 실행한다.'],
        ['반복되는 일상을 싫어한다.'],
        ['변화있는 생활을 즐긴다.'],
        ['도전적이고 미래 지향적이다.'],
        ['어려운 일을 비교적 쉽게 처리하는 편이다.'],
        ['권위적이지 않다.'],
        ['미래에 대한 꿈이 크다.'],
        ['결단력, 통솔력, 책임감이 크다.'],
        ['일을 추진할 때 거시적인 안목으로 처리한다.'],
        ['가까운 사람에게 헌신적으로 대한다.']]

mbti['test'][5].split(' ')
mbti['mbti'][5]

ENTP = [['외향적이지만 혼자만의 시간이 많이 필요하다.'],
        ['친한 사람과 안 친한 사람의 선을 확실하게 긋는다.'],
        ['두뇌회전이 빠르며, 직관적으로 보는 성향이라 이해력이 뛰어나다.'],
        ['말하기와 글쓰기에 재능이 있는 경우가 많다.'],
        ['복잡한 문제를 지름길을 이용해 쉽게 해결한다.'],
        ['상상력,창의력,호기심이 뛰어나다.'],
        ['상대방의 의견이 궁금해서 자주 물어보는 편이다.'],
        ['즉흥적이고 유연하며 순발력이 뛰어나다.'],
        ['개방적이고 자유를 추구한다.'],
        ['억압당하는 것을 좋아하지 않는다.'],
        ['모험심이 강하며 새로운 시도를 할 때 위험을 감수하는 것을 꺼리지 않는다.'],
        ['여행을 좋아한다.'],
        ['비합리적인 것들을 싫어한다.'],
        ['상대방과의 분쟁에 적극적인 편이다.'],
        ['말이 안 통하거나 귀찮으면 상대방과의 분쟁을 하지 않는다.'],
        ['언변(말주변)이 뛰어나 협상능력이 좋다.'],
        ['재치가 있어서 기발한 방법을 자주 찾아낸다.'],
        ['기본적으로 논증과 분석을 선호하며 대상에 대해 집요하고 꾸준하게 파악한다.'],
        ['다양한 관점에서 분석하는 것을 잘한다.'],
        ['시스템의 논리적인 모순이나 결함을 잘 발견한다.'],
        ['벼락치기식 공부를 선호하는 편이다.'],
        ['논리력이 뛰어나서 발표나 토론 등을 잘 한다.'],
        ['단기적인 성과는 뛰어나지만 장기적인 노력이 필요한 부분에서는 부족하다.'],
        ['한 주제의 반복되는 이야기를 싫어한다.'],
        ['상대방의 생각을 읽고 이해하는 능력이 뛰어나다.'],
        ['매력적인 대화를 구사한다.'],
        ['독특한 발상과 아이디어를 추구한다.'],
        ['가치관이 뚜렷하며 직설적인 화법을 구사한다.'],
        ['상대방의 눈치를 보지 않는 편이다.'],
        ['관심분야와 취미가 넓다.'],
        ['타인을 고정관념과 편견 없이 바라본다.'],
        ['이상형과 연애하길 원하는 경향이 강하다.'],
        ['경쟁심이 강한 편이다.'],
        ['쾌락주의적이다.']]

mbti['test'][6].split(' ')
mbti['mbti'][6]

INTJ = [['이성과 논리를 바탕으로 대상을 개념화 하는것을 선호한다.'],
        ['어떤 일이든 체계와 진행 방식부터 이해하려고 한다.'],
        ['어려운 학문을 공부하는 것을 즐긴다.'],
        ['논리 체계를 이해하려고 한다.'],
        ['문제 해결 욕구가 강하며 적극적으로 해결한다.'],
        ['부족한 개념이나 체계를 받아들이기 어려워 한다.'],
        ['창의적 사고와 참신한 발상을 탐구하는 것을 좋아한다.'],
        ['예측할 수 없는 상황이나 일이 발생하는 것을 싫어한다.'],
        ['문제해결 과정에서 자신만의 기술을 만들어 낸다.'],
        ['일을 처리하는데 효율성을 많이 추구한다.'],
        ['개인감정보다 이성을 바탕으로 한 합리성으로 해결책을 제시한다.'],
        ['복잡한 일에 대한 해결책을 상대방한테 간단하게 전달한다.'],
        ['기존 의견보다는 색다른 관점이나 반대 의견에 더 주목한다.'],
        ['감정보다는 이성을 추구한다.'],
        ['확실한 증거를 선호한다.'],
        ['사소한 실수나 불일치성을 찾아내는 데 탁월하다.'],
        ['자기 분야에서는 완벽주의를 추구하는 편이다.'],
        ['통찰력, 논리력, 의지력을 중요시하게 여긴다.'],
        ['자기 통제력과 일에 대한 몰입력이 강하다.'],
        ['깊이 있는 프로젝트와 아이디어를 계획해 성공시키는 것을 좋아한다.'],
        ['지식이나 기교같은 자기개발을 하는것을 좋아한다.'],
        ['지식 축적 활동이나 상대방과의 논증을 통해 자존감을 얻는다.'],
        ['과정보다 결과를 중시한다.'],
        ['추상적인 이론을 실현하는 것을 좋아한다.'],
        ['사회화보다는 개인적인 성공을 중시한다.'],
        ['자신의 능력에 대한 믿음이 강하며, 미래지향적이고 낙관적이다.'],
        ['관심있는 분야에는 깊게 통달하려고 한다.'],
        ['어떤 어려운 문제도 해결할 수 있다는 자신감이 있다.'],
        ['문제 해결에 있어서 각각의 방법들에 대해 장단점을 고려한다.'],
        ['체계적이고 조직적인 분위기에 알맞다.']]

mbti['test'][7].split(' ')
mbti['mbti'][7]

INTP = [['조용하고 과묵한 편이다.'],
        ['논리와 분석으로 문제를 해결하는것을 좋아한다.'],
        ['먼저 말을 많이 하지는 않지만 관심 있는 분야에 대해서는 말이 많아진다.'],
        ['이해가 빠르고 직관적으로 통찰하는 능력이 있다.'],
        ['지적 호기심이 많고 논리적으로 분석하는 것을 좋아한다.'],
        ['창의적 지능과 논리면에서 모든 유형 중 가장 뛰어난 모습을 보인다.'],
        ['비과학적이거나 비논리적인 일들에 대해 거부반응을 보인다.'],
        ['아이디어와 원리, 인과관계에 관심이 많다.'],
        ['실체보다는 그 가능성에 대헤 관심이 많다.'],
        ['가끔씩 매우 추상적이고 비현실적으로 생각하는 경향이 있다.'],
        ['복잡한 문제를 해결하는 데 관심이 많지만 실제 적용하는데는 관심이 없다.'],
        ['주어진 일에 대해 즉흥적으로 처리하는 편이다.'],
        ['어느정도 틀만 있으면 그 안에서 자유롭게 행동하는 편이다.'],
        ['호불호가 뚜렷한 편이다.'],
        ['지적 호기심을 활용할 수 있는 학문에서 강세를 보인다.'],
        ['주변 사람들을 잘 따르는 편이다.'],
        ['사랑에 빠지면 헌신하는 모습을 보여준다.'],
        ['혼자서 행동하고 노는 것을 좋아한다.'],
        ['사회적 만남이나 활동을 즐기는 경우가 드물다.'],
        ['관심사가 다양하고 이해가 빨라서 다방면으로 도전을 즐긴다.'],
        ['문제해결을 위해서 논리적인 해결책을 선호한다.']]

# 고승한/김준수
mbti2 = mbti2.iloc[:,2:]
mbti2.mbti[8:]

ESFJ = [['스트레스를 받으면 누군가를 만나야 한다.'],
        ['강의 시 내용을 이해했는지와 무관하게 고개를 많이 끄덕인다.'],
        ['모든 유형 중에서 외향성이 가장 강하다.'],
        ['즐거움을 추구하지 않는 편이다.'],
        ['사교성은 매우 뛰어나지만 노는 것은 별로 좋아하지 않는다.'],
        ['참을성이 많고 타인을 잘 돕는다.'],
        ['남에게 동조하는 경향이 뛰어나며 사람들과의 상호 활동에서 기력이 생긴다.'],
        ['타인의 인정을 받는 것에 아주 민감하다.'],
        ['변화를 싫어하는 편이며 좋은 음식 을 좋아하고 재물을 모으는 것을 즐긴다.'],
        ['조화와 균형을 중요시한다.'],
        ['집단의 일이나 목적을 개인의 이익보다 앞세운다.'],
        ['관계에서 중재자 역할을 자처한다.'],
        ['명확하고 활발한 칭찬표현이 없을시 실망하는 경향이 있다.'],
        ['다수 속에 있는 것을 좋아한다.'],
        ['치어리더나 풋볼의 쿼터백 같은 팀의 사기를 불어넣는 역할을 하기도 한다.'],
        ['여러 사람들의 스포트라이트를 받는 것을 즐긴다.'],
        ['국제 정치나 과학 이론과 같은 주제에는 관심이 없다.'],
        ['남들 챙기는 것을 좋아한다.'],
        ['좋아하는 편에 속하지만 챙겨야 하는 책임감 때문에 어쩔 수 없이 챙길 때도 많다.'],
        ['단순한 성격으로 복잡한 세상을 편하게 살아간다.'],
        ['자기 주장이 강하지는 않다.'],
        ['공감 능력이 좋다.'],
        ['하지만 진심으로 공감되지 않더라도 적당히 상대방의 기분에 맞춰주는 가식적인 공감도 잘 해준다.'],
        ['윗 글처럼 처음에는 공감되지 않던 타인의 주장을 들으며 가식적인 공감을 하다가도 이 말도 일리가 있는데 하며 설득 당하는 경우도 잦다.'],
        ['가시적으로 증명되지 않은 개념을 잘 받아들이지 못한다.'],
        ['행동보다 말이 앞선다거나 뜬구름 잡는 소리를 하는 것을 한심하게 생각하지만 겉으로는 잘 받아준다.'],
        ['역지사지를 잘한다.'],
        ['타인을 진심으로 이해하기 힘들 경우 그럴 수 있지라는 마음으로 넘어갈 가능성이 크다.'],
        ['스몰톡을 선호한다.'],
        ['천성적으로 사교적인 성향이며 가까운 친구나 지인들의 일거수일투족을 모두 알기를 원한다.'],
        ['계급과 위계질서를 잘 따르며 타인도 그러길 원한다.'],
        ['옳고 그름을 날카롭게 구분한다.'],
        ['하지만 주위 분위기를 살피며 그에 따라 행동한다.'],
        ['자신이 옳다고 생각하는 일에 감정적으로 외골수의 모습을 보인다.'],
        ['굉장히 활발하고 사교적인 타입이지만 외향성과 내향성의 비율 차이가 적은 경우에는 조용하다고 평가받을 수도 있다.'],
        ['윗사람에 싹싹하며 즉각적인 요구를 잘 파악해서 이행하기 때문에 주로 직장에서 빠르게 적응하는 편이다.'],
        ['자연스럽게 분위기를 주도하거나 리더 역할을 맡는 경우가 많다.'],
        ['완벽주의 기질이 약간 있다.'],
        ['자신이 존경하는 사람이나 물건을 이상화하는 경향이 있다.'],
        ['의사결정을 할 때 성급하게 결정하여 간과하는 점들이 있다.'],
        ['시간관념이 엄격하여 약속된 시간은 절대 지켜야한다는 경향이 있는데 시간이 여유롭게 남았음에도 불구하고 조급한 경향이 있다.'],
        ['이성을 볼 때도 첫눈에 반해서 좋다기 보다는 옆에서 지켜보다 괜찮은 사람이라고 생각되면 미친 듯이 좋아한다.'],
        ['한번 좋아하면 헌신을 다한다.'],
        ['이해를 바탕으로한 암기보다 무작정 암기를 잘한다.'],
        ['생각보다 굉장히 철저하고 현실주의적이다.'],
        ['하지만 남들에게 싫은 소리를 잘 안 하고 대부분 맞춰주기 때문에 겉으로는 티가 나지 않을 수 있다.'],
        ['화가 나도 웬만하면 묵묵히 참아주는 편이다.'],
        ['정이 굉장히 많다.'],
        ['좋아하는 사람들에게 애정을 쏟으며 선물하는 것을 좋아한다.'],
        ['눈치가 굉장히 빠른 편이다.'],
        ['타인에 관련된 것엔 눈치가 빠르나 자기 자신과 관련된 것에는 둔한 경우도 많다.'],
        ['동정심이 강하고 다 같이 사이좋게 지내는 것을 추구하기 때문에 약자를 잘 도와준다.'],
        ['기본적으로 친절하다.'],
        ['돈보다는 사회적 지위 권위 명예를 추구하는 편이다.'],
        ['자존감이 높은 편이다.'],
        ['그러나 딱히 티를 내지는 않는다.'],
        ['한번 깊은 관계를 맺은 사람들은 절대 배신하지 않는다.'],
        ['사람들 이름과 얼굴을 잘 기억하고 잘 구분한다.'],
        ['학교나 직장에서 다른 사람들은 몰라도 본인은 구성원들을 거의 다 기억하고 있다.'],
        ['자기 이야기를 많이 하고 칭찬이나 인정을 받고 싶은 일이 생기면 동네방네 떠들고 다니지만 분위기를 띄우고 재밌게 만들고 싶어서 말하는 편이고 진짜 크거나 중요한 일은 그 누구에게도 절대 말하지 않는다.'],
        ['긍정적이고 낙천적인 편이다.'],
        ['자신과 주변을 발전시키기 보다는 현재 위치와 생활을 유지하면서 살아간다.'],
        ['이들이 누구의 이런 면이 별로야 이렇게 행동했으면 좋겠어 식의 어투가 아닌 나 얘 진짜 싫어 라고 확실하게 부정적으로 말했다면 그 사람은 정말 싫은 것이다.'],
        ['남들을 잘 챙기고 부탁에 거절을 잘 안 하는 것도 맞지만 이렇게 하면서 자신의 이득도 잘 챙긴다.'],
        ['즉흥적으로 한 행동은 후회하는 경우가 많다.'],
        ['예를 들어 새해라고 금주를 다짐하면 실패한다.'],
        ['철저히 계획 후에 행동하는 것이 더 동기부여 되는 유형.'],
        ['과도한 친절이 타인을 피곤하게 만든다.'],
        ['지적인 역량을 쌓는 것보다는 사람들과 친밀한 관계를 맺는 것을 선호하는 편이다.'],
        ['그래서 공부에 관심이 덜한 편이지만 성실한 성격이므로 공부하겠다는 마음을 먹으면 열심히 한다.'],
        ['감정적으로 상대가 부정을 드러내면 하루종일 그 생각 뿐이다.'],
        ['잘못된 부분에 자책하고 자기검열을 통해 개선하려고 노력한다.'],
        ['귀가 얇다.'],
        ['오해받는 것을 극도로 싫어한다.'],
        ['일을 할 때 의무감에 최우선 가치를 둔다.'],
        ['한번 시작했으면 끝을 봐야한다.'],
        ['건강한 유형과 불건강한 유형의 모습이 정말 천지 차이로 다르다.'],
        ['건강한 유형은 다정하고 책임감 있으며 누구의 말이든 잘 들어주고 남을 진심으로 돕고자 하는 마음을 가지고 있다.'],
        ['그러나 불건강한 유형은 정말 끔찍할 정도로 가식적이거나 별다른 이유도 없이 자기 마음에 안 든다는 이유만으로 계속해서 괴롭힌다.'],
        ['게다가 이런 불건강 유형의 경우 어떻게든 모두가 그 사람을 싫어하게 만들기 위해 뒤에서 나쁜 소문을 퍼뜨리고 정치질 중일 확률이 매우 높다.'],
        ['기본적으로 말이 많고 시끄러운 성격이지만 상황에 따라 엄청 조용해질 수도 있는 성격이다.'],
        ['부기능인 내향 감각으로 과거 회상을 좋아하고 남들이 기억하기 힘든 세세한 추억들까지 간직하고 있는 경우가 많다.'],
        ['반대로 나쁜 기억을 쉽게 잊지 못한다.'],
        ['부기능과 차기능이 각각 내향 감각 외향 직관 으로 이를 통해 썰을 풀면서 자신만의 토크쇼를 여는데 굉장히 재주가 있다.'],
        ['끝 없는 대잔치 구조와 조직을 즐기는 경향이 있다.'],
        ['이런 것들이 세상과 사람들을 이해하는데에 넓은 관점을 만들어주기 때문이다.'],
        ['다른 사람을 돕는 것을 즐기며 타인과 함께 지내는 것을 행복으로 여긴다.'],
        ['친절하고 베풀어 주는 방법을 다른 사람들이 알아주고 고마워할 수 있기를 기대하는 편이다.'],
        ['다른 사람의 필요와 감정에 민감하게 반응하며 충족하고자 노력한다.'],
        ['다른 사람에게 호감을 사고 싶어하며 관심을 받지 않으면 시무룩해진다.'],
        ['불친절이나 무관심에 쉽게 상처받으며 주눅든다.'],
        ['자신에게 잘 다가오지 않고 머뭇거리는 상대방도 불편해한다.'],
        ['따뜻한 마음을 가졌으며 타인의 호감을 사기 쉽다.'],
        ['배려하고 존중하며 사회적으로 포용적인 마음을 가졌다.'],
        ['타인의 감정에 민감하기 때문에 자신과 관련이 없는 일에도 간섭할 수도 있다.'],
        ['사람들이 함께 일하도록 장려하며 재치 있고 건설적인 태도를 보여주며 신뢰를 산다.'],
        ['다른 사람으로부터 선의와 헌신을 이끌어내는 데 뛰어난 사교계의 귀족.'],
        ['생활력은 강하지만 급변하는 환경에 적응하기 어려워하며 현상에 미래에는 어떻게 변화할 것인가를 생각하는 능력이 부족하다.'],
        ['차기능이 내향 사고 로 지적인 역량을 쌓는 것에 그닥 관심이 없으며 내면의 논리적인 지식을 분석하는 것에 어려움을 느끼며 내면의 논리를 분석하려는 사람들을 이해하지 못한다.'],
        ['사회적 조화를 중시하고 분위기를 망치는 부정적인 비판을 싫어한다.'],
        ['그래도 불합리하다고 판단되면 인정하며 고개를 끄덕인다.'],
        ['객관적인 사고가 다소 부족하여 자기 객관화에 다소 부족한 모습을 보이고 자신을 매우 과대평가하거나 매우 과소평가하는 경향이 있다.'],
        ['차기능이 내향 직관 인 것으로 인해 상대방의 말이나 행동의 숨은 의도를 파악하기 힘들어하고 미래에 대한 계획을 세우는 것을 등한시하며 미래지향적이고 목표지향적인 생각이 부족하다.'],
        ['가끔 뒷일을 생각하지 않고 저지르는 경향이 있다.'],
        ['인간이 어떻게 기능하는지에 대한 이해를 넓히고 자신의 문화가 직면한 난관과 도전에 새로운 빛을 던지기 위해 사회적 기술을 사용한다.'],
        ['전형적인 사회적 모어와 친해지는 것은 종종 순수 분석 지식이 유형에 의해 충족될 수 있다.'],
        ['주기능이 외향 감정 이기 때문에 개인적인 가치보다는 집단의 통합과 보편적인 가치를 추구한다.'],
        ['집단의 분위기에 동화되는 것을 선호하며 다른 사람들도 그러길 바란다.'],
        ['주기능과 차기능으로 인해 개방성이 매우 높은 편이며 변화된 상황에서도 쉽게 적응한다.'],
        ['차기능의 열등 기능으로 공부나 지적 역량을 쌓는 것에 큰 관심이 없다.'],
        ['타인을 편하게 하는 성격이기 때문에 평균 소득이 감정형 중에서는 가장 높다.'],
        ['타고난 분위기 메이커입니다.'],
        ['새로운 사람 사귀는 것도 좋아하고 같이 노는 것도 좋아합니다.'],
        ['스트레스 받으면 누구라도 만나야 됩니다.'],
        ['어색한 거 못 참고 먼저 말 겁니다.'],
        ['친구 가족 내 사람을 잘 챙깁니다.'],
        ['강의 때 제일 호응을 많이 합니다.'],
        ['남한테 싫은 소리하는 거 싫어합니다.'],
        ['생각은 진짜 창의적인데 그만큼 실행력이 따라가지를 못합니다.'],
        ['감정 기복 심하고 감정이 얼굴에 다 드러납니다.'],
        ['남 얘기에 리액션 잘해줘서 고민 상담하는 애들이 있습니다.'],
        ['어디 가서 사회생활 잘한다는 소리를 듣습니다.'],
        ['다른 사람들한테 인정받을 때 기분이 좋습니다.'],
        ['누가 나한테 반대하거나 부탁을 거절하면 쉽게 마상을 입습니다.'],
        ['아직 안 일어난 상황에 대해 미리 걱정합니다.'],
        ['인간관계에서 상처받아도 상대방 배려한다고 얘기를 못합니다']]

ESTJ = [['외향적이고 감정이 잘 드러나서 직설적인 언어로 표현한다.'],
        ['모든 것이 제자리에 있어야 하며 계획이 틀어지는 것을 싫어한다.'],
        ['리더 역할을 딱히 선호하지는 않으나 막상 맡으면 잘한다.'],
        ['분명한 규칙을 중요시하고 그에 따라 행동하고 일을 추진하고 완성한다.'],
        ['정치 성향 면에서 중도주의 성향이 최하위 보수주의 성향은 가장 강한 것으로 나타났다.'],
        ['고집이 있지만 논리적으로 긍정하게 되면 더 이상 고집을 피우지 않는다.'],
        ['호불호가 확실하다.'],
        ['일을 잘해 놓고도 존경받는 일이 드물 수 있다.'],
        ['성격이 직설적이면서도 공감 능력이 매우 부족한 편이라서 아랫사람 주변사람과 갈등이 있는 경우가 있다.'],
        ['집단에서 분위기보다는 목적 의식을 중요시한다.'],
        ['경영자적인 재질 가지고 있는 것을 적절하게 활용하는데 탁월한 자질을 지녔다.'],
        ['이들의 재능은 주로 경영자적인 능력으로 나온다.'],
        ['한번 시작한 일을 철저하게 뿌리 뽑는다.'],
        ['모든 일을 계획적으로 구상하고 실행한다.'],
        ['예약과 계획을 생활화한다.'],
        ['자기관리에 철저하다.'],
        ['목표 지향적이다.'],
        ['독창력 창의력이 부족하다.'],
        ['매우 진취적이고 혁신적이며 현실적인 도전정신이 강한 야심가다.'],
        ['상당히 출세지향적이다.'],
        ['여유로우면 불안하다.'],
        ['남의 말에 공감하는 척하지만 속으로는 상황을 일일이 판단한다.'],
        ['말과 걸음이 빠르다.'],
        ['외로움을 별로 타지 않는다.'],
        ['지배하려는 성격이 있어도 양보는 잘 하지 않는다.'],
        ['감동시키기보다는 이해시키기를 원한다.'],
        ['싸움을 싫어하지만 싸워서 지는 것도 싫어한다.'],
        ['가만히 있으면 피곤하다.'],
        ['정도를 제외하면 평균 연봉이 가장 높은 유형이며 권력자가 될 확률도 다른 유형보다 높다.'],
        ['문과로 지원해야 유리한 것으로 나타났다.'],
        ['특징은 자신들의 생각이 확고한 경우가 많으므로 상대방을 멀어지게 할 수도 있습니다.'],
        ['상대방에 대한 감정적인 지원을 제공하려는 동기가 부족하기 때문입니다.'],
        ['무뚝뚝하다고 보일 수 있기 때문에 의식적으로 감정적으로 상대방을 이해하고 지원해 주려는 노력이 필요합니다.'],
        ['이 유형은 연인에 대해 관심이 많으며 때로는 지나치게 상대방을 통제하려고 하다가 관계가 멀어질 수 있습니다.'],
        ['연인의 행동에 대해서 너무 걱정이 된다고 하면 양해를 구하고 설명하려는 노력이 필요합니다.'],
        ['고집 셈 현실적 이성적 직설적입니다.'],
        ['호불호가 확실합니다.'],
        ['사람 많은거 극혐합니다.'],
        ['리더 맡는 거 싫어하는데 막상 하면 잘합니다.'],
        ['나가서 노는 것보단 이것저것 배우는 걸 좋아합니다.'],
        ['외로움을 별로 안 탑니다.'],
        ['싸우는 거 싫어하지만 싸워서 지는 것을 싫어합니다.'],
        ['일처리 못하는 거 세상에서 제일 싫어합니다.'],
        ['시간약속 어기는 거 싫고 즉흥적인 것을 싫어하고 번개약속을 싫어합니다.'],
        ['내 시간 방해받는 거 싫고 나한테 지적하려면 오억가지 근거 갖고 와야 한다.'],
        ['근데 하나라도 아닌 것 같으면 다 씹고 마이웨이를 걷습니다.'],
        ['남에게 관심 없고 오로지 나한테만 집중 목표 설정해놓고 그 목표 이룰 때까지 한 우물만 판다.'],
        ['사람들이 아는 내 성격이랑 혼자 있을 때랑 조금 다름 모든 게 제자리에 있어야 하고 내 계획이 절대 틀어지면 안 된다.'],
        ['뭐든 확실한 게 좋습니다.'],
        ['딱딱 떨어져야 합니다.'],
        ['리더 역할을 주도적으로 자주 합니다.'],
        ['누가 일 못하는 거 못 보고 차라리 그럴바에 내가 두세배로 일 다 해놓습니다.'],
        ['누가 힘든얘기 하면 감정적 공감보다 상황분석 먼저 하고 누가 잘못했네 머릿속으로 따지고 있습니다.'],
        ['그렇지만 상처받을까 봐 얘기는 안 하고 위로는 못합니다']]

ISFJ = [['혼자 있는 시간에 활력이 넘치고 아이디어와 개념보다 사실과 세부 사항에 중점을 두며 감정과 가치에 따라 결정을 내리고 계획과 조직을 선호하는 사람을 나타내며 자발적이고 유연하다.'],
        ['사람들을 안전하고 잘 보살피는 데에 관심이 있기 때문에 때때로 보호자 성격이라고도 한다.'],
        ['전통과 조직에 충직한 관리적인 성격이다.'],
        ['실용적이고 동정심이 많으며 다른 사람들을 보살피며 위험으로부터 보호하려고 한다.'],
        ['관습적이고 근거가 있으며 사회의 확립된 구조에 기여하는 것을 좋아한다.'],
        ['검증된 방법과 확실한 가치에 기인하고 사회에 받아들여진 일을 하는 것을 원한다.'],
        ['확립된 제도에 적응하고 안정적인 사회 구조를 유지하기 위해 할 수 있는 일에 기여하는 것을 중요시 여긴다.'],
        ['안정적인 삶을 지향하지만 본인이 이해 또는 존경받는다고 생각되는 범위에서 변화를 잘 수용할 수 있다.'],
        ['다른 사람들에 대한 깊은 책임감을 가지며 꾸준하고 헌신적이다.'],
        ['특히 다른 사람들의 욕구를 충족시킬 때 의무를 다한다.'],
        ['다른 사람들에게 자신이 믿을만 하고 그들이 나에게 기대하는 일을 해낼 수 있다는 신뢰가 있기를 바란다.'],
        ['타인을 향한 연민이나 동정심이 있으면서도 가족이나 친구를 보호해야 할 때는 가차 없는 모습을 보이기 때문에 이들을 정의하는 성격 특성에 꼭 들어맞지 않는다.'],
        ['개인적인 가치에 따라 행동하며 양심적이다.'],
        ['관계를 중요시 여기고 조화를 유지하기 위해 노력한다.'],
        ['조용하고 내성적인 반면 관계술에 뛰어나 인간관계를 잘 만들어간다.'],
        ['길고 안정적인 관계를 원하며 가족에 대한 깊은 헌신을 유지하는 경향이 있다.'],
        ['대체로 기존의 관계를 지향하지만 새로운 사람들과도 함께 할 수도 있다.'],
        ['장기적으로 의지할 수 있는 사람들과 가장 연결되어 있다고 느낀다.'],
        ['그룹에서 그들은 종종 역사가의 역할을 맡아 새로운 회원이 기존의 관습을 존중하고 가치있게 여기도록 한다.'],
        ['종종 자신에게 주의를 기울이지 않으며 절제된 방식으로 다른 사람들에게 도움을 제공하는 것을 볼 수 있다.'],
        ['가족 친구 및 지역 사회에 도움이 될 목적으로 일에 전념한다.'],
        ['무엇을 받으면 몇 배로 베푸는 이타주의자로 열정과 자애로움을 바탕으로 일단 믿는 이들이라면 타인이라도 잘 어울려 일에 정진한다.'],
        ['일반적으로 사교 집단에 참여는 하지만 주목받는 것은 꺼린다.'],
        ['자신의 역할을 완수하기 위해 열심히 일하기 때문에 주로 뒤에서 발견될 가능성이 더 크다.'],
        ['이들은 맡은 바 일에 책임감을 가지고 업무에 임하며 회사나 가정에서 그들의 기대치를 넘어 주위 사람들을 만족시키고자 최선을 다한다.'],
        ['일반적으로 뒤에서 일하는 것을 선호하며 자신의 성과를 공개적으로 발표하지 않고도 인정을 받는 것을 좋아한다.'],
        ['그들은 자신의 의무를 다했다고 다른 사람들에게 인정받고 싶지만 스포트라이트를 받고 싶지는 않다.'],
        ['본인의 업적이나 실적을 다른 사람들이 알아차리게 하는 데 어려움을 느낀다.'],
        ['종종 자신이 이룬 성취를 과소평가하는 경향이 있는데 이러한 겸손한 태도로 종종 다른 이들로부터 존경을 받기도 하는가 하면 이기적인 사람들은 이들의 겸손함을 역으로 이용하여 수호자형 사람이 세운 공을 자신의 것으로 돌리는 경우도 있다.'],
        ['이들은 화려한 스포트라이트를 받는 것을 불편해하며 다른 이들과 함께 달성한 업무에 있어 공을 인정받는 데에 어색해 하기도 한다.'],
        ['하지만 이들이 자신의 노력을 알리는 데 조금만 더 열중한다면 다른 유형의 사람이었을 때 그저 상상만 하고 있을 법한 일을 성취해 냄으로써 더 큰 자신감을 얻을 수 있을 것이다.'],
        ['대화를 할 때 개인적인 정보를 빨리 공개하지 않는 편이다.'],
        ['주변환경에 집중하고 인식하는 경향이 있으며 자신의 개인적인 경험에서 세부사항을 연관시킨다.'],
        ['세부사항에 주의를 기울이고 확립된 절차를 준수하는 일을 즐긴다.'],
        ['신중한 성향을 가진 사람은 완벽주의자만큼이나 세심하고 꼼꼼한 면모를 보이기도 한다.'],
        ['이로 인해 일을 지연하는 경우가 있기는 하지만 그렇다고 일을 시간 내에 마치지 못하는 것은 아니다.'],
        ['일어난 일 또는 직접 본 것에 대해 이야기하는 편이다.'],
        ['직접 본 것에 충실하며 종종 개인적인 경험을 바탕으로 관점을 공유한다.'],
        ['정보의 실제적인 사용을 보거나 도움이 될 수 있다고 생각할 때 정보를 제공한다.'],
        ['관계를 맺는 과정에서 다른 사람들에 대한 사실을 듣는 것을 좋아하고 사람들에 대한 세부 사항을 기억한다.'],
        ['내성적이면서 신기하게도 사회적인 성향을 가지고 있기도 한 이들은 좋은 기억력을 자랑한다.'],
        ['뛰어난 기억력으로 단순히 데이터나 사소한 정보를 기억하는 것이 아니라 만나는 사람들이나 그들과 관련한 소소한 사항들을 모두 기억해 놓는다.'],
        ['성격 특성 측정에서 보수적 관습적 보호적 유보적으로 점수를 매긴다.'],
        ['영적 능력을 믿을 가능성이 높은 유형 중 만성통증을 경험할 가능성이 평균보다 높다.'],
        ['심장병에 걸릴 가능성이 가장 높은 유형 중 대학 교육학 전공자 중 두 번째로 흔한 유형이다.'],
        ['소득이 가장 낮은 가지 유형 중 교육 의료 및 종교 직업에서 흔히 볼 수 있다.'],
        ['예리한 기억력 관찰을 위한 독수리의 눈 모든 세부 사항을 설명하려는 절대적인 결의를 갖춘 탁월한 실천가이다.'],
        ['임무에 집중할 때 구체적인 사실에 대한 깊이 있는 이해를 바탕으로 실제 문제를 해결하는 셜록 홈즈와 같은 성향을 가지고 있다.'],
        ['작업을 완료해야 할 때 강렬하고 진지하다.'],
        ['다른 사람들에게는 과도해 보일 수 있는 엄격한 접근방식을 자신의 일에 가져오는 유능한 수집가이다.'],
        ['유능한 도우미이다.'],
        ['시간과 에너지를 필요로 하는 사람과 기꺼이 나누고 문제와 목표에 공감하는 접근 방식을 취한다.'],
        ['부모 파트너 친구 학생 노동자 기업가 이웃 지역 사회 구성원 공무원 및 시민으로서 항상 탁월함을 위해 노력하며 정체성을 형성하고 고유한 능력을 부여하는 것은 비전의 포괄성이다.'],
        ['이제 우리 모두는 소중히 여기는 가치인 명예 성실 책임 충성도 및 헌신에 대해 잘 알고 있다.'],
        ['이론보다 실제가 더 중요하며 관습과 전통을 최대한 존중하며 너무 빠르게 변화하는 세상과 확립된 표준을 따르기를 거부하는 사람들에 대해 불안해할 수 있다.'],
        ['완전한 불만모드에 있어 도덕적 부패와 개인적인 책임에 대한 존중의 상실이 우리 사회를 안팎으로 파괴하고 있다고 스스로 확신할 수 있으며 비관주의에 너무 빠질 수 있다.'],
        ['충성심은 분명히 훌륭한 인격적 특성이다.'],
        ['그러나 그것은 양갈래 길이며 우리가 신뢰하기로 선택한 사람들이 부정직하거나 신뢰할 수 없는 것으로 판단되면 우리는 떠날 준비를 한다.'],
        ['그러나 그런 사람을 놓아주기 위해 고군분투하고 안좋은 상황의 끝까지 머무르는 경향이 있으며 이것이 유일하게 명예로운 일이라고 확신한다.'],
        ['수줍음이 많은 사람들과 경계를 이루는 매우 사적인 사람들이며 이것이 더 개방적이고 예측할 수 없는 성격 유형과 항상 잘 어울리는 것은 아니다.'],
        ['개방적인 이들이 거주하는 환경의 사회적 복잡성은 둥근 구멍의 우주에 있는 사각형 못처럼 안맞게 느낄 수도 있다.'],
        ['갈등에 대처하는 데에 어려움이 있고 사소한 비판도 개인적으로 받아들이는 경향이 있다.'],
        ['상대의 완고한 성격과 결합하여 취약함을 느끼고 부담을 느낄 수 있으며 방어 메커니즘으로 자기 비판과 의존성에 빠질 수 있다.'],
        ['훌륭한 직업 윤리를 가진 것으로 유명하지만 시간이 지남에 따라 이 긍정적인 특성은 일중독으로 변해 가 너무 과부하되어 시야가 좁아질 수 있다.'],
        ['워커홀릭 완벽주의적 성향으로 인해 주의가 산만해질 수 있으며 드물게 사무실에서 벗어나 잠시 집에 돌아와도 최근의 프로젝트나 과제에 계속 집착하게 된다.'],
        ['자신의 세계관에 얽매이고 자신의 머리 속에서 사는 데에 너무 많은 시간을 보내는 경향이 있다.'],
        ['따라서 사고방식과 이념적 성향이 다른 사람들과의 사회적 접촉이 절실히 필요하다.'],
        ['이러한 유형의 건설적인 사회적 상호 작용은 다양성과 사회변화를 더 편안하게 받아들이는 데 도움이 될 수 있다.'],
        ['다른 사람들을 대할 때 때때로 자신의 삶의 목적이 평화를 유지하고 모두를 행복하게 만드는 것처럼 행동한다.'],
        ['즉 자신을 제외한 모든 사람이다.'],
        ['자신의 감정을 억제하고 다른 사람의 필요를 따르는 습관은 고상해 보일 수 있지만 실제로는 그들을 행복하게 만들지 못하는 비생산적인 일로 전락한다.'],
        ['인간으로서 자신의 잠재력을 최대한 발휘할 수 있도록 자신을 표현해야 한다.'],
        ['자신감과 열정을 지키기 위해서는 이들도 아니요 라고 말해야 할 때와 자기 자신을 방어해야 할 때를 정확히 인지할 필요가 있다.'],
        ['안정적인 것은 일반적으로 좋은 것이만 특히 재미와 모험을 위해 남은 시간이 없을 정도로 일상 생활에 얽매이는 경향이 있어 더욱 모험이 필요하다 자발적이고 창의적인 면과 연결되도록 노력하고 때때로 새로운 것을 시도하여 검증된 사실에 대한 당신의 관념이 굳어지지 않도록 해야한다.'],
        ['진지하고 냉철한 태도는 선의일 수 있지만 때때로 약간의 유머는 누구에게도 상처를 주지 않는다.'],
        ['당신은 방에서 인생을 빨아먹는 사람이 되고 싶지 않을 것이기에 특히 업무에 있을 때 재미 웃음 계획에 없던 가끔의 커피를 홀짝이는 휴식이 스트레스를 해소하고 동료애를 구축하는 데 도움이 되며 장기적으로 직장 효율성을 높이는 데 도움이 될 수 있음을 인식해야 한다.'],
        ['알 수 없는 상황에서 주의해야 할 것은 의 계획적 운영절차이며 이는 개인의 성장을 방해하여 침체될 수 있다.'],
        ['때로는 걱정하는 것이 합리적이지만 끊임없는 걱정은 행복에 대한 기생충과도 같다.'],
        ['이따금 완벽주의를 버리고 느슨하게 살자 엄격한 기준을 풀 때만이 진정한 행복이 찾아온다']]

ISTJ = [['의과대학이나 간호대학의 정서문화와 흡사하다.'],
        ['선입견이 강하다.'],
        ['낯가림이 심한 편이다.'],
        ['지나고 난 다음에 따지는 편이다.'],
        ['주어진 업무나 책임을 끝까지 완수한다.'],
        ['의젓한 성격이므로 장남 장녀같다는 말을 많이 듣는다.'],
        ['예고없이 갑작스러운 변화를 매우 싫어한다.'],
        ['원리 원칙적이다.'],
        ['실수한 것을 참지 못하고 즉각 수정하기를 원한다.'],
        ['남들이 속을 모른다고 말한다.'],
        ['휴일에도 집에서 주로 지낸다.'],
        ['참고 참았다가 터뜨리는 편이다.'],
        ['논리적 합리적인 것을 중시하지만 부기능이 외향적 사고이고 주기능이 내향적 감각이라서 구시대적인 관습을 논리에 따른 판단 없이 수용하는 편이다.'],
        ['잘못했다는 건 인정하면서도 미안하다 잘못했다고 잘 못한다.'],
        ['주기능이 내향 감각이면서 차기능이 내향 감정이라서 사고형 중에서는 가장 감정 성향이 높은 편이다.'],
        ['정리정돈을 해놓는 것이 우선이다.'],
        ['주기능인 내향 감각 으로 과거 회상을 좋아하며 남들이 기억하기 힘든 세세한 추억들까지 간직하고 있는 경우가 많다.'],
        ['직설적인 표현을 많이 하는 편이다.'],
        ['주로 가까운 사람들에게 현실성 대중성을 중시하므로 취미를 가져도 일반적인 것 아니면 전통적인 것을 선호한다.'],
        ['겉보기에 차가워 보인다.'],
        ['건강하지 않을 경우 자신이 속해 있는 소속 내의 사람들을 관리하고 통제하려는 경향이 있다.'],
        ['특히 기성세대 부모의 그런 경향은 진취적이고 독립적인 자녀 앞에서 큰 독이 된다.'],
        ['내향형 중에서는 가장 많이 성공하는 유형이기도 하다.'],
        ['남들이 본인의 일에 참견하는 것을 싫어한다.'],
        ['보편적인 요소와 일들에 많은 흥미를 가지며 소위 말하는 특이한것 튀는것에는 관심이 적은 편이다.']]

ENFJ = [['직관 형들 중에서 가장 외향적이다.'],
        ['전형적인 모범이 되는 학생회장 유형이다.'],
        ['군중을 이끄는 뛰어난 리더십이 있다.'],
        ['말하는 재능 글쓰는 재능이 대단히 뛰어나다.'],
        ['대중과 상대방의 분위기를 읽는 공감능력이 탁월하기에 유머감각이 뛰어나다.'],
        ['사람을 굉장히 좋아한다.'],
        ['연민과 동정 이해심이 대단히 많다.'],
        ['인생과 인간을 따뜻하게 바라본다.'],
        ['감정이입이 너무 잘돼서 스스로도 스트레스를 받는다.'],
        ['모든 사람들이 특별하다고 생각한다.'],
        ['세상 모든 사람이 함께 행복했으면 좋겠다고 생각한다.'],
        ['타인의 관심사에 귀 기울이며 그들을 배려한다.'],
        ['타인에 대한 관심이 많아 간혹 오지랖이 넓다는 평가를 받는다.'],
        ['이상적이다.'],
        ['따라서 사람과 인간관계를 이상화하는 성향이 있다.'],
        ['원만한 인간관계를 유지하는 데 큰 의미를 부여하는 유형이다.'],
        ['인간관계에서도 진실성 온전함에 가장 높은 가치를 부여한다.'],
        ['직관적으로 사람을 파악하는데 능하고 도움을 주기 위해 적극적으로 나서는 편이다.'],
        ['정말로 가치 있다고 여기는 일에 대해 헌신이 강하다.'],
        ['누군가 성장할 수 있는 기회가 있다면 전폭적인 지원을 아끼지 않는다.'],
        ['사람을 좋아해 대가 없는 베품을 굉장히 좋아한다.'],
        ['호감있는 사람에게는 간이고 쓸개고 빼 주는 편이다.'],
        ['대의명분 제도에 충실하다.'],
        ['책임감이 강하고 양심적이며 인내심이 강하다.'],
        ['힘이 넘치고 정의로우며 열정적이다.'],
        ['사회 정의를 위해서는 어떠한 어려움과도 맞서 싸운다.'],
        ['외교적이고 주변과의 조화능력이 탁월하다.'],
        ['하지만 가끔 타인의 문제나 감정에 지나치게 관여할 때가 있다.'],
        ['자기 반성과 자책을 자기 발전의 원동력으로 삼는다.'],
        ['관심사가 다양하며 학습 속도가 빠르다.'],
        ['경쟁적이거나 긴장이 팽배한 환경에서 일하기 힘들 수 있다.'],
        ['삶의 의미를 끊임없이 탐구한다.'],
        ['타인을 의식하는 경향도 있다.'],
        ['모든 것을 자기 자신과 연결시키려는 성향이 있다.'],
        ['성격이 급해 가끔은 충동적으로 행동할 때가 있다.'],
        ['질서정연하며 조직적인 세계를 선호한다.'],
        ['자기 반성은 잘하지만 남을 비판하는 데 능숙지 않다.'],
        ['특유의 설득력 있는 연설 능력으로 함께 추구해야 할 공통된 목표를 설정하고 제시하며 사람들을 이끈다.'],
        ['더 밝은 미래 구현을 위해 앞장서서 사람들을 이끄는 것을 좋아한다.'],
        ['살기 좋은 공동체를 만들기 위해 사람들을 동참시키고 이끄는 데에서 큰 자부심과 행복을 느낀다.'],
        ['상대방을 설득시키는데 대단히 능하다.'],['연예인 방송인 언론인 교육자 외교관 등의 직업이 적합하다.'],
        ['평균 지능 지수 가 유형 중 위이다.'],
        ['구체적이고 현실적이며 지도력이 있고 신중하며 집중력이 강하다.'],
        ['주기능 외향 감정 와 부기능 내향 직관 의 영향으로 눈치가 무서울 정도로 빠르다.']]

ENFP = [['감정이 얼굴에 잘 드러난다.'],
        ['인정을 받으려는 욕구가 강하고 타인의 시선에 민감하다.'],
        ['관심받기를 원하며 생각이 많고 예민하다.'],
        ['새로운 시도를 좋아한다.'],
        ['계획하기보다는 그때그때 일을 처리하는 편이다.'],
        ['새로운 사람 만나기를 좋아한다 감동을 잘하고 눈물도 잘 흘린다.'],
        ['경제 관념이 희박하여 돈을 모으기는 힘들다.'],
        ['작은 일에도 감정의 기복이 심하다.'],
        ['내면은 소심하여 자주 삐친다.'],
        ['그러나 삐치더라도 몇 시간 후면 다시 원래대로 돌아온다.'],
        ['외향 직관 가 강하기 때문에 상황를 깊게 분석하는 능력은 떨어지는 편이지만 반비례로 상황를 정말 쉴 틈없이 파악하려는 성질이 약점을 보완하기 때문에 종합적으로는 상대적으로 눈치가 있는편에 속하고 당장 직관적으로 드러나는 분위기 파악은 빠른 경향이 있다.'],
        ['상대방의 말에 굉장히 민감하나 겉으로는 기분이 나쁘지 않은 척한다.'],
        ['내면에 열정을 지녔다.'],
        ['위기 대처능력이 뛰어나다.'],
        ['사람을 기쁘게 해주는 능력이 있다.'],
        ['사람을 쉽게 밀쳐내지 못한다.'],
        ['행사나 일을 잘 주선한다.'],
        ['다만 보통 이걸 하자 선에서 끝나며 구체적인 계획은 없다.'],
        ['놀다가도 몰입이 안 되고 지금 무엇을 하고 있는 건가 라는 생각이 들 때가 있다.'],
        ['타인이 보기엔 자칫 허영이라 느낄 정도로 멋 내고 뽐내는 것을 굉장히 좋아한다.'],
        ['싸움을 할려면 심장부터 뛴다.'],
        ['단순 암기에 약하다.'],
        ['인생을 즐겁게 살려고 한다.'],
        ['선생님이 마음에 들면 하기 싫은 과목도 잘한다.'],
        ['주기능은 외향 직관 으로 두뇌 회전이 빠른 편이고 직관력을 이용하여 어떤 사안에 대한 대략적인 이해가 뛰어나다.'],
        ['하기 싫은 것에 대한 인내력이 부족하다.'],
        ['좋아하는 사람과 싫어하는 사람의 구별이 심하다.'],
        ['반복적인 일상을 힘들어 한다 분위기를 잘 띄운 후에 자기는 빠진다.'],
        ['의사소통 능력과 대인관계 만족도가 타 유형에 비해 높다.'],
        ['출처 미드나 오피스물을 좋아하는 경우가 많다.'],
        ['집 꾸미기를 좋아하는 성향을 가지고 있는 경우가 많다.']]

INFJ = [['이상주의적 완벽주의적 성향을 추구한다.'],
        ['내향적 사고로 겉으로는 공감할 수 있지만 속으로는 비판적으로 생각하는 경향이 있다.'],
        ['덕분에 감정형 중에선 가장 이성성향이 높은 편이다.'],
        ['주기능이 내향 직관으로 미래를 예측하는 것을 좋아하며 상상력 창의력과 독창성이 뛰어나다.'],
        ['본인만의 철칙이 뚜렷하여 고집이 세다고 느껴질 수 있다.'],
        ['출처 사회적 불의에 민감하여 높은 도덕 관념을 지니고 있다.'],
        ['출처 생활에서는 보수적이면서 동시에 반항적이다.'],
        ['출처 겉으로는 사회적 질서에 잘 따르지만 사실은 본인만의 철칙이 뚜렷해서 자기 기준에 맞지 않으면 반항적으로 변한다.'],
        ['또한 사회적 불의에 민감하여 정의롭지 못한 사회에 대응하는 태도를 보이는 경향이 있다.'],
        ['감정적이면서 동시에 이성적이다.'],
        ['출처 목적과 의미가 있는 일에 대해 열정적이다.'],
        ['출처 이는 유형의 특징이기도 하다.'],
        ['직관적 감성이 늘 현실을 초월하는 의미와 관념에 관심을 기울이기 때문이다.'],
        ['특유의 열정으로 본인이 가진 한계점을 넘어서는 것은 즐기지만 자칫 열정이 임계점을 넘어설 경우 쉬이 지치거나 극심한 스트레스를 호소하기도 한다.'],
        ['출처 번아웃에 취약한 유형이다.'],
        ['반복적이고 의미 없는 일이나 과도한 업무량 불편한 인간관계 등에 쉽게 지친다.'],
        ['출처 사회에 적응하기 위해 페르소나를 쓴다.'],
        ['겉보기에는 아주 차갑지만 속은 난로처럼 따뜻하다.'],
        ['사람이나 일에 있어 호불호가 분명히 나뉜다.'],
        ['출처 자신의 상상력을 자극하는 창작물을 좋아한다.'],
        ['출처 호기심이 많고 열정적이며 언제나 의문을 갖는다.'],
        ['가슴 속에 묻어둔 질문들이 많다.'],
        ['출처 몽환적이며 신비로운 것을 좋아한다.'],
        ['출처 거짓말을 매우 싫어하며 진실을 중요시한다.'],
        ['출처 대체로 약자의 편에 선다.'],
        ['자아성찰을 자주 하는 편이며 본인 스스로에게 매우 엄격하다.'],
        ['출처 스스로 옳다고 확신이 생긴 신념은 끝까지 관철해 나간다.'],
        ['이익이나 부당함에 따르는 것을 싫어하여 결백성이 심하다.'],
        ['심리학에 관심이 많다.'],
        ['출처 대부분의 이유가 성격유형 중 비율이 매우 적은 유형은 확률상 일상에서 자신과 같은 유형을 접하기가 어렵고 그로 인해서 주변에서 괴짜나 이방인 취급을 받기도 하며 누군가의 이해를 받는 경우 자체가 드물기 때문에 자신의 성격의 문제로 취급하기 일쑤다.'],
        ['동질감과 안도감을 느낀다.'],
        ['에너지 마법 성격 유형 철학 삶의 목적과 같은 추상적인 것을 선호한다.'],
        ['자기 안에 갈등이 많고 복잡하다.'],
        ['고민이 많기 때문에 청소년기 때 방황을 하는 경우가 종종 있다.'],
        ['건강하지 않은 경우 주목공포증 발표공포증이 있는 경우가 많다.'],
        ['반대로 건강할 경우 발표나 토론 등의 활동을 즐긴다.'],
        ['자신들을 위해 만들어준 합법적인 리그라고 생각하기도 한다.'],
        ['종교가 없더라도 종교적이다.'],
        ['음악 책 등의 예술 및 문학 분야에 많은 관심과 지식을 지니고 있으며 그 관심이 행동으로 직결되는 경우가 많기 때문에 그 분야에 뛰어난 감각을 가지고 있는 사람이 많다.'],
        ['출처 언어능력 및 감각이 좋아 국어를 포함한 어학 과목에 강하다.'],
        ['출처 단어에 담긴 함의를 파악해야 하는 사회탐구 과목 특성상 특히 윤리와 사상 생활과 윤리에도 강세를 보인다.'],
        ['일반적인 통념과는 다르게 수리적인 영역이나 공학분야 등에서도 두각을 나타낸다.'],
        ['유형이 이과적인 분야에 강하지 않을 거라고 생각하는 사람들도 있지만 마찬가지로 이과적인 과목에도 강세를 보이는 경우가 종종 있다.'],
        ['왜냐하면 두 유형의 성향이 깊게 생각하는 것과 관련이 많기 때문이라고 한다.'],
        ['비유와 은유를 잘하며 본인이 하는 말을 타인이 잘 이해하지 못하는 경우가 있다.'],
        ['일반적으로 혼자서 무엇을 하는 걸 선호하는 경향이 있다.'],
        ['자신의 바운더리에 포함시킨 사람은 모든 걸 내어줄 정도로 헌신적이고 다정하다.'],
        ['그런데 그 바운더리에 들어오는 것이 굉장히 까다롭고 힘든 일이다.'],
        ['좋아하면 좋아할수록 좀처럼 자신의 마음을 드러내기 어려워해서 짝사랑을 많이 하는 편이라고 한다.'],
        ['쓸 데 없는 연락을 싫어한다.'],
        ['미래 진로 고민 등 진중한 이야기 나누는 것을 더 좋아한다.'],
        ['전화보다 문자 등의 글로 쓸 수 있는 소통 매체를 더 선호한다.'],
        ['특성 상 말로 표현하기보다 글로 표현하는 것이 훨씬 정갈하게 표현할 수 있기 때문이다.'],
        ['상대방의 입장에서는 친하다고 느낄 수 있으나 정작 본인은 그렇지 않다고 느끼는 경우도 많다.'],
        ['마음 속으로 친분을 단계 정도 나누고 있다든가 한 경우들이 있다.']]

INFP = [['개인주의자다.'],
        ['이들은 각 개인이 꼭 보편적인 길을 선택할 필요없이 각자만의 길을 찾아가야 한다고 믿는다.'],
        ['주기능은 내향감정으로 자신의 생각과 가치를 탐구하거나 무엇이 옳고 그른지 스스로 결정하는 데에 시간을 보내는 것을 즐기고 다른 사람들에게도 그렇게 하도록 부드럽게 격려한다.'],
        ['이들의 판단은 사회의 보편적인 정서에 크게 의존하지 않기 때문에 외향감정의 판단과 표현을 경계할 수 있다.'],
        ['판단과 표현은 지나치게 전체주의적 혹은 가식적으로 보일 수 있다.'],
        ['자아를 포기하면서까지 사회에 녹아들 바에는 차라리 그들 스스로에게 진실하기를 원할 것이다.'],
        ['이상주의자다.'],
        ['목가적이고 낭만적이며 내적 신념이 강하다.'],
        ['자신이 지향하는 이상에 대해서는 정열적인 신념을 지니고 있다.'],
        ['자신에게 의미있는 가치나 사람들에게 충성하며 자신의 가치와 조화를 이룰 수 있는 외부세계를 선호한다.'],
        ['진정성을 중시한다.'],
        ['가식적이거나 피상적 상투적인 것에 큰 거부감을 느낄 수 있다.'],
        ['내향성이 강한 본인의 거부감을 굳이 표현하고 싶지 않은 경우에 따라 페르소나를 사용 할 수는 있다.'],
        ['전통관습에 매달리는 것은 별로 호소력이 없다.'],
        ['복잡한 상황에서는 잘 견디지만 반복되는 일에는 인내심이 없다.'],
        ['창의력이 뛰어나고 새로운 아이디어와 정보를 잘 수용하는 편이다.'],
        ['부기능은 외향 직관으로 두뇌 회전이 빠른 편이고 직관력을 이용하여 어떤 사안에 대한 대략적인 이해가 매우 뛰어나다.'],
        ['이해심 많고 적응력이 좋으며 대체로 관대하고 개방적이다.'],
        ['자신들의 가치가 위협받지 않는 한 잘 적응하고 융통성이 있으며 수용하는 편이다.'],
        ['물론 반대의 환경에서는 매우 적응을 어려워하고 겉도는 경우가 많다.'],
        ['약속을 정할때도 일반적으로 타인한테 먼저 맞추려고 하는등 사소한 일들에 한해서는 이타적인 기질을 보인다.'],
        ['그러나 내적인 신념이 조금이라도 위협당한다고 느끼면 한 치의 양보가 없으며 경우에 따라서 매우 이기적으로 행동도 한다.'],
        ['호기심이 많고 어떠한 일의 결과보다 가능성을 보는 경향이 있으며 아이디어를 수행하기 위한 촉매 역할을 한다,'],
        ['사람들의 본질을 이해하려 하고 이들의 가능성을 성취할 수 있도록 돕는다.'],
        ['조화롭게 살고자 하며 분쟁을 피하기 위해서는 철저하다.'],
        ['타인의 정서를 잘 이해하고 원만한 관계를 맺는다.'],
        ['단지 약간의 심리적인 거리는 유지한다.'],
        ['반면 다른 사람이 반대의 목적을 가지고 일하는 것을 보거나 갈등이 표출되었을 때는 감정적으로 힘들어 한다.'],
        ['타인의 감정에 민감하고 좋아하는 사람을 기쁘게 하는 것을 즐거워한다.'],
        ['마음이 따뜻하나 상대방과 친해지기 전까지 자신의 따뜻함을 잘 표현하지 않으며 오히려 조용하고 과묵하다.'],
        ['애정표시를 직접적으로 하지 못하는 편이다.'],
        ['소수의 특별한 사람들과 매우 깊게 아주 정열적으로 대의에 대해 관심을 갖는다.'],
        ['자신과 관련된 사람이나 일에 대해 책임감이 강하고 성실하다.'],
        ['헌신 동정 관계를 유지하기 위해 적응하는 데 특별한 능력이 있으므로 같이 살기에 편하다.'],
        ['자신들이 믿는 사람이나 대의명분을 위해서는 기꺼이 희생할 수 있다.'],
        ['추함 선과 악 등 도덕적인 것과 비도덕적인 것에 대하여 민감하게 반응한다.'],
        ['순수한 논리보다는 가치부여 과정 자체를 선호한다.'],
        ['성공 미 건강 재산 지식을 지나치게 누리게 되면 언젠가는 그 대가를 지불해야 한다는 무의식적인 확신을 갖고 있다.'],
        ['또한 스스로 불순한 유혹에 굴복 당했다고 믿을 때 그 보상으로 자신을 희생하는 행위를 보인다.'],
        ['이러한 보상 행위는 스스로의 내부적 동기에 의해서이며 외부에서 강요된 것이 아니다.'],
        ['책과 언어에 관심을 갖고 있고 표현에 있어서 뛰어난 작가가 될 수 있는 천재성을 가지는 경우가 다수 있다.'],
        ['사업과는 인연이 멀다.'],
        ['신비롭고 몽환적인 것 판타지물 등을 좋아한다.'],
        ['우울증 유병률이 가장 높은 유형이다.']]

---------------------------MBTI 2차 정제작업 저장-------------------------------

## 데이터 저장
# 담당 : 고승한/양민승
import pickle
import pandas as pd
from pandas import Series, DataFrame
import csv

# 고승한
new_esfj1 = pd.DataFrame({'MBTI':'ESFJ','특성':ESFJ1})
new_estj1 = pd.DataFrame({'MBTI':'ESTJ','특성':ESTJ1})
new_isfj1 = pd.DataFrame({'MBTI':'ISFJ','특성':ISFJ1})
new_istj1 = pd.DataFrame({'MBTI':'ISTJ','특성':ISTJ1})
new_enfj1 = pd.DataFrame({'MBTI':'ENFJ','특성':ENFJ1})
new_enfp1 = pd.DataFrame({'MBTI':'ENFP','특성':ENFP1})
new_infj1 = pd.DataFrame({'MBTI':'INFJ','특성':INFJ1})
new_infp1 = pd.DataFrame({'MBTI':'INFP','특성':INFP1})

new_df = pd.concat([new_esfj1,new_estj1,new_isfj1,new_istj1,new_enfj1,new_enfp1,new_infj1,new_infp1], ignore_index = True)

file = open("/Users/seunghanko/Downloads/new_df.pkl","wb")
pickle.dump(new_df,file)
file.close()

# 양민승
# 각각의 MBTI 내용 중첩리스트 풀어주기
ISFP1 = [j for i in ISFP for j in i]
ESTP1 = [j for i in ESTP for j in i]
ESFP1 = [j for i in ESFP for j in i]
ISTP1 = [j for i in ISTP for j in i]
ENTJ1 = [j for i in ENTJ for j in i]
ENTP1 = [j for i in ENTP for j in i]
INTJ1 = [j for i in INTJ for j in i]
INTP1 = [j for i in INTP for j in i]

# 데이터 프레임화를 위한 라벨 및 내용 만들기
new_isfp = pd.DataFrame({'MBTI':'ISFP','특성':ISFP1})
new_estp = pd.DataFrame({'MBTI':'ESTP','특성':ESTP1})
new_esfp = pd.DataFrame({'MBTI':'ESFP','특성':ESFP1})
new_istp = pd.DataFrame({'MBTI':'ISTP','특성':ISTP1})
new_entj = pd.DataFrame({'MBTI':'ENTJ','특성':ENTJ1})
new_entp = pd.DataFrame({'MBTI':'ENTP','특성':ENTP1})
new_intj = pd.DataFrame({'MBTI':'INTJ','특성':INTJ1})
new_intp = pd.DataFrame({'MBTI':'INTP','특성':INTP1})

# 콘캣 메소드를 통한 mbti 데이터프레임 합치기
new_mbti = pd.concat([new_isfp,new_estp,new_esfp,new_istp,new_entj,new_entp,new_intj,new_intp],ignore_index=True)  
new_mbti   

# 총 갯수 일치하는지 확인
len(new_mbti) == len(new_isfp)+len(new_estp)+len(new_esfp)+len(new_istp)+len(new_entp)+len(new_entj)+len(new_intp)+len(new_intj)


# 양민승/고승한 자료를 받아서 합치기
file = open("c:/data/new_df.pkl",'rb')
new_df = pickle.load(file)
new_df
file.close()

mbti_final = pd.concat([new_mbti,new_df],ignore_index=True)
mbti_final

# 파일 저장
mbti_final.to_csv('c:/data/MBTI_b.csv')

-------------------------MBTI 3차 정제작업--------------------------------------

## MBTI 키워드 변경 작업
# 담당 : 고승한/양민승
import pandas as pd
from pandas import Series,DataFrame


# 양민승 작업
# ESFP들 키워드 세부 요약
ESFP = [["상호존중을 중시한다."],
        ["붙임성과 인사성이 좋다."],
        ['공과 사 구분이 잘 안된다.'],
        ['에너지가 넘친다.'],
        ['현재가 중요하다.'],
        ['분위기 메이커이다.'],
        ['통신사 VVIP.'],
        ['지시랑 명령을 잘 따르지 않는다.'],
        ['장기적으로 결과가 잘 안나온다.'],
        ['부탁 거절을 잘 못한다.'],
        ['친구따라 강남을 자주 간다.'],
        ['충동적인 기질이 강하다.'],
        ['심각한 상황에도 여유가 있다.'],
        ['마감시간 지키기 어렵다.'],
        ['음식 사진을 다량으로 보유하고 있다.'],
        ['낙관주의자.'],
        ['현장에서 행동하는 것을 좋아한다.'],
        ['온화하며 동정적이다.'],
        ['매사에 즐겁다.'],
        ['재치가 넘친다.'],
        ['산만하다는 이야기를 듣는다.'],
        ['해야할 일보다 즐거움에 우선순위를 둔다.'],
        ['복잡한 사람과 상황을 회피한다.'],
        ['새로운 시도를 즐긴다.']]

# ESTP 키워드 입력
ESTP = [['선입견이 없다.'],
        ['스릴과 모험, 여행을 즐긴다.'],
        ['행동과 목적에 재미를 추구하는 경우가 많다.'],
        ['합리적으로 효율을 추구한다.'],
        ['영업, 어필을 잘 한다.'],
        ['상대를 편하게 해준다.'],
        ['현실적인 것에 몰두를 잘한다.'],
        ['논리와 인과관계 파악이 빠르다.'],
        ['나서지 말라는 얘기를 듣는다.'],
        ['형사물을 좋아한다.'],
        ['일을 잘 그만둔다.'],
        ['쿨하다.'],
        ['지금 이 순간을 즐긴다.'],
        ['적극적이고 열정적이다.'],
        ['두루두루 방면에 지식이 있다.'],
        ['발표에 재능이 있다.'],
        ['위기상황에 임기응변을 잘 발휘한다.'],
        ['갈등상황을 잘 중재한다.'],
        ['자신의 지식과 역량에 믿음이 있다.'],
        ['나서기는 좋아하지만 책임지기는 싫어한다.'],
        ['중요한 의무보다 삶의 즐거움이 먼저다.'],
        ['생각보다 행동이 앞선다.'],
        ['고민을 깊게 하지 않는다.'],
        ['분위기를 타는 편이다.']]

# ISFP 키워드
ISFP = [['공과 사 구분이 가끔씩 안된다.'],
        ['눈치만 보다가 끝나는 경우가 있다.'],
        ['타인의 감정을 잘 헤아린다.'],
        ['도시적인 것 보다 자연과 풍경을 좋아한다.'],
        ['작은 일에도 행복감을 느낀다.'],
        ['게임에서 지원가(힐러) 선호.'],
        ['낙천주의자다.'],
        ['인생의 의미를 찾아내는데 재능이 있다.'],
        ['부드러운 성격이다.'],
        ['포용력과 수용력이 넓다.'],
        ['따뜻한 성격이다.'],
        ['논리적이고 객관적인 체계를 거부한다.'],
        ['친밀감을 잘 형성한다.'],
        ['종종 자아비판에 빠진다.'],
        ['남을 배려하다 자기꺼를 못 챙긴다.'],
        ['다이어리나 플래너를 사서 안 쓴다.'],
        ['사람 좋다는 소리를 들어봤다.'],
        ['소극적 저항'],
        ['물 흐르듯이 산다.'],
        ['미래 생각하면 막막하다.'],
        ['즉흥적 성격이다.'],
        ['현재 삶을 즐긴다.'],
        ['조용하다.'],
        ['사람과 상황 사이에서 갈등한다.']]

# ISTP 키워드
ISTP = [['청소는 꼭 필요할때 한다.'],
        ['개인공간이 필수이다.'],
        ['옷 취향이 심플함.'],
        ['소수와 어울림.'],
        ['바로 드러내지 않고 관조함.'],
        ['단축키 잘 외움.'],
        ['관찰력이 좋다.'],
        ['과한 정서표현 부담스러움'],
        ['과묵함'],
        ['다양성 새로운 경험 추구'],
        ['자료를 간결화 함'],
        ['결정을 잘 미룬다.'],
        ['서비스직 불호'],
        ['기술쪽으로 재능이 있다.'],
        ['게으른 천재'],
        ['공평함'],
        ['독립적이다.'],
        ['순발력이 있다.'],
        ['영혼없다는 이야기 들어봄'],
        ['원리원칙을 중요시 한다.'],
        ['"내가 싫어?" 라는 말을 들어 본적이 있다.'],
        ['운전이나 조종을 잘하는 편이다.'],
        ['타인에 무관심'],
        ['실리적이다.']]

# ENTJ 키워드
ENTJ = [['복잡한 문제에 뛰어든다.'],
        ['열정적이다.'],
        ['직설적이다.'],
        ['타인의 감정 이해를 어려워 한다.'],
        ['리더 역할을 선호한다.'],
        ['너무 차갑다는 말을 듣는다.'],
        ['기준이 높다.'],
        ['일을 만들어 한다.'],
        ['속도가 빠르다.'],
        ['공감 보다는 문제 해결을 선호한다.'],
        ['돌진만 있고 후진이 없다.'],
        ['비전이 확고함.'],
        ['수용이나 경청이 부족하다.'],
        ['계획이 구체적이기 보다 이상적이다.'],
        ['지나친 비판을 한다.'],
        ['솔직하다.'],
        ['카리스마 있다.'],
        ['수첩,다이어리,캘린더를 쓴다.'],
        ['자신을 몰아붙인다.'],
        ['자기 주장이 강하다.'],
        ['호기심이 왕성하다.'],
        ['계획이 어긋나면 스트레스를 받는다.'],
        ['자신의 역량과 지식에 자신감이 있다.'],
        ['전략적이다.']]

# ENTP 키워드
ENTP = [['꾸미기를 좋아하고 패션에 관심이 있다.'],
        ['새로운 것을 추구한다.'],
        ['독특하다.'],
        ['열정적이다.'],
        ['발명,발견에 관심이 있다.'],
        ['주관이 뚜렷하다.'],
        ['마무리가 시원하지 않다.'],
        ['종종 공격적으로 나온다.'],
        ['변화에 대한 적응력이 좋다.'],
        ['기회와 가능성을 중시한다.'],
        ['솔직한 편이다.'],
        ['도전적이다.'],
        ['호기심이 많다.'],
        ['상황에 대한 논리적 분석'],
        ['후회를 모른다.'],
        ['비전을 중시한다.'],
        ['체계와 패턴을 잘 파악한다.'],
        ['자신감이 넘친다.'],
        ['현실성이 부족하다.'],
        ['꼼꼼하지는 않은 편이다.'],
        ['상상력이 풍부하다.'],
        ['참을성이 부족하다.'],
        ['"왜 이렇게 정신없어?" 라는 말을 가끔 듣는다.'],
        ['창의적이다.']]

# INTJ 키워드    
INTJ = [['현실주의자인 척 하는 이상주의자다.'],
        ['책임감이 있다.'],
        ['사회 생활시 페르소나가 있다.'],
        ['분석을 잘한다.'],
        ['지적을 활동을 선호한다.'],
        ['일상적인 행복에 무디다.'],
        ['비평을 좋아한다.'],
        ['칭찬에 인색하다.'],
        ['처음 봤는데 알 것 같은 것들이 있다.'],
        ['문구류를 수집한다.'],
        ['대화보다 독서나 검색을 한다.'],
        ['독립적이다.'],
        ['친밀한 관계가 어렵다.'],
        ['우선 던져놓고 힘들게 회수한다.'],
        ['완벽주의자다.'],
        ['객관적이다.'],
        ['꼼꼼하지 않다.'],
        ['생각이 많다.'],
        ['이상한 유머가 있다.'],
        ['효율성을 추구한다.'],
        ['슬랩스틱보다 블랙유머를 좋아한다.'],
        ['기하학적인(패턴,그림) 것에 끌린다.'],
        ['종종 영혼없다는 소리를 듣는다.'],
        ['열심히 산다는 소리를 가끔 듣는다.']]

# INTP
INTP = [['아이디어가 풍부하다.'],
        ['중간 보고를 싫어한다.'],
        ['얼굴과 이름을 파악하는데 약하다.'],
        ['깊이 파고든다.'],
        ['대화시 주제가 다양하다.'],
        ['대화보다 독서나 검색을 좋아한다.'],
        ['브레인 스토밍을 좋아한다.'],
        ['정없다는 소리를 가끔 듣는다.'],
        ['세상 질서에 별 관심이 없다.'],
        ['인성보다는 능력을 선호한다.'],
        ['생각에 몰입해 실행을 미룬다.'],
        ['친밀한 관계를 만들기 어렵다.'],
        ['재능과 천재성에 높은 가치를 둔다.'],
        ['생각의 흐름이 빠르다.'],
        ['변화에 강한편이다.'],
        ['레시피에 맞게 요리하는게 어렵다.'],
        ['쓸데없는 정보를 싫어한다.'],
        ['편한 옷을 선호한다.'],
        ['독창적인 세계관이 있다.'],
        ['노트를 사놓고 잘 안쓴다.'],
        ['반복되는 일상을 지겨워한다.'],
        ['종종 돌직구를 날린다.'],
        ['목적없이 지식을 탐구한다.'],
        ['호기심이 많다.']]

# 고승한
# 키워드 자료 열별로 저장.
ESFJ = [['상담 / 심리에 관심있음.'],
        ['아이들 좋아함.'],
        ['어색하면 먼저 말을 꺼냄'],
        ['서비스정신 투철'],
        ['통일성보다는 다양성 선호'],
        ['쉽게 서운해짐'],
        ['칭찬 자판기'],
        ['자신보다 남을 챙길 때가 있다.'],
        ['매사에 열정적'],
        ['이벤트 잘 기획함'],
        ['관심에 민감함'],
        ['표정이 밝은 편'],
        ['리액션 부자(거의 방청객)'],
        ['설득을 잘 하는 편'],
        ['가족여행 좋아함.'],
        ['팀플레이 선호'],
        ['손편지 좋아함'],
        ['속단하는 경향 있음.'],
        ['오지랖 있음'],
        ['외모를 잘 꾸밈'],
        ['인정욕구 강함'],
        ['정이 많음'],
        ['현실 / 룰을 중시함'],
        ['성격 좋다는 이야기 들어봄']]

ESTJ = [['추진력 있다.'],
        ['공공질서 수호자'],
        ['세부사항 절차에 집착한다.'],
        ['일을 잘한다.'],
        ['중간 보고가 없으면 불안하다.'],
        ['카리스마 있다.'],
        ['성급한 결정'],
        ['도표를 사랑한다.'],
        ['독단적 업무처리'],
        ['현실적이다.'],
        ['결단력, 자신감이 있다.'],
        ['목표에 대한 의지가 굳다.'],
        ['완벽주의'],
        ['책임감이 강하다.'],
        ['빈틈이 없다.'],
        ['지나친 권위'],
        ['체계 / 일정 / 과정 등 잘 조직화'],
        ['공감 좀 해달라는 이야기 들어봄.'],
        ['게으른 사람을 보면 이해가 안 된다.'],
        ['똑부러짐'],
        ['외로운 안탐'],
        ['모범시민'],
        ['예약을 좋아한다.'],
        ['명확하고 현실적인 문제에 집중한다.']]

ISFJ = [['섬세하다.'],
        ['주관 / 신념은 있으나 잘 드러내지 않음.'],
        ['봉사활동을 알아본 적이 있다.'],
        ['무서운 놀이기구를 못 탄다.'],
        ['아기자기한 것을 좋아한다.'],
        ['위계질서에 엄격하다.'],
        ['잘 참지만 선 넘으면 칼차단'],
        ['마음에 문을 여는데 시간이 걸림'],
        ['작지만 확실한 행복이 좋다.'],
        ['리더 / 관리자 자리 부탐스러움.'],
        ['탐미주의 성향'],
        ['예의가 바르다.'],
        ['자기 취향이 확실한 편'],
        ['눈치만 보다 끝나는 경우가 있다.'],
        ['속이 깊다'],
        ['이타주의자'],
        ['보수적인 편이다.'],
        ['계획을 세워도 계획이 현재에 머물러 있다.'],
        ['성실하다.'],
        ['서비스업 교육업에 관심이 있다.'],
        ['의뭉스러운 구석이 있다.'],
        ['객관적 비판이 불편하다.'],
        ['주변 사람들 기념일을 잘 챙긴다.'],
        ['화목한 분위기를 만든다.']]

ISTJ = [['분리수거 잘함'],
        ['보수적'],
        ['믿고 맡김 당한다.'],
        ['개근상 2개 이상 보유자'],
        ['빨리빨리 잘 못함'],
        ['말보다 결과물'],
        ['강한 책임감'],
        ['동선이 일정하다.'],
        ['이사 극혐'],
        ['참 피곤하게 산다는 소리를 들은 적 있다.'],
        ['첫째냐는 소리를 듣는다.'],
        ['시간약속 잘 지킴'],
        ['계량을 잘한다.'],
        ['츤데레'],
        ['무단횡단 이해 못함'],
        ['현재에 충실'],
        ['단골 식당 정해진 자리가 있다.'],
        ['표정 변화가 적다.'],
        ['사기 안 당함'],
        ['공사 구분이 철저하다.'],
        ['비전보다는 팩트'],
        ['아부 안 먹힘'],
        ['오래 근속하는 편이다.'],
        ['공무원 선호']]

ENFJ = [['붙임성이 좋다'],
        ['칭찬을 잘한다.'],
        ['비유를 잘 활용'],
        ['강한 책임감'],
        ['변화를 추구한다.'],
        ['감수성 충만'],
        ['도표를 싫어한다.'],
        ['대범하다'],
        ['타인이 가능성을 잘 본다.'],
        ['추진력 있음.'],
        ['타인의 눈치를 보는 편'],
        ['상상력이 풍부하다.'],
        ['해피 페이스'],
        ['오지랖 넓음'],
        ['카리스마'],
        ['성장과 가능성을 중시한다.'],
        ['종종 성급한 결정을 내린다.'],
        ['오그라드는 표현을 잘한다.'],
        ['열정적이다.'],
        ['책을 선물한 적 있음.'],
        ['세부사항을 간과하는 경향이 있다.'],
        ['집단을 중시한다.'],
        ['동정심이 많은 편'],
        ['세계평화를 꿈꾼다.']]

ENFP = [['창의력 특출남'],
        ['사람 / 상황에 통찰력 있음'],
        ['비슷한 사람 만나면 시너지가 폭발한다.'],
        ['새 사람, 아이디어에 민감'],
        ['남녀노소 누구나 친구'],
        ['공과사 구분이 어렵다.'],
        ['흥미가 지나치게 많음.'],
        ['표정이 밝다.'],
        ['적응력 융통성으로 성과를 냄'],
        ['타인과 공감을 통한 의사결정'],
        ['어린 아이같다.'],
        ['협조 / 지지에 능하다.'],
        ['주의 집중이 잘 안된다.'],
        ['세부사항 일상적인 것 고려 못함.'],
        ['마감 일자와 절차를 무시'],
        ['정리 좀 하라는 소리 들어봄'],
        ['기분파'],
        ['집에 우환이 있어도 나가면 즐겁다.'],
        ['언어표현 잘함'],
        ['사람 파악이 빠르다.'],
        ['먼저하고 다음에 보고한다.'],
        ['통신사 우수고객'],
        ['논리 / 분석에 약하다.'],
        ['고민은 사치라고 생각한다.']]

INFJ = [['관심사가 다양하다.'],
        ['말보다는 글쓰기'],
        ['쉽게 상처받는다.'],
        ['책임감이 강하다.'],
        ['논리성 / 실용성에 약하다.'],
        ['배려심이 깊다.'],
        ['개념적 은유적 표현을 선호'],
        ['종교에 관심이 있다.'],
        ['생각이 많다.'],
        ['상상 친구를 만든 적이 있다.'],
        ['촉이 좋다.'],
        ['인문 / 사회과학 선호'],
        ['종종 넌 너무 복잡해라는 말을 듣는다.'],
        ['이지적'],
        ['학구적 활동을 선호'],
        ['잘 들어준다.'],
        ['과한 공감능력'],
        ['감정과 동기를 잘 읽는다.'],
        ['실용성과 거리가 멀다.'],
        ['내면에 고립'],
        ['자신만의 가치관이 있다.'],
        ['좁고 깊은 관계망'],
        ['독특한 상상력'],
        ['겸손하다.']]

INFP = [['혼자 해결함'],
        ['귀찮음'],
        ['상상력 풍부'],
        ['용두사미'],
        ['개인적 가치 추구'],
        ['결정을 미룬다.'],
        ['온화함'],
        ['내적신념 뚜렷'],
        ['여유 중시'],
        ['선택장애'],
        ['속을 잘 안비친다.'],
        ['공감과 배려'],
        ['호기심이 많다.'],
        ['할 말은 많지만 하지 않는다.'],
        ['낯가림이 있다.'],
        ['이상주의자'],
        ['사람과 상황 사이에서 갈등한다.'],
        ['성장 추구'],
        ['분위기에 민감'],
        ['성취욕 대비 실행력 낮음'],
        ['상세 설명이 건너뜀'],
        ['호불호 명확'],
        ['단순반복 작업 불호'],
        ['포기하면 편해']]

-------------------------MBTI 3차 정제작업 저장---------------------------------
## 데이터 취합 작업
# 담당 : 고승한/양민승

# 고승한
# 내부 리스트 해제 코드
[j for i in ESFJ for j in i]
[j for i in ESTJ for j in i]
[j for i in ISFJ for j in i]
[j for i in ISTJ for j in i]
[j for i in ENFJ for j in i]
[j for i in ENFP for j in i]
[j for i in INFJ for j in i]
[j for i in INFP for j in i]

# 성향별 데이터프레임 생성
new_esfj = pd.DataFrame({'MBTI':'ESFJ','특성':[j for i in ESFJ for j in i]})
new_estj = pd.DataFrame({'MBTI':'ESTJ','특성':[j for i in ESTJ for j in i]})
new_isfj = pd.DataFrame({'MBTI':'ISFJ','특성':[j for i in ISFJ for j in i]})
new_istj = pd.DataFrame({'MBTI':'ISTJ','특성':[j for i in ISTJ for j in i]})
new_enfj = pd.DataFrame({'MBTI':'ENFJ','특성':[j for i in ENFJ for j in i]})
new_enfp = pd.DataFrame({'MBTI':'ENFP','특성':[j for i in ENFP for j in i]})
new_infj = pd.DataFrame({'MBTI':'INFJ','특성':[j for i in INFJ for j in i]})
new_infp = pd.DataFrame({'MBTI':'INFP','특성':[j for i in INFP for j in i]})

# concat으로 데이터프레임 결합.
keywords_mdti_df = pd.concat([new_esfj, new_estj, new_isfj, new_istj, new_enfj, new_enfp, new_infj, new_infp], ignore_index=True)

# 파일 추출.
keywords_mdti_df.to_csv('/Users/seunghanko/Downloads/keywords_mbti_df.csv')

# 양민승
# 각각의 MBTI 내용 중첩리스트 풀어주기
ISFP1 = [j for i in ISFP for j in i]
ESTP1 = [j for i in ESTP for j in i]
ESFP1 = [j for i in ESFP for j in i]
ISTP1 = [j for i in ISTP for j in i]
ENTJ1 = [j for i in ENTJ for j in i]
ENTP1 = [j for i in ENTP for j in i]
INTJ1 = [j for i in INTJ for j in i]
INTP1 = [j for i in INTP for j in i]

# 데이터 프레임화를 위한 라벨 및 내용 만들기
new_isfp = pd.DataFrame({'MBTI':'ISFP','특성':ISFP1})
new_estp = pd.DataFrame({'MBTI':'ESTP','특성':ESTP1})
new_esfp = pd.DataFrame({'MBTI':'ESFP','특성':ESFP1})
new_istp = pd.DataFrame({'MBTI':'ISTP','특성':ISTP1})
new_entj = pd.DataFrame({'MBTI':'ENTJ','특성':ENTJ1})
new_entp = pd.DataFrame({'MBTI':'ENTP','특성':ENTP1})
new_intj = pd.DataFrame({'MBTI':'INTJ','특성':INTJ1})
new_intp = pd.DataFrame({'MBTI':'INTP','특성':INTP1})

# 콘캣 메소드를 통한 mbti 데이터프레임 합치기
new_mbti = pd.concat([new_isfp,new_estp,new_esfp,new_istp,new_entj,new_entp,new_intj,new_intp],ignore_index=True)  
new_mbti   

# 총 갯수 일치하는지 확인
len(new_mbti) == len(new_isfp)+len(new_estp)+len(new_esfp)+len(new_istp)+len(new_entp)+len(new_entj)+len(new_intp)+len(new_intj)

# 고승한 자료 불러오기
new_df = pd.read_csv("c:/data/keywords_mbti_df.csv")

# 고승한/양민승 MBTI 요약 자료 받아 합치기 및 저장
mbti_b = pd.concat([new_mbti,new_df],ignore_index=True)
mbti_b.to_csv('c:/data/MBTI_c.csv',index=False)

-----------------------------자소서 웹크롤링------------------------------------

## 자소서 웹크롤링
# 담당 : 김준수/김동환
사용 사이트
김준수 - 잡코리아
김동환 - 캐치
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import pandas as pd
from pandas import Series, DataFrame
import pickle
import re
from urllib.request import urlopen
from bs4 import BeautifulSoup as bs
from urllib.error import URLError, HTTPError

# 김준수
url = 'https://www.jobkorea.co.kr/starter/passassay/' # 잡코리아
driver =  webdriver.Chrome('c:/data/chromedriver.exe')
driver.get(url)
driver.implicitly_wait(2)

inter = pd.DataFrame(columns = ['name','work','text'])
iu = []
for u in range(2,8): # 페이지 넘기는 반복문
    for i in range(1,21): # 자소서 번호 반복문
        try:
            driver.find_element(By.CSS_SELECTOR,'div.starListsWrap > ul.selfLists > li:nth-of-type('+str(i)+') > div.txBx > p.tit > a ').click() # 자소서 선택하는 코드
            time.sleep(5) # 대기 5초
            html = driver.page_source # 화면 스크린샷
            soup = bs(html,'html.parser') # 코드 정리
            name = soup.select_one('div.selfTopBx > div.viewTitWrap > h2.hd > strong').text.strip().replace('\n\n관심기업','') # 자소서 안의 회사명 
            work = soup.select_one('div.selfTopBx > div.viewTitWrap > h2.hd > em').text # 자소서 직무
            text = soup.select('dd.show > div.tx') # 자소서 내용
            inter = inter.append({'name':name,'work':work,'text':text},ignore_index = True) # 데이터 프레임화
            driver.back() # 뒤로가기
            time.sleep(5) # 대기 5초    
        except:
            iu.append(i) # 오류 코드 저장
            driver.back() # 뒤로가기
            
    driver.find_element(By.CSS_SELECTOR,'div.tplPagination > ul > li:nth-of-type('+str(u)+') > a').click() # 다음페이지 클릭
    time.sleep(5) # 대기 5초
    
inter.to_csv('c:/data/자소서.csv',index=False) # 자소서 저장

# 김동환
url = 'https://www.catch.co.kr/JobN/CoverLetter/Main' # 캐치
driver = webdriver.Chrome('c:/data/chromedriver.exe') # 크롬사이트에서 자동화로 작업하기 위한 함수(selenium)
driver.get(url) # url에 저장된 사이트로 이동

df = DataFrame(columns=['company','work','text']) # 회사명, 직종, 자소서를 추출해서 저장할 데이터프레임

# 캐치(사이트이름) 자소서 크롤링 100개
k = 0
while k < 2: # 1~10페이지 그다음 넘어가서 11~20페이지 까지 2번 반복하기위한 while문
    if k > 0 : # 10페이지까지 반복문이 돌고 k값이 1이되면 다음버튼 클릭
        driver.find_element(By.XPATH,'//*[@id="Contents"]/div/div[3]/div[2]/p/a[12]').click()
        time.sleep(3)
    for j in range(2,12): # 1페이지부터 10페이지까지 반복
        driver.find_element(By.XPATH,'//*[@id="Contents"]/div/div[3]/div[2]/p/a['+str(j)+']').click() # 페이지 번호 클릭
        time.sleep(4) 
        for i in range(1,6): # 페이지마다 5개 기업들이 있기에 하나씩 들어가서 추출하는 작업 반복
            driver.find_element(By.CSS_SELECTOR,'table.table8 > tbody > tr:nth-of-type('+str(i)+') >td.al1:nth-of-type(1) > p.t5 > a').click() # 기업명 클릭
            time.sleep(7)
            html = driver.page_source # 페이지의 html 소스를 가져오는 작업
            soup = BeautifulSoup(html,'html.parser') # 가져온 html을 pasing하는 작업
            com = soup.select_one('div.view > p.q').text # 회사명 텍스트만 추출
            work = soup.select_one('div.view > p.ctg2').text # 직종명 텍스트만 추출
            text = [i.text for i in soup.select('dl.passtip_qna > div > dd > p.txt')] # 자소서 추출 / 기업마다 여러개의 자소서가 있기때문에 여러 자소서를 한개의 리스트에 넣는 작업
            df = df.append({'company':com,'work':work,'text':text},ignore_index=True) # 추출한 데이터 데이터프레임에 저장
            driver.back() # 뒤로가기 함수
            time.sleep(7) # sleep을 주면서 사이트서버에서 의심하지 않도록 작업, 렉으로 사이트가 늦게 켜지는 현상도 있기 때문에 필요
    k += 1

# 여러 질문에 대한 자소서 하나로 합치는 작업
for i in range(0,100):
    df['text'][i] = ','.join(df['text'][i]) # 리스트로 저장된 자소서 데이터를 ','를 기준으로 하나의 텍스트(문자열)로 합치기(join)

# 저장 
df.to_csv('c:/data/final/자소서원본.csv',index=False) # 인덱스 추가 없이 csv파일로 저장

--------------------------------자소서 전처리-----------------------------------

## 자소서 전처리
# 담당 : 김준수/김동환

# 김준수
df = pd.read_csv('c:/data/자소서.csv')
df['text'][1]
df['text'] = df['text'].apply(lambda x : re.sub('\<.+?\>|[.\"\",\'\'-?]|글자수 자|·|“|”|/|‘|’',' ',x))
df['text'] = df['text'].apply(lambda x : re.sub('\[\]|\d+\w+|OOOOO|[A-z]+|\d+|#|\(.+?\)|%|①|②',' ',x))
df['text'] = df['text'].apply(lambda x : re.sub('\s{2,}',' ',x)).str.strip()
df.to_csv('c:/data/자소전.csv',index=False)

# 김동환
x = pd.read_csv('c:/data/final/자소서원본.csv')

# 전처리 작업
# x.text = x.text.apply(lambda x: re.sub('[.,"-%&/+>’‘▶:]|\(.+?\)|\<.+?\>|\'|■+|\[|\]',' ',x)) # 특수문자가 전부 필요없을 것 같음
x.text = x.text.apply(lambda x : re.sub('[^\w]+',' ',x)) # 특수문자 모두제거
x.text = x.text.apply(lambda x: re.sub('\d+|\d+\w+|[A-z]+',' ',x)) # 숫자, 숫자+글자, 영어 제거
x.text = x.text.apply(lambda x: re.sub('\s{2,}',' ',x)).str.strip() # 2칸이상 공백 한칸으로 변환, 앞뒤 공백제거
x.to_csv('c:/data/final/자소서전처리.csv',index=False)

------------------------------자소서 취합---------------------------------------

## 자소서 취합
# 담당 : 김준수/김동환
x = pd.read_csv('c:/data/자소서전처리.csv')
자소서_a = pd.concat([df,x],ignore_index=True)
자소서_a.to_csv('c:/data/자소전_a.csv',index=False)

--------------------------나이브베이즈 중간 점검---------------------------------

## 나이브베이즈 중간 점검
#담당 : 양민승/고승한/김준수

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from pandas import Series, DataFrame
import pandas as pd
from konlpy.tag import Okt

# 테스트 데이터 불러오기
mbti_c = pd.read_csv('c:/data/MBTI_c.csv')

# 필요한 명사/형용사 추출, 1글자 제외
okt = Okt()
def okt_pos(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0])
    token_corpus = [word for word in token_corpus if len(word) >= 2]
    return token_corpus

# 학습데이터
cv = CountVectorizer(tokenizer=okt_pos) # okt활용하여 명사/형용사만 사전으로 만들기
x_train = cv.fit_transform(mbti_c['특성']) # 학습데이터
cv.get_feature_names() # 정보 확인
x_train.toarray()
y_train = mbti_c['MBTI']

# 테스트데이터
tfidf = TfidfTransformer()
x_train = tfidf.fit_transform(x_train) # 위에서 fit작업이 완료되어 사전이 만들어져 있고 transform 작업만하면 됨

# 학습 모델
nb = MultinomialNB()
nb.fit(x_train,y_train)

# 사용한 데이터
x = '배우는 것을 좋아하고 성취하는 것을 좋아합니다.자신에게 문제가 있다면 피드백을 수용하는 사람입니다.때론 일에만 몰두하여 주변을 잊기도 하지만 좋은 사람들이 옆에서 도와주어 조금 더 신중하게 되었습니다.사람들과의 유대감과 협동을 중시하여 더 좋은 결과로 이끌어 내는 것을 잘합니다.공과 사의 구분이 철저합니다.(쉴 땐 쉬고 일할 땐 일하는 것이 제일 중요하다 생각합니다.)'
y = '대학교 수업 실습으로 3명이 팀을 이루어서 아이디어를 생각하고 구현하는 프로젝트였습니다.  팀이 만들어지고 저는 나서서 먼저 팀장역할을 맡는다고 하고 팀을 이끌어 갔습니다. 팀원들이 의견을 자유롭게 낼 수 있도록 환경을 조성하였고 저 또한 아이디어와 의견을 자유롭게 내며 팀원들의 이야기에 계속해서 귀 기울이고   맞추어 나가려고 노력하였습니다. 각자 UI, 기능, 데이터베이스, 서버, PPT, 발표 등 역할을 나누고 맡은 역할에 열심히 하여 좋은 결과를 도출해내 아쉽지만 만족스러운 결과물을 만들어냈습니다. 고등학교 문과를 졸업한 저에게 컴퓨터는 새롭고 두려운 존재였습니다. 첫 프로그래밍 언어로 java를 배웠습니다. 변수? 클래스? 이게 무슨 말인지 머리속에 복잡했고 내가 할 수 있을까 겁이 났지만 한 번 해보자 모르면 알 때까지 생각하고 찾아보고 연구하며 그러한 행동이 두려움을 감싸기 시작하면서 저는 두려움이 즐거움으로 변하기 시작했습니다. 그 기간이 짧지는 않았지만 해보자는 마음, 도전해보자는 마음가짐으로 다가갔습니다. 어떤 문제, 어려움이 닥치더라도 이겨낼 수 있는 자신감이 있는 사람이 되어 가고 있습니다. 지원하는 회사에 입사해서 큰 어려움을 마주하더라도 두려워하지 않고 다양한 방법으로 해결책을 찾으려고 노력하는 사람이 되겠습니다.'
z = '학과 학년 대표와 스터디그룹의 팀장을 역임하면서 학우 및 멤버들과의 분위기를 유쾌하게 가져갔고, 다양한 아르바이트 경험을 통해 동료들과 함께 유쾌한 분위기로 업무를 처리 했습니다. 또한, 새로운 공부나 환경에 대해서 스트레스를 덜 받고 유쾌하게 받아들여 적응력이 좋습니다. 귀사에 입사하게 된다면 어떤 어려운 업무나 팀 프로젝트가 있더라도 특유의 유쾌함을 살려 일을 해결할 수 있는 사람이 되겠습니다. 상대방과 의사소통 할 때 서로의 의견을 경청하며 부드럽게 말하되, 쓴 소리가 필요한 상황이 있으면 확실하게 하는 편입니다. 1학년 학과 집행부를 하면서 무조건 적인 부드러운 의사소통은 누구에게나 다 도움이 되질 않고 필요하면 쓴 소리도 해야한다는 것을 깨닫게 되었습니다. 복학한 후에 전공 수업 팀 프로젝트에서 팀장을 맡을 때 부드러운 의사소통을 바탕으로 하되 각자에 주어진 일을 제대로 하지 않는 팀원이 있으면 쓴 소리도 하고, 주말엔 팀원들을 모아 사적 모임을 가지고 친목 도모를 하며 프로젝트를 진행했고, 만족할만한 결과물과 동시에 좋은 성적을 받아냈습니다. 또한, 당사자 및 주변인들과의 대화를 통해 내가 잔소리나 쓴 소리를 하며 과했던 부분이 있는지 피드백을 합니다.'
c = '제 관점에서의 장점은 한번 맡은 일은 끝까지 책임지는 "책임감"입니다. 한 번도 써본 적 없는 프로그래밍 언어를 이용한 개발 업무를 맡은 경험이 있습니다. 신규 솔루션으로, 주변에 물어볼 곳도 마땅치 않았기 때문에 특이사항이 생겼을 때 수시로 보고하면서, 제 손으로 끝마칠 수 있었습니다. 타인의 관점에서의 장점은 인상이 부드럽다는 것입니다. 어릴 적부터 최근까지, 저와 알게 된 사람은 제게는 말을 거는 게 참 편하다는 이야기를 끊임없이 들었습니다. 제 관점에서의 단점은 결정할 때, 망설이는 경우가 있습니다. 이 부분은 개인적인 일이면 일단 하는 방향으로, 회사 일과 관련된 일이면 상사에 보고, 혹은 조언을 구하는 방향으로 단점을 보완하고 있습니다. 타인의 관점에서는 일을 할 때 혼자 너무 끙끙대지 말라는 이야기를 들은 적이 있습니다. 이는 시간을 정해놓고 혼자 고민하되, 해결이 안되면 보고 후 조언을 구하는 방식으로 개선하고 있습니다.'

# 예측
x_test = cv.transform(pd.Series(x))
x_test_tfidf = tfidf.transform(x_test)
nb.fit(x_train, y_train).predict(x_test_tfidf)

x_test1 = cv.transform(pd.Series(y))
x_test_tfidf = tfidf.transform(x_test1)
nb.fit(x_train, y_train).predict(x_test_tfidf)

x_test2 = cv.transform(pd.Series(z))
x_test_tfidf = tfidf.transform(x_test2)
nb.fit(x_train, y_train).predict(x_test_tfidf)

x_test3 = cv.transform(pd.Series(c))
x_test_tfidf = tfidf.transform(x_test3)
nb.fit(x_train, y_train).predict(x_test_tfidf)

# 확인
cv.inverse_transform(x_test)
nb.predict(x_test)

cv.inverse_transform(x_test1)
nb.predict(x_test)

cv.inverse_transform(x_test2)
nb.predict(x_test)

cv.inverse_transform(x_test3)
nb.predict(x_test)

---------------------------자소서 직업 분류 작업--------------------------------

## 자소서 직업 분류 작업
# 담당 : 김동환/김준수
import pandas as pd
from collections import Counter
import re

# 파일 읽어오기
ja = pd.read_csv('c:/data/final/자소전_a.csv')

# 업무 종류 확인
Counter(ja.work)
# ja[ja.work.apply(lambda x: re.sub('2021년 하반기 신입 전기·전자·제어','기술',x)) =='기술'] 업무명 변경되는 것 확인

# 업무 통일 작업에 필요없는 단어,문자들 제거
ja.work = ja.work.apply(lambda x: re.sub('''2021년 하반기 신입 |2021년 상반기 신입 |2021년 하반기 인턴 |2021년 상반기 인턴 |
                               2020년 하반기 신입 |2020년 상반기 신입 |2020년 하반기 인턴 |2020년 상반기 인턴 |
                               2022년 하반기 신입 |2022년 상반기 신입 |2022년 하반기 인턴 |2022년 상반기 인턴 |2019년 하반기 인턴 |2020년 하반기 신입 ''','',x))
ja.work = ja.work.apply(lambda x:re.sub(' \(.+\)','',x))

''' 업무 종류 확인
ja.work.apply(lambda x: re.sub('전기·전자·제어','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('재무·세무·IR','사무',x)) #
ja.work.apply(lambda x: re.sub('연구소·R&D','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('기획·전략·경영','사무',x)) #
ja.work.apply(lambda x: re.sub('시설·보안·경비·안전','경비',x)) #
ja.work.apply(lambda x: re.sub('전기·소방·통신·안전','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('사무·총무·법무','사무',x)) #
ja.work.apply(lambda x: re.sub('전시·공간디자인','디자인',x)) #
ja.work.apply(lambda x: re.sub('CS관리·강의','CS',x)) #
ja.work.apply(lambda x: re.sub('설치·정비·A/S','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('마케팅·광고·분석','마케팅',x)) #
ja.work.apply(lambda x: re.sub('바이오·제약·식품','연구개발',x)) #
ja.work.apply(lambda x: re.sub('ERP·시스템분석·설계','소프트웨어',x)) #
ja.work.apply(lambda x: re.sub('생산관리·공정관리·품질관리','생산',x)) #
ja.work.apply(lambda x: re.sub('영업관리·지원·영업기획','영업',x)) #
ja.work.apply(lambda x: re.sub('고객상담·인바운드','CS',x)) #
ja.work.apply(lambda x: re.sub('노무·헤드헌터·직업상담','사무',x)) #
ja.work.apply(lambda x: re.sub('자동차·조선·기계','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('기계설계·CAD·CAM','사무',x)) #
ja.work.apply(lambda x: re.sub('생산·제조·설비·조립','생산',x)) #
ja.work.apply(lambda x: re.sub('반도체·디스플레이','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('디자인기타','디자인',x)) #
ja.work.apply(lambda x: re.sub('시공·현장·감리·공무','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('영상·사진·촬영','디자인',x)) #
ja.work.apply(lambda x: re.sub('사무·원무·코디','사무',x)) #
ja.work.apply(lambda x: re.sub('화학·에너지·환경','연구개발',x)) #
ja.work.apply(lambda x: re.sub('건축·설계·인테리어','건축',x)) #
ja.work.apply(lambda x: re.sub('웹기획·PM','사무',x)) #
ja.work.apply(lambda x: re.sub('IT/인터넷','소프트웨어',x)) #
ja.work.apply(lambda x: re.sub('마케팅/광고/홍보','마케팅',x)) #
ja.work.apply(lambda x: re.sub('무역/유통','유통',x)) #
ja.work.apply(lambda x: re.sub('생산/제조','생산',x)) #
ja.work.apply(lambda x: re.sub('연구개발/설계','하드웨어',x)) #
ja.work.apply(lambda x: re.sub('영업/고객상담','영업',x)) #
ja.work.apply(lambda x: re.sub('경영/사무','사무',x)) #
ja.work.apply(lambda x: re.sub('건설','생산',x)) # 
'''

# 분할된 업무종류 12가지로 통일(하드웨어, 사무, 디자인, CS, 경비, 마케팅, 소프트웨어, 생산, 연구개발, 영업, 무역, 건축)
for i in range(0,len(ja.work)):
    
    if ja.work[i] in ['전기·전자·제어','연구소·R&D','전기·소방·통신·안전','설치·정비·A/S','자동차·조선·기계','반도체·디스플레이',
                      '시공·현장·감리·공무','연구개발/설계']:
        ja.work[i] = '하드웨어'
        
    elif ja.work[i] in ['재무·세무·IR','기획·전략·경영','사무·총무·법무','노무·헤드헌터·직업상담','기계설계·CAD·CAM','사무·원무·코디',
                        '웹기획·PM','경영/사무']:
        ja.work[i] = '사무'
        
    elif ja.work[i] in ['전시·공간디자인','디자인기타','영상·사진·촬영']:
        ja.work[i] = '디자인'
    
    elif ja.work[i] in ['CS관리·강의','고객상담·인바운드']:
        ja.work[i] = 'CS'
    
    elif ja.work[i] in ['시설·보안·경비·안전']:
        ja.work[i] = '경비'
    
    elif ja.work[i] in ['마케팅·광고·분석','마케팅/광고/홍보']:
        ja.work[i] = '마케팅'
    
    elif ja.work[i] in ['ERP·시스템분석·설계','IT/인터넷']:
        ja.work[i] = '소프트웨어'
    
    elif ja.work[i] in ['생산관리·공정관리·품질관리','생산·제조·설비·조립','생산/제조']:
        ja.work[i] = '생산'
    
    elif ja.work[i] in ['바이오·제약·식품','화학·에너지·환경']:
        ja.work[i] = '연구개발'
        
    elif ja.work[i] in ['영업관리·지원·영업기획','영업/고객상담']:
        ja.work[i] = '영업'
        
    elif ja.work[i] in ['무역/유통']:
        ja.work[i] = '무역'
    
    elif ja.work[i] in ['건축·설계·인테리어', '건설']:
        ja.work[i] = '건축'
        
# 수정작업 완료 / csv파일로 저장
ja.to_csv('c:/data/final/자소전_b.csv',index=False)

---------------------------MBTI 키워드 웹크롤링 재 작업-------------------------

## MBTI 키워드 웹크롤링 재 작업
# 담당 : 김준수/김동환
import pandas as pd
from pandas import Series, DataFrame
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup as bs
import re

사용한 사이트
 - 'https://blog.naver.com/dongduk_w_univ/222615414405'
 - 'https://blog.naver.com/PostView.naver?blogId=dongduk_w_univ&logNo=222614721850&categoryNo=16&parentCategoryNo=&from=thumbnailList'
 
# 동덕여대 I파트 웹크롤링
url = 'https://blog.naver.com/dongduk_w_univ/222615414405' # i 
driver = webdriver.Chrome('c:/data/chromedriver.exe')
driver.get(url)

# 브라우저에는 보이는데 엘레먼트를 찾을 수 없다는 내용만 나올 때
- iframe이라는 테그가 있는지 확인 : html안에 다른 html이 있다고 생각하면 된다.
- iframe 안에 html코드를 보려면 프레임 이동을 시켜줘야함
- 작업 끝나면 빠져나오기 

# 프레임 id 가져오기
element = driver.find_element_by_id('mainFrame')

# 프레임 id를 이용하여 프레임 안으로 이동(프레임 안으로 이동하면 안에 있는 테그들에 접근할 수 있다.)
driver.switch_to.frame(element) 

# MBTI 추출
driver.find_element(By.CSS_SELECTOR,'div#body > div#whole-border > div#whole-body > div#wrapper > div#twocols > div#content-area > div#post-area > div#postListBody > div#post_1 > div.post-back > table.post-body > tbody > tr > td.bcc > div.wrap_rabbit >div.se-viewer > div.se-main-container > div.se-component.se-text').text

jaso = []
for i in driver.find_elements(By.CSS_SELECTOR,'div.se-main-container > div.se-component.se-text'):
    for j in i.find_elements(By.CSS_SELECTOR,'div > div > div >p'):
        jaso.append(j.text.strip())

# MBTI 전처리
jaso = jaso[21:] # 앞 필요없는 인덱스 제외
jaso = jaso[:-13] # 뒤 필요없는 인덱스 제외

jaso = Series(jaso).apply(lambda x : re.sub(' [A-Z]{4} [가-힣]{2}\W ','',x)) # INFP 장점👍 : 이런 형식 제거
jaso = jaso.apply(lambda x : re.sub('∨[가-힣]{3} ∨[가-힣]{3,4} ∨[가-힣]{3}','',x)) #  ∨감수성 ∨공감능력 ∨호기심 : 형식 제거

jaso_p = []
for i in range(len(jaso)): # 공백인 데이터 제외
    if (jaso[i]=='') == False:
        jaso_p.append(jaso[i])

mbti = Series(jaso_p).apply(lambda x : re.search('[A-Z]{4}',x)) # mbti위의 값을 제거하기 위해서 작성된 코드 # 정규표현식과 일치하면 출력 아니면 None 출력
j = 1
for i in mbti[mbti.isnull() ==False].index: 
    del jaso_p[i-j] # 하나씩 제거할 때마다 데이터가 리스트가 하나씩 줄어들기 때문에  j값을 1씩 더 증가 시킴
    j += 1

jaso_p=Series(jaso_p).apply(lambda x : re.sub('ISTP','<ISTP>',x)) # ISTP만 꺾새 없어서 넣어줌
jaso_p2 = ' '.join(jaso_p).split('<') # 전체를 합쳐서 MBTI별로 나누기

# 데이터 프레임으로 만들기
df = DataFrame(columns=['mbti','text'])
for i in jaso_p2:
    m = ''
    for j in range(len(i.split('-')[1:])):
        m = i.split('-')[0] # mbti
        df = df.append({'mbti':m,'text':i.split('-')[j+1]},ignore_index=True) 
        
df = df.iloc[1:] # 1행 제외
df.mbti = df.mbti.apply(lambda x : re.sub('>','',x).strip()) # mbti 전처리
df.text = df.text.apply(lambda x : x.strip()) # 앞뒤 공백 제거

# 데이터 저장
df.to_csv('c:/data/자소서동덕여대i.csv') # 데이터 저장

# 프레임 빠져나오기(처음 상태로 이동)
driver.switch_to.default_content()

-----------------------------동덕여대 E파트 웹크롤링----------------------------

## 동덕여대 E파트 웹크롤링
url = 'https://blog.naver.com/PostView.naver?blogId=dongduk_w_univ&logNo=222614721850&categoryNo=16&parentCategoryNo=&from=thumbnailList' # e
driver = webdriver.Chrome('c:/data/chromedriver.exe')
driver.get(url)

# MBTI 스크랩
jaso = []
for i in driver.find_elements(By.CSS_SELECTOR,'div.se-main-container > div.se-component.se-text'):
    for j in i.find_elements(By.CSS_SELECTOR,'div > div > div >p'):
        jaso.append(j.text)

# MBTI 전처리
jaso = jaso[20:] # 앞 필요없는 인덱스 제외
jaso = jaso[:-12] # 뒤 필요없는 인덱스 제외

jaso = Series(jaso).apply(lambda x : re.sub(' [A-Z]{4} [가-힣]{2}\W ','',x)) # INFP 장점👍 : 이런 형식 제거
jaso = jaso.apply(lambda x : re.sub('∨[가-힣]{3} ∨[가-힣]{3,4} ∨[가-힣]{3}','',x)) #  ∨감수성 ∨공감능력 ∨호기심 : 형식 제거

jaso_p = []
for i in range(len(jaso)): # 공백인 데이터 제외
    if (jaso[i]=='') == False:
        jaso_p.append(jaso[i])

mbti = Series(jaso_p).apply(lambda x : re.search('[A-Z]{4}',x)) # mbti위의 값을 제거하기 위해서 작성된 코드 # 정규표현식과 일치하면 출력 아니면 None 출력
j = 1
for i in mbti[mbti.isnull() ==False].index: 
    del jaso_p[i-j] # 하나씩 제거할 때마다 데이터가 리스트가 하나씩 줄어들기 때문에  j값을 1씩 더 증가 시킴
    j += 1

jaso_p2 = ' '.join(jaso_p).split('<') # 전체를 합쳐서 MBTI별로 나누기

# 데이터 프레임으로 만들기
df2 = DataFrame(columns=['mbti','text'])
for i in jaso_p2:
    m = ''
    for j in range(len(i.split('-')[1:])):
        m = i.split('-')[0] # mbti
        df2 = df2.append({'mbti':m,'text':i.split('-')[j+1]},ignore_index=True) 
        
df2.mbti = df2.mbti.apply(lambda x : re.sub('>','',x)) # mbti 전처리
df2.mbti = df2.mbti.apply(lambda x : re.sub('∨호탕함 ∨열정 ∨빠른추진력 ','',x).strip()) # mbti 전처리
df2.text = df2.text.apply(lambda x : x.strip()) # text 앞뒤 공백제거

df2.to_csv('c:/data/자소서동덕여대e.csv')

----------------------------데이터 취합 및 저장---------------------------------

## 데이터 취합
# 담당 : 김준수/김동환
# i, e 합치기
jaso_df = pd.concat([df,df2],axis=0)

# 파일 저장    
jaso_df.to_csv('c:/data/MBTI_e.csv') 

---------------------------나이브 베이즈 최종 코드------------------------------

## 나이브 베이즈 최종 코드
# 담당 : 김준수/고승한
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from konlpy.tag import Okt
# 테스트 데이터 불러오기
mbti_c = pd.read_csv('c:/data/MBTI_g.csv') # MBTI_f 파일은 엑셀에서 튜닝 데이터로 코드 없음
my = pd.read_csv('c:/data/자소전_b')

# 필요한 명사/형용사 추출, 1글자 제외
okt = Okt()
def okt_pos(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0]+'/'+i[1]) # 형태소 합치기
    token_corpus = [word for word in token_corpus if len(word.split('/')[0]) >= 2]
    return token_corpus

# 학습데이터
cv = CountVectorizer(tokenizer=okt_pos) # okt활용하여 명사/형용사만 사전으로 만들기
x_train = cv.fit_transform(mbti_e['특성']) # 학습데이터
cv.get_feature_names() # 정보 확인
x_train.toarray()
y_train = mbti_e['MBTI']


tfidf = TfidfTransformer()
x_train = tfidf.fit_transform(x_train) # 위에서 fit작업이 완료되어 사전이 만들어져 있고 transform 작업만하면 됨

# 학습 모델
nb = MultinomialNB()

# 예측
a = []
for i in range(0,len(my['text'])):
    x_test = cv.transform(pd.Series(my['text'][i]))
    x_test_tfidf = tfidf.transform(x_test)
    a.append(nb.fit(x_train_tfidf, y_train).predict(x_test_tfidf))

----------------------나이브베이즈 MBTI 예측 데이터 시각화-----------------------

## 나이브베이즈 시각화 데이터 작업
# 담당 : 고승한
from io import StringIO # 프린트한 값을 다른 변수에 저장하기 위함.
import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from konlpy.tag import Okt
from pandas import Series, DataFrame
import pandas as pd
# 고승한
# 데이터 불러오기
jasoseol = pd.read_csv('c:/data/자소전_b.csv')
mbti_es = pd.read_csv('c:/data/MBTI_g.csv')

# 나이브 베이즈 코드
okt = Okt()
def okt_word(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0]+'/'+i[1])
    token_corpus = [word for word in token_corpus if len(word.split('/')[0]) >= 2]
    return token_corpus

# 학습 데이터 만들기
cv = CountVectorizer(tokenizer=okt_word)
x_train = cv.fit_transform(mbti_es['특성'])
y_train = mbti_es['MBTI']

tfidf = TfidfTransformer()
x_train_tfidf = tfidf.fit_transform(x_train)

# 예측
nb = MultinomialNB()
a = []
for i in range(0,len(jasoseol['text'])):
    x_test = cv.transform(pd.Series(jasoseol['text'][i]))
    x_test_tfidf = tfidf.transform(x_test)
    io = StringIO()
    print(nb.fit(x_train_tfidf, y_train).predict(x_test_tfidf), file=io, end="")
    new_value = re.sub("[\'|\[|\]]","",io.getvalue())
    a.append(new_value)


# mbti 예측 결과를 mbti 컬럼으로 저장하여 카운트 후 new_jasoseol 데이터프레임 생성.
jasoseol['mbti'] = a
new_jasoseol = jasoseol['mbti'].value_counts()
new_jasoseol = new_jasoseol.reset_index()
new_jasoseol.columns = ['mbti','cnt']
new_jasoseol

--------------------------MBTI 예측 bar chart 출력------------------------------

## MBTI 예측 bar chart 출력.
# 담당 : 고승한
import seaborn as sns
ax = sns.barplot(x='mbti' , y='cnt', data = new_jasoseol)

# 각 막대 수치 표시 및 위치 조정
for idx,value in enumerate(ax.patches):
    height = value.get_height() - 1
    if idx == 0 :
        height -= 2 # 인덱스가 0일 때만 출력 위치 추가로 - 2
    ax.annotate("%.0f" % value.get_height(), (value.get_x() + value.get_width()/2., height), 
       ha='center', va='center', fontsize=12, color='black', xytext=(0, 14), 
       textcoords='offset points')

---------------------------MBTI 직무별 데이터 작업------------------------------

## MBTI 직무별 데이터 작업
# 담당 : 고승한
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import font_manager,rc
font_name = font_manager.FontProperties(fname = "C:/Windows/Fonts/GAESUNG.TTF").get_name() # 폰트 지정
rc('font',family = font_name)
# 고승한
# 성격 앞 두자리만 추출 ex)ESTP -> ES
jasoseol['new_mbti'] = jasoseol['mbti'].apply(lambda x : x[0:2])

# 성격 유형별 / 직무별 카운트 구함.
cnt_per_job = jasoseol.groupby(['new_mbti','work'])['mbti'].count() # 그룹
cnt_per_job = cnt_per_job.reset_index() # 인덱스 초기화
color = sns.color_palette('pastel') # 그래프 색상

# mbti 앞 두자리에 따라 데이터프레임 분할.
mbti_in = cnt_per_job[cnt_per_job['new_mbti'] == 'IN']
mbti_is = cnt_per_job[cnt_per_job['new_mbti'] == 'IS']
mbti_en = cnt_per_job[cnt_per_job['new_mbti'] == 'EN']
mbti_es = cnt_per_job[cnt_per_job['new_mbti'] == 'ES']

-----------------------------MBTI직무별 원그래프--------------------------------

## MBTI직무별 원그래프 각각 따로 출력
# 담당 : 고승한
plt.figure(figsize = (10,10))
plt.pie(mbti_in.mbti, colors = color, labels=mbti_in.work, autopct = '%.1f%%') # in
plt.legend()

plt.figure(figsize = (10,10))
plt.pie(mbti_is.mbti, colors = color, labels=mbti_is.work, autopct = '%.1f%%') # is
plt.legend()

plt.figure(figsize = (10,10))
plt.pie(mbti_en.mbti, colors = color, labels=mbti_en.work, autopct = '%.1f%%') # en
plt.legend()

plt.figure(figsize = (10,10))
plt.pie(mbti_es.mbti, colors = color, labels=mbti_es.work, autopct = '%.1f%%') # es
plt.legend(loc = "upper left")

------------------------------MBTI I/E 정제작업---------------------------------

# 담당 : 양민승
mbti_es = pd.read_csv("c:/data/mbti_g.csv")
jasosu = pd.read_csv("c:/data/자소전_b.csv")

okt = Okt()
def okt_word(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0]+'/'+i[1])
    token_corpus = [word for word in token_corpus if len(word.split('/')[0]) >= 2]
    return token_corpus

# 학습데이터
cv = CountVectorizer(tokenizer=okt_word)
x_train = cv.fit_transform(mbti_es['특성'])
y_train = mbti_es['MBTI']

tfidf = TfidfTransformer()
x_train_tfidf = tfidf.fit_transform(x_train)
y_train
# 예측
nb = MultinomialNB()
a = []
for i in range(0,len(jasosu['text'])):
    x_test = cv.transform(pd.Series(jasosu['text'][i]))
    x_test_tfidf = tfidf.transform(x_test)
    io = StringIO()
    print(nb.fit(x_train_tfidf, y_train).predict(x_test_tfidf), file=io, end="")
    new_value = re.sub("[\'|\[|\]]","",io.getvalue())
    a.append(new_value)

jasosu['mbti'] =  a # 예측 데이터 데이터 프렘임 적용
jasosu['mbti'].value_counts()


# mbti중 I로 시작하는 것들의 자소서 뽑기
i_text = jasosu.loc[jasosu.mbti.str.startswith('I') == True,['text','mbti']]
# mbti중 E로 시작하는 것들의 자소서 뽑기
e_text = jasosu.loc[jasosu.mbti.str.startswith('E') == True,['text','mbti']]

# 인덱스 번호 정렬
i_text.reset_index(drop=True,inplace=True)
e_text.reset_index(drop=True,inplace=True)

# 자소서 I 톡큰화
token_text_i = DataFrame(columns=['text','mbti']) 
for i in range(0,len(i_text['text'])):
    x_test = cv.transform(pd.Series(i_text['text'][i]))
    i_token = []
    for u in range(0,len(cv.inverse_transform(x_test)[0])):
        i_token.append(cv.inverse_transform(x_test)[0][u])
    token_text_i = token_text_i.append({'text':i_token,'mbti':i_text['mbti'][i]},ignore_index=True)
 
token_text_i
len(cv.inverse_transform(x_test)[0])

# 자소서 E 톡큰화
token_text_e = DataFrame(columns=['text','mbti'])

for i in range(0,len(e_text['text'])):
    x_test = cv.transform(pd.Series(e_text['text'][i]))
    e_token = []
    for u in range(0,len(cv.inverse_transform(x_test)[0])):
        e_token.append(cv.inverse_transform(x_test)[0][u])
    token_text_e = token_text_e.append({'text':e_token,'mbti':e_text['mbti'][i]},ignore_index=True)

# 훈련데이터(mbti 특성)을 I랑 E로 나누기
i_mbti = mbti_es.loc[mbti_es.MBTI.str.startswith('I') == True,['특성','MBTI']]
e_mbti = mbti_es.loc[mbti_es.MBTI.str.startswith('E') == True,['특성','MBTI']]

# 인덱스 번호 정렬
i_mbti.reset_index(drop=True,inplace=True)
e_mbti.reset_index(drop=True,inplace=True)

# i와 e에 있는 mbti 특성들을 각각의 특성들끼리 합치기(okt_word 단어 분류 비교 위함)
isfp = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'ISFP','특성']) # ISFP
infp = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'INFP','특성']) # INFP
isfj = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'ISFJ','특성']) # ISFJ
infj = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'INFJ','특성']) # INFJ
istj = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'ISTJ','특성']) # ISTJ
istp = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'ISTP','특성']) # ISTP
intp = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'INTP','특성']) # INTP
intj = '. '.join(i_mbti.loc[i_mbti['MBTI'] == 'INTJ','특성']) # INTJ

enfp = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ENFP','특성']) # ENFP
enfj = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ENFJ','특성']) # ENFJ
entp = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ENTP','특성']) # ENTP
entj = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ENTJ','특성']) # ENTJ
esfp = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ESFP','특성']) # ESFP
esfj = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ESFJ','특성']) # ESFJ
estp = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ESTP','특성']) # ESTP
estj = '. '.join(e_mbti.loc[e_mbti['MBTI'] == 'ESTJ','특성']) # ESTJ

-------------------------------I/E DataFrame-----------------------------------

## 데이터프레임으로 만들기
# 담당 : 양민승

i_teuk = DataFrame(columns=['MBTI','특성'])
e_teuk = DataFrame(columns=['MBTI','특성'])

i_teuk = i_teuk.append({'특성':isfp,'MBTI':'ISFP'},ignore_index=True)
i_teuk = i_teuk.append({'특성':infp,'MBTI':'INFP'},ignore_index=True)
i_teuk = i_teuk.append({'특성':isfj,'MBTI':'ISFJ'},ignore_index=True)
i_teuk = i_teuk.append({'특성':infj,'MBTI':'INFJ'},ignore_index=True)
i_teuk = i_teuk.append({'특성':istj,'MBTI':'ISTJ'},ignore_index=True)
i_teuk = i_teuk.append({'특성':istp,'MBTI':'ISTP'},ignore_index=True)
i_teuk = i_teuk.append({'특성':intp,'MBTI':'INTP'},ignore_index=True)
i_teuk = i_teuk.append({'특성':intj,'MBTI':'INTJ'},ignore_index=True)

e_teuk = e_teuk.append({'특성':enfp,'MBTI':'ENFP'},ignore_index=True)
e_teuk = e_teuk.append({'특성':enfj,'MBTI':'ENFJ'},ignore_index=True)
e_teuk = e_teuk.append({'특성':entp,'MBTI':'ENTP'},ignore_index=True)
e_teuk = e_teuk.append({'특성':entj,'MBTI':'ENTJ'},ignore_index=True)
e_teuk = e_teuk.append({'특성':esfp,'MBTI':'ESFP'},ignore_index=True)
e_teuk = e_teuk.append({'특성':esfj,'MBTI':'ESFJ'},ignore_index=True)
e_teuk = e_teuk.append({'특성':estp,'MBTI':'ESTP'},ignore_index=True)
e_teuk = e_teuk.append({'특성':estj,'MBTI':'ESTJ'},ignore_index=True)

------------------------------I/E 토큰화---------------------------------------

# 담당 : 양민승
# I~ 특성 토큰화한거 보여주기
token_teuk_i = DataFrame(columns=['특성','mbti'])

for i in range(0,len(i_teuk['특성'])):
    x_test = cv.transform(pd.Series(i_teuk['특성'][i]))
    i_token_t = []
    for u in range(0,len(cv.inverse_transform(x_test)[0])):
        i_token_t.append(cv.inverse_transform(x_test)[0][u])
    token_teuk_i = token_teuk_i.append({'특성':i_token_t,'mbti':i_teuk['MBTI'][i]},ignore_index=True)
token_teuk_i

# E~ 특성 토큰화한거 보여주기
token_teuk_e = DataFrame(columns=['특성','mbti'])

for i in range(0,len(e_teuk['특성'])):
    x_test = cv.transform(pd.Series(e_teuk['특성'][i]))
    e_token_t = []
    for u in range(0,len(cv.inverse_transform(x_test)[0])):
        e_token_t.append(cv.inverse_transform(x_test)[0][u])
    token_teuk_e = token_teuk_e.append({'특성':e_token_t,'mbti':e_teuk['MBTI'][i]},ignore_index=True)
token_teuk_e

token_text_i.mbti.unique()
token_teuk_i.mbti.unique()

pd_i = pd.merge(token_text_i,token_teuk_i,on='mbti') # I 자소서/MBTI 특성 합치기
pd_e = pd.merge(token_text_e,token_teuk_e,on='mbti') # E 자소서/MBTI 특성 합치기

# 특성과 자소서 내용들 토큰화한것 중 일치하는 것 데이터 프레임
# I
i_same = DataFrame(columns=['token','mbti'])
for v in range(0,len(pd_i.mbti)):
    i_same_token = []
    token = ''
    for u in range(0,len(pd_i.특성[v])):
        if (pd_i.특성[v][u] in pd_i.text[v]) == True:
            token = pd_i.특성[v][u]
            i_same_token.append(token)
        else:
            print('일치하지 않음')
    i_same = i_same.append({'token':i_same_token,'mbti':pd_i.mbti[v]},ignore_index=True)
i_same        

# E
e_same = DataFrame(columns=['token','mbti'])

for v in range(0,len(pd_e.mbti)):
    e_same_token = []
    token = ''
    for u in range(0,len(pd_e.특성[v])):
        if (pd_e.특성[v][u] in pd_e.text[v]) == True:
            token = pd_e.특성[v][u]
            e_same_token.append(token)
        else:
            print('일치하지 않음')
    e_same = e_same.append({'token':e_same_token,'mbti':pd_e.mbti[v]},ignore_index=True) 
e_same

# Counter 작업을 위한 데이터 화
from collections import Counter

e_tok = []
for u in range(0,len(e_same.token)):
    tok = ''
    for i in range(0,len(e_same.token[u])):
        tok = e_same.token[u][i]
        e_tok.append(tok)     
e_tok

i_tok = []
for u in range(0,len(i_same.token)):
    tok = ''
    for i in range(0,len(i_same.token[u])):
        tok = i_same.token[u][i]
        i_tok.append(tok)    
i_tok

# 일치하는 토큰 상위 갯수 20개씩 뽑기        
e_tok20 = Counter(e_tok).most_common(20)
i_tok20 = Counter(i_tok).most_common(20)

# 튜플에서 추출후 시각화를 위한 데이터프레임화
e_20_df = DataFrame(columns=['token','cnt'])
for i in range(0,len(e_tok20)):
    tok = e_tok20[i][0]
    cnt = e_tok20[i][1]
    e_20_df = e_20_df.append({'token':tok,'cnt':cnt},ignore_index=True)
e_20_df

i_20_df = DataFrame(columns=['token','cnt'])
for i in range(0,len(i_tok20)):
    tok = i_tok20[i][0]
    cnt = i_tok20[i][1]
    i_20_df = i_20_df.append({'token':tok,'cnt':cnt},ignore_index=True)
i_20_df

# 각각에서 불필요한 단어를 제외한 핵심단어들 추출
e_10_df = e_20_df.drop([0,1,4,7,8,10,11,13,16,17])
e_10_df.reset_index(drop=True,inplace=True)
e_10_df

i_10_df = i_20_df.drop([6,7,15,14,16,17,18,19,3,12])
i_10_df.reset_index(drop=True,inplace=True)
i_10_df

-----------------------나이브베이즈 E/I 단어 시각화-----------------------------

## E와 I 비교 시각화
# 담당 : 양민승/고승한
import seaborn as sns
import matplotlib.pylab as plt
from matplotlib import font_manager, rc
font_name = font_manager.FontProperties(fname="C:/Windows/Fonts/GAESUNG.TTF").get_name()
rc('font',family=font_name)

# 색깔 팔레트 만들기
palette3 = sns.color_palette('coolwarm',10)
sns.palplot(palette3)

# 막대그래프로 시각화
plt.xticks(rotation=45)
ax = sns.barplot(x='token',y='cnt', data=i_10_df, palette=palette3) # i

# 각 막대 수치 표시 및 위치 조정
for p in ax.patches: 
    ax.annotate("%.0f" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 3), 
       ha='center', va='center', fontsize=12, color='black', xytext=(0, 8), 
       textcoords='offset points')
    
ax.set(title = 'I(내향형)')

plt.xticks(rotation=45)
ax = sns.barplot(x='token',y='cnt', data=e_10_df, palette=palette3) # e

# 각 막대 수치 표시 및 위치 조정
for p in ax.patches: 
    ax.annotate("%.0f" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 5), 
       ha='center', va='center', fontsize=12, color='black', xytext=(0, 8), 
       textcoords='offset points') 
    
ax.set(title = 'E(외향형)')

------------------------------주말/평일 웹크롤링--------------------------------

## 항공편 웹크롤링(사용시 크롤링 부분들 수정 요망)
# 양민승
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import re
import pickle
from bs4 import BeautifulSoup
from selenium.webdriver.common.keys import Keys
from pandas import Series, DataFrame
import pandas as pd
import time

# mbti별 여행지 참고 자료(https://29street.donga.com/article/all/67/2512426/1)
# 인터파크
# 유럽
# selenium을 통한 url불러오기
url = "http://www.interpark.com/malls/index.html?gateTp=1"
driver = webdriver.Chrome("c:/data/chromedriver.exe")
driver.get(url)

# 항공 클릭하기
driver.find_element(By.XPATH,'//*[@id="container"]/div[5]/div/div[2]/ul/li[6]/a').click()
driver.implicitly_wait(2)
# 출발지 선택(인천)
trip_wd(평일)
trip_wk(주말)

# 여행 일정 선택 먼저 한 후 코드 돌려주세요.
# 유럽
trip_wk = DataFrame(columns=['국가','항공사','가격','MBTI'])
for u in range(1,9):
    element = driver.find_element(By.CLASS_NAME,'btnDeparture.jsBtnDeparture.jsSearch')
    driver.implicitly_wait(2)
    element.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div/dl[1]/dd[5]/a').click()
    time.sleep(3)

# 도착지 선택(파리 런던 로마 프라하 프랑크프로트, 마드리드,바로셀로나, 취리히)
    element1 = driver.find_element(By.CLASS_NAME,'btnArrival.jsBtnDeparture.jsSearch')
    element1.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div[2]/dl[2]/dd['+str(u)+']/a').click()
    time.sleep(5)

# 검색버튼 클릭하기
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/fieldset/div/div[2]/div/div[2]/button').click()
    time.sleep(15)
    driver.find_element(By.XPATH,'//*[@id="lowPriceCol"]').click()
    time.sleep(2)
    
# 페이지 소스 가져오기
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')

# 가져온 자료를 가지고 데이터 프레임으로 만들기(최저가 3개)
    for i in range(0,3):
        air = soup.select('span.airportName')[i].text.strip()
        price = soup.select('span.charge')[i].text.strip()
        country = soup.select_one('h2.search-title.style1 > strong').text.strip()
        mbti = 'ENFP'
        trip_wk = trip_wk.append({'국가':country,'항공사':air,'가격':price,'MBTI':mbti},ignore_index = True)
  
    driver.back()
    time.sleep(3)   
trip_wk
soup.select_one('h2.search-title.style1 > strong').text.strip()

# 동남아
for u in range(1,9):
    element = driver.find_element(By.CLASS_NAME,'btnDeparture.jsBtnDeparture.jsSearch')
    driver.implicitly_wait(2)
    element.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div/dl[1]/dd[5]/a').click()
    time.sleep(3)

# 도착지 선택(홍콩,하노이,방콕,마닐라,타이페이,싱가포르,다낭,호치민)
    element1 = driver.find_element(By.CLASS_NAME,'btnArrival.jsBtnDeparture.jsSearch')
    element1.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div[2]/dl[5]/dd['+str(u)+']/a').click()
    time.sleep(5)

# 검색버튼 클릭하기
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/fieldset/div/div[2]/div/div[2]/button').click()
    time.sleep(15)
    driver.find_element(By.XPATH,'//*[@id="lowPriceCol"]').click()
    time.sleep(2)
    
# 페이지 소스 가져오기
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')

# 가져온 자료를 가지고 데이터 프레임으로 만들기(최저가 3개)
    for i in range(0,3):
        air = soup.select('span.airportName')[i].text.strip()
        price = soup.select('span.charge')[i].text.strip()
        country = soup.select_one('h2.search-title.style1 > strong').text.strip()
        trip_wk = trip_wk.append({'국가':country,'항공사':air,'가격':price},ignore_index = True)
    driver.back()
    time.sleep(3)
    
trip_wk

# 태평양
for u in range(1,5):
    element = driver.find_element(By.CLASS_NAME,'btnDeparture.jsBtnDeparture.jsSearch')
    driver.implicitly_wait(2)
    element.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div/dl[1]/dd[5]/a').click()
    time.sleep(3)
    
# 도착지 입력(괌,사이판,시드니,오클랜드)
    element1 = driver.find_element(By.CLASS_NAME,'btnArrival.jsBtnDeparture.jsSearch')
    element1.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div[2]/dl[4]/dd['+str(u)+']/a').click()
    time.sleep(5)

# 검색버튼 클릭하기
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/fieldset/div/div[2]/div/div[2]/button').click()
    time.sleep(15)
    
# 페이지 소스 가져오기
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')

# 가져온 자료를 가지고 데이터 프레임으로 만들기(최저가 3개)
    for i in range(0,3):
        air = soup.select('span.airportName')[i].text.strip()
        price = soup.select('span.charge')[i].text.strip()
        country = soup.select_one('h2.search-title.style1 > strong').text.strip()
        trip = trip.append({'국가':country,'항공사':air,'가격':price},ignore_index = True)
  
    driver.back()
    time.sleep(3)
trip

## 못 넣은 여행지 추가하기
# con = [['크로아티아'],['아이슬란'],['부다페'],['델리'],['미얀마'],['터키'],['그리스'],['라스베가스'],['발리'],['블라디'],['뉴욕'],['라오스'],['나미비아'],['브라질']]
# con = [['터키'],['그리스'],['라스베가스'],['발리'],['블라디'],['뉴욕'],['라오스'],['나미비아'],['브라질']]
# con = [['뉴욕'],['라오스'],['나미비아'],['브라질']]
# con = [['나미비아'],['브라질']]
con = [['크로아티아'],['아이슬란'],['부다페'],['델리'],['브라질'],['터키'],['그리스'],['라스베가스'],['발리'],['뉴욕'],['괌'],['뉴질랜드']]
for u in range(0,len(con)):
    element = driver.find_element(By.CLASS_NAME,'btnDeparture.jsBtnDeparture.jsSearch')
    driver.implicitly_wait(2)
    element.click()
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[2]/div/dl[1]/dd[5]/a').click()
    time.sleep(3)

# 도착지 입력
    element1 = driver.find_element(By.CLASS_NAME,'btnArrival.jsBtnDeparture.jsSearch')
    element2 = driver.find_element(By.XPATH,'//*[@id="latest"]')
    time.sleep(3)
    element1.clear() # 삭제
    time.sleep(3)
    element1.send_keys(con[u]) # 불필요한 창 지우기 위해 데이터 입력
    time.sleep(3)
    element2.click() # 불필요한 창 지우기
    time.sleep(2)
    element1.clear() # 삭제
    time.sleep(2)
    element1.send_keys(con[u]) # 입력
    time.sleep(1.5)
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/div[1]/div/div[2]/div/div/div[1]/div/ul/li[1]/a').click() # 검색시 나오는 나라 선택
    time.sleep(3)
    
    # 검색버튼 클릭하기
    driver.find_element(By.XPATH,'//*[@id="__next"]/div/div/div[1]/div[2]/div/div[2]/form/fieldset/div/div[2]/div/div[2]/button').click() # 검색버튼 클릭
    time.sleep(15)
    driver.find_element(By.XPATH,'//*[@id="lowPriceCol"]').click() # 최적값 클릭
    time.sleep(2)
        
    # 페이지 소스 가져오기
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')

    # 가져온 자료를 가지고 데이터 프레임으로 만들기(최저가 3개)
    for i in range(0,3):
        air = soup.select('span.airportName')[i].text.strip()
        price = soup.select('span.charge')[i].text.strip()
        country = soup.select_one('h2.search-title.style1 > strong').text.strip()
        mbti = 'ENFP'
        trip_wk = trip_wk.append({'국가':country,'항공사':air,'가격':price,'MBTI':mbti},ignore_index = True)
      
    driver.back()
    time.sleep(3) 
    trip_wk

len(con)

# 각각의 mbti 특성에 맞춰 MBTI열 값 수정
# mbti별 여행지 참고 자료(https://29street.donga.com/article/all/67/2512426/1)

trip_wd.loc[:,:]
trip_wd.loc[0:5,'MBTI'] = 'INTJ' #프랑스,영국
trip_wd.loc[6:8,'MBTI'] = 'ISTJ' #이탈리아
trip_wd.loc[18:20,'MBTI'] = 'ESFP' #바르셀로나
trip_wd.loc[75:77,'MBTI'] = 'ESTJ' # 뉴욕
trip_wd.loc[9:11,'MBTI'] = 'ISFJ' # 체코
trip_wd.loc[54:56,'MBTI'] = 'ISFJ' # 헝가리
trip_wd.loc[30:32,'MBTI'] = 'ESTP' # 방콕
trip_wd.loc[78:80,'MBTI'] = 'ESFJ' # 괌  
trip_wd.loc[48:50,'MBTI'] = 'ESFJ' # 크로아티아
trip_wd.loc[51:53,'MBTI'] = 'ISTP' # 아이슬란드
trip_wd.loc[57:59,'MBTI'] = 'INFP' # 인도
trip_wd.loc[66:68,'MBTI'] = 'INTP' # 그리스
trip_wd.loc[81:83,'MBTI'] = 'ENTJ' # 뉴질랜드
trip_wd.loc[66:8,:]

trip_wk['MBTI'] = trip_wd['MBTI']

trip_wd.to_csv("c:/data/항공권_평일.csv") # 7/12~7/20
trip_wk.to_csv("c:/data/항공권_주말.csv") # 7/16~7/24

# 항공권 추가분 입력
import pandas as pd

trip_wd = pd.read_csv("c:/data/항공권_평일_a.csv")

trip_wd = trip_wd.iloc[:,2:7]

tr = ['서울(ICN) - 비엔티안(VTE)', 'VietJetAir+베트남항공' , 778204 ,'ENFP']
trip_wd.loc[len(trip_wd)] = tr
trip_wd
tr_me = ['서울(SEL) → 칸쿤(캉쿤)(CUN)','대한항공',1789700,'ENFJ']
trip_wd.loc[len(trip_wd)] = tr_me
trip_wd

trip_wk = pd.read_csv("c:/data/항공권_주말_a.csv")

trip_wk = trip_wk.iloc[:,2:7]

tk = ['서울(ICN) - 비엔티안(VTE)', 'VietJetAir+Thaismile' , 833150 ,'ENFP']
trip_wk.loc[len(trip_wk)] = tk
trip_wk
tk_me = ['서울(SEL) → 칸쿤(캉쿤)(CUN)','대한항공',1996700,'ENFP']
trip_wk.loc[len(trip_wk)] = tk_me
trip_wk

# 항공권 최종본 저장
trip_wd.to_csv('c:/data/항공권_평일_b.csv')
trip_wk.to_csv('c:/data/항공권_주말_b.csv')

----------------------------여행 패키지 웹크롤링--------------------------------

## 패키지 상품 긁어오기
# 담당 : 양민승
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import re
import pickle
from bs4 import BeautifulSoup
from pandas import Series, DataFrame
import pandas as pd
import time
import csv

# 하나투어 홈페이지 접속하기
url = 'https://www.hanatour.com/'
driver = webdriver.Chrome("c:/data/chromedriver.exe")
driver.get(url)

# 해외여행 페이지로 가기
driver.find_element(By.XPATH,'//*[@id="gnb_wrap"]/div[3]/div/div[1]/div[2]/ul/li[1]/a').click()

pack = DataFrame(columns=['패키지명','일정','가격','MBTI'])
# con = [['파리'],['런던'],['스페인'],['이탈리아'],['스위스'],['홍콩'],['발리'],['방콕'],['체코'],['헝가리'],['인도'],['브라질'],['터키'],['그리스'],['라스베이거스'],['뉴욕'],['괌'],['뉴질랜드']]
# con = [['체코'],['헝가리'],['인도'],['브라질'],['터키'],['그리스'],['라오스'],['괌'],['뉴욕'],['라스베이거스'],['뉴질랜드']]
con = [['칸쿤'],['터키'],['그리스'],['라오스'],['괌'],['사이판'],['뉴욕'],['라스베이거스'],['뉴질랜드']]
# 검색어 입력
for u in range(0,len(con)):
    element = driver.find_element(By.XPATH,'//*[@id="input_keyword"]')
    element.clear()
    time.sleep(2)
    element.send_keys(con[u])
    time.sleep(2)
    driver.find_element(By.XPATH,'//*[@id="gnb_wrap"]/div[2]/div/div[1]/div[1]/div[2]/ul/li[1]/a').click() #검색 클릭
    time.sleep(10)
    # 날짜 버튼 클릭(7월로 변경하는 작업)
    driver.find_element(By.XPATH,'//*[@id="contents"]/div[1]/div[1]/div[2]/a').click() 
    time.sleep(1)
    driver.find_element(By.XPATH,'//*[@id="contents"]/div[1]/div[1]/div[2]/div/div[1]/div/div[3]/div/div[1]/span/label').click()
    time.sleep(1)
    driver.find_element(By.XPATH,'//*[@id="contents"]/div[1]/div[1]/div[2]/div/div[2]/span[2]/button').click()
    # 페이지 소스 가져오기
    time.sleep(8)
    html = driver.page_source
    soup = BeautifulSoup(html,'html.parser')
    time.sleep(2)
    # 필요한 데이터 가져오기
    for i in range(0,3):
        name = soup.select('strong.item_title.eps3')[i].text.strip()
        day = soup.select('p.item_text > span.icn.cal')[i].text.strip()
        price = re.sub('\n|\s|원~','',soup.select('strong.price')[i].text.strip())
        mbti = 'ENFP'
        pack = pack.append({'패키지명':name,'일정':day,'가격':price,'MBTI':mbti},ignore_index=True)

    # 뒤로 돌아가기    
    driver.back()
    time.sleep(2)

# 여행지 맞춰 MBTI 라벨 맞추기(https://29street.donga.com/article/all/67/2512426/1)
pack.loc[0:2,'MBTI'] = 'INTJ' #프랑스
pack.loc[3:5,'MBTI'] = 'INTJ' #영국
pack.loc[6:8,'MBTI'] = 'ESFP' #스페인
pack.loc[9:11,'MBTI'] = 'ISTJ' # 이탈리아
pack.loc[12:14,'MBTI'] = 'INFJ' # 스위스
pack.loc[15:17,'MBTI'] = 'ESTJ' # 홍콩
pack.loc[18:20,'MBTI'] = 'ISFP' # 발리
pack.loc[21,'MBTI'] = 'ESTP' # 방콕
pack.loc[22:24,'MBTI'] = 'ISFJ' # 체코
pack.loc[25:27,'MBTI'] = 'ISFJ' # 헝가리
pack.loc[28:30,'MBTI'] = 'INFP' # 인도
pack.loc[31:33,'MBTI'] = 'ENFJ' # 남미
pack.loc[34:36,'MBTI'] = 'INTP' # 터키
pack.loc[37:39,'MBTI'] = 'INTP' # 그리스
pack.loc[40:42,'MBTI'] = 'ENFP' # 라오스
pack.loc[43:45,'MBTI'] = 'ESFJ' # 괌
pack.loc[46:48,'MBTI'] = 'ISTJ' # 사이판
pack.loc[49:51,'MBTI'] = 'ESTJ' # 뉴욕
pack.loc[52:54,'MBTI'] = 'ESTP' # 라스베이거스
pack.loc[55:57,'MBTI'] = 'ENTJ' # 뉴질랜드
pack.loc[58:60,'MBTI'] = 'ESFJ' # 크로아티아
pack.loc[61,'MBTI'] = 'ISTP' # 아이슬란드
del pack.iloc[0:3]

pack = pack.drop([0,1,2])
pack.info()

pack

# csv파일로 저장하기
import csv
pack.to_csv('c:/data/패키지여행.csv')

# 추가적인 부분 수정하기
## 오류 데이터수정
trip_wk = pd.read_csv('c:/data/항공권_주말.csv')
trip_wd = pd.read_csv('c:/data/항공권_평일.csv')

trip_wd.loc[78:80,'MBTI'] = 'ESFJ' # 괌
trip_wd.loc[75:77,:]

trip_wd.loc[trip_wd['MBTI'] == 'ENFP',]

trip_wd.loc[15:17,'MBTI'] = 'ESFP'  # 스페인
trip_wd.loc[21:23,'MBTI'] = 'INFJ' # 스위스
trip_wd.loc[50:67,:]

# 최종본 저장
trip_wd.to_csv('c:/data/항공권_평일_a.csv')
trip_wk.to_csv('c:/data/항공권_주말_a.csv')

-----------------------------항공 주중 자료 정리--------------------------------

##항공 주중 자료 정리
# 고승한
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
font_name=font_manager.FontProperties(fname='c:/windows/fonts/HMFMPYUN.TTF').get_name()
rc('font',family=font_name)
import seaborn as sns
import matplotlib as mpl

# 사용한 데이터
trip_wd = pd.read_csv('c:/data/4.항공권_평일_b.csv')
trip_wk = pd.read_csv('c:/data/3.항공권_주말_b.csv')
pack = pd.read_csv('c:/data/0.패키지여행.csv')

trip_wd = trip_wd.iloc[:,1:]
trip_wk = trip_wk.iloc[:,1:]
pack = pack.iloc[:,1:]
trip_wd


# 몇몇 지역만 뽑아서 시각화.
# x축 -> mbti
# y축 -> 가격
# 그룹화 -> 주중, 주말, 패키지

## 주중
# nan 데이터 확인.
trip_wd[~trip_wd.MBTI.isin(['INTJ', 'ISTJ', 'ISFJ', 'ENFP', 'ESFP', 'INFJ', 'ESTJ', 'ESTP', 'ESFJ', 'ISTP', 'INFP', 'ENFJ', 'INTP', 'ISFP', 'ENTJ'])]

# 국가별 최소가격 추출.
new_trip_wd = trip_wd.groupby('국가').aggregate({'가격':'min','MBTI':'max'}).reset_index()

# 결측값 있는 행 제거(NAN값)
new_trip_wd = new_trip_wd.dropna(axis=0)
new_trip_wd.reset_index(drop=True, inplace=True)

# 파리 mbti INTJ -> ENTP로 변경.(INTJ 값이 2번 들어가 파리MBTI 인터넷 검색 시 ENTP에 포함되어있어 ENTP로 변경)
new_trip_wd.loc[new_trip_wd['국가'] == '인천(ICN) → 파리(CDG)(CDG)','MBTI'] = 'ENTP'

# mbti 개수 재확인.
new_trip_wd['MBTI'].unique()

# 가격 형식 변경 ex : 1,000,000 -> 1000000
new_trip_wd['가격'] = new_trip_wd['가격'].str.replace(',','').astype(int)

------------------------------항공 주말 자료 정리-------------------------------

## 주말
# 담당 : 고승한
# nan 데이터 확인.
trip_wk[~trip_wk.MBTI.isin(['INTJ', 'ISTJ', 'ISFJ', 'ENFP', 'ESFP', 'INFJ', 'ESTJ', 'ESTP', 'ESFJ', 'ISTP', 'INFP', 'ENFJ', 'INTP', 'ISFP', 'ENTJ'])]

# 국가별 최소가격 추출.
new_trip_wk = trip_wk.groupby('국가').aggregate({'가격':'min','MBTI':'max'}).reset_index()

# 결측값 있는 행 제거
new_trip_wk = new_trip_wk.dropna(axis=0)
new_trip_wk.reset_index(drop=True, inplace=True)

# 파리 mbti INTJ -> ENTP로 변경.(INTJ 값이 2번 들어가 파리MBTI 인터넷 검색 시 ENTP에 포함되어있어 ENTP로 변경)
new_trip_wk.loc[new_trip_wk['국가'] == '인천(ICN) → 파리(CDG)(CDG)','MBTI'] = 'ENTP'

# mbti 개수 재확인.
new_trip_wk['MBTI'].unique()

# 가격 형식 변경
new_trip_wk['가격'] = new_trip_wk['가격'].str.replace(',','').astype(int)

# 주중, 주말 데이터 프레임에 구분 컬럼 추가.
new_trip_wd['구분'] = '주중'
new_trip_wk['구분'] = '주말'

# 주중, 주말 데이터 프레임을 result 데이터 프레임으로 통함.
result = new_trip_wd
result = pd.concat([result, new_trip_wk],ignore_index=True)

# 위 테이블에서 I(내향형) 8개 지역 추출
i_regions = result.loc[result['국가'].str.contains('런던|이스탄불|쮜리히|델리|로마|레이캬빅|프라하|발리'), ['국가','가격','MBTI','구분']]

-----------------------------패키지 내향형 정제 작업-----------------------------------

## 패키지 자료 구성
# 담당: 고승한

# MBTI 중 I(내향형) 8개 패키지 패키지 추출
britain = pack.loc[pack['패키지명'].str.contains('영국'), ['패키지명','가격','MBTI']]
turkey = pack.loc[pack['패키지명'].str.contains('터키|이스탄불'), ['패키지명','가격','MBTI']]
# 스위스, 이탈리아는 패키지로 겹치는 데이터가 있기 때문에 각각에 맞는 MBTI만 추출.
swiss = pack.loc[(pack['패키지명'].str.contains('스위스')) & (pack['MBTI'] == 'INFJ'), ['패키지명','가격','MBTI']]
india = pack.loc[pack['패키지명'].str.contains('인도'), ['패키지명','가격','MBTI']]
italy = pack.loc[(pack['패키지명'].str.contains('이탈리아')) & (pack['MBTI'] == 'ISTJ'), ['패키지명','가격','MBTI']]
iceland = pack.loc[pack['패키지명'].str.contains('아이슬란드'), ['패키지명','가격','MBTI']]
cesko = pack.loc[pack['패키지명'].str.contains('체코'), ['패키지명','가격','MBTI']]
bali = pack.loc[pack['패키지명'].str.contains('발리'), ['패키지명','가격','MBTI']]

# 각 데이터프레임에 result 데이터프레임에 존재하는 컬럼인 '국가' 컬럼 추가.
britain['국가'] = '영국'
turkey['국가'] = '터키'
swiss['국가'] = '스위스'
india['국가'] = '인도'
italy['국가'] = '이탈리아'
iceland['국가'] = '아이슬란드'
cesko['국가'] = '체코'
bali['국가'] = '발리'

# 8개의 데이터프레임 통합.
packages = pd.concat([britain,turkey,swiss,india,italy,iceland,cesko,bali], ignore_index = True)
packages

# 가격 형식 변경
packages['가격'] = packages['가격'].str.replace(',','').astype(int)

# 국가별 최소가격 추출.
new_packages = packages.groupby('국가').aggregate({'가격':'min','MBTI':'max'}).reset_index()

# 구분 컬럼값 '패키지'로 추가
new_packages['구분'] = '패키지'

# 양 데이터프레임 통합
i_regions = pd.concat([i_regions,new_packages], ignore_index = True)

# MBTI순으로 정렬
i_regions = i_regions.sort_values(by='MBTI')

# 인덱스 초기화
i_regions.reset_index(drop = True, inplace = True)

----------------------------패키지 외향형 정제 작업----------------------------
## 외향형 정제 작업
# 담당: 고승한

# result 데이터프레임에서 E(외향형) 8개 지역 추출
e_regions = result.loc[result['국가'].str.contains('라스베이거스|뉴욕|괌|바르셀로나|오클랜드|파리|비엔티안|칸쿤'), ['국가','가격','MBTI','구분']]

# MBTI 중 E(외향형) 8개 패키지 패키지 추출
w_america = pack.loc[pack['패키지명'].str.contains('서부'), ['패키지명','가격','MBTI']]
e_america = pack.loc[pack['패키지명'].str.contains('동부'), ['패키지명','가격','MBTI']]
guam = pack.loc[pack['패키지명'].str.contains('괌'), ['패키지명','가격','MBTI']]
spain = pack.loc[pack['패키지명'].str.contains('스페인'), ['패키지명','가격','MBTI']] 
newzealand = pack.loc[pack['패키지명'].str.contains('뉴질랜드'), ['패키지명','가격','MBTI']]
france = pack.loc[pack['패키지명'].str.contains('프랑스'), ['패키지명','가격','MBTI']]
laos = pack.loc[pack['패키지명'].str.contains('라오스'), ['패키지명','가격','MBTI']]
mexico = pack.loc[pack['패키지명'].str.contains('멕시코|칸쿤'), ['패키지명','가격','MBTI']]

# 각 데이터프레임에 result 데이터프레임에 존재하는 컬럼인 '국가' 컬럼 추가.
w_america['국가'] = '미_서부'
e_america['국가'] = '미_동부'
guam['국가'] = '괌'
spain['국가'] = '스페인'
newzealand['국가'] = '뉴질랜드'
france['국가'] = '프랑스'
laos['국가'] = '라오스'
mexico['국가'] = '멕시코'

# 프랑스 mbti ENTP로 변경.(MBTI 수집이 잘못되어 수정)
france.MBTI = 'ENTP'

# 8개의 데이터프레임 통합.
packages = pd.concat([w_america,e_america,guam,spain,newzealand,france,laos,mexico], ignore_index = True)
packages

# 가격 형식 변경
packages['가격'] = packages['가격'].str.replace(',','').astype(int)

# 국가별 최소가격 추출.
new_packages = packages.groupby('국가').aggregate({'가격':'min','MBTI':'max'}).reset_index()

# 구분 컬럼값 '패키지'로 추가
new_packages['구분'] = '패키지'

# 양 데이터프레임 통합
e_regions = pd.concat([e_regions,new_packages], ignore_index = True)

# MBTI순으로 정렬
e_regions = e_regions.sort_values(by='MBTI')

# 인덱스 초기화
e_regions.reset_index(drop = True, inplace = True)

-----------------------내향형/외향형/패키지 시각화-------------------------------

## 시각화
# 고승한

# 내향형 8개 지역 주중가격, 주말가격, 패키지가격 추출.
colors = ["#ead0b8", "#f0957d", "#7dadcd"]
result_plt = sns.barplot(x='MBTI',y='가격',hue='구분', data=i_regions, palette = colors)
result_plt.set(title = 'MBTI I(내향형) 주중/주말/패키지 가격')
result_plt.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))

# 외향형 7개 지역 주중가격, 주말가격, 패키지가격 추출.
colors = ["#7dadcd","#ead0b8", "#f0957d"]
result_plt = sns.barplot(x='MBTI',y='가격',hue='구분', data=e_regions[e_regions.MBTI != 'ENTJ'], palette = colors)
result_plt.set(title = 'MBTI E(외향형) 주중/주말/패키지 가격')
result_plt.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))

# 외향형 1개 지역(뉴질랜드) 주중가격, 주말가격, 패키지가격 추출.
colors = ["#ead0b8", "#7dadcd", "#f0957d"]
result_plt = sns.barplot(x='MBTI',y='가격',hue='구분', data=e_regions[e_regions.MBTI == 'ENTJ'], palette = colors)
result_plt.set(title = 'MBTI E(외향형) 주중/주말/패키지 가격')
result_plt.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))

--------------------------CNN 이미지 웹크롤링-----------------------------------

## CNN 웹크롤링 작업
# 담당 : 김준수/김동환
from selenium import webdriver # 웹브라우저를 컨트롤하여 웹을 자동화 하는 도구
from selenium.webdriver.common.by import By 
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup as bs # 
import time # 시간 
import urllib.request as req

# 사용한 자료 정보들
# estp 7999
name = ['경리','레이나','연정','이유비','지수','큐리','김립','신동엽','손준호','전현무','저스디스','용훈','허훈','정일훈']
# esfp 7000
name = ['개코','정용화','이상엽','가수 비','사이먼 도미닉','지석진','개그맨 김영철','에일리','효린','웬디','윤아','이수현','장예원','주이']
# esfj 7050
name = ['규현','려욱','서은광','박보검','박지성','이이경','성종 인피니트','가수 박혜원','김남주 에이핑크','김도연 위키미키','오나라','효정','유나 브레이브걸스']
# estj 7049
name = ['김구라','시야준수','데프콘','빅스 엔','갓세븐 뱀뱀','홍준표','위아이 김동한','송은이','이지혜','제시카','래퍼 치타','한채영','모모랜드 제인','김소영 아나운서']
# enfp 7001
name = ['강균성','김사무엘','sg워너비 김진호','딘딘','노홍철','송민호','싸이','김태리','박나래','문별','박민영','사나','이효리','화사']
# enfj 7051
name = ['강다니엘','김재중','공명','동해','박군','송중기','수호','낸시','박미선','박소담','신민아','신세경','이성경','유이']
# entj 7051
name = ['곽동연','빅스 라비','스윙스','이특','팔로알토','지코','여진구','문가영','윤하','티파니 영','서현','임은수','한유미 배구선수','이달의 소녀 희진']
# entp 7052
name = ['김동완','박경','영탁','육성재','자이언티','이제훈','정혁','강민아','라미란','손승연','제시','한예슬','브레이브걸스 유정','김세정']
#infp
name = ['아이유','정려원','민효린','김숙','강예원','유겸','원필','RM','슈가','정국','예리','백예린','나은','이청아','구구단 하나','선미','유아인']
#infj
name = ['태연','하니','솔라','승희','김윤아','류수정','루다','이달의 소녀 이브','빅뱅 태양','카이','레오','제이비','원우','디에잇','우지']
#intj
name = ['강동원','지드래곤','다원','손나은','류진','공민지','구혜선','김범','김법래','김유정','김윤아','보아','신예은','엄기준','은혁','유준상','에릭','이경규','안소희']

#intp
name = ['소연(여자)아이들','정은지','BAE173 제이민','임현식','슈가','BTS 진','EXO 세훈','DAY6 Jae','프로미스나인 이나경','GHOST9 이신','김상균','미료','기리보이','초아',
        '라붐 소연',' 브레이브걸스 민영','마마무 휘인','원어스 서호']
#istj
name = ['남윤수','GOT7 마크','우주소녀 보나','소녀시대 써니','인피니트 엘','엡텐션 선율','ENHYPEN 성훈','인피니트 김성규','SG워너비 이석훈','차태현','레인보우 조현영','AOA 찬미','소녀시대 효연']

#isfj
name = ['동방신기 최강창민','갓세븐 진영','갓세븐 영재','뉴이스트 JR','엔시티 재민','엔시티 도영','세븐틴 정한','엔플라잉 차훈','업텐션 규진','브라운아이드걸스 나르샤',
        '트와이스 다현','오마이걸 비니','있지 예지','아이즈원 야부키 나코',' 프로미스나인 백지헌','프로미스나인 이서연','이달의소녀 진솔','주호민']
#istp
name = ['전지현','트와이스 나연','홍진경','에프엑스 크리스탈','EXID 혜린','이달의소녀 올리비아 혜',' 드림캐쳐 가현',
        '펜타곤 진호','던','스트레이키즈 한','원어스 환웅','김종민','김연아','박명수','장성규']

#isfp
name = ['AOA 설현','APLNK 윤보미','BTS 정국','EXID LE','EXO 백현', 'NCT 제노',' CLC 오승희','레드벨벳 슬기','레드벨벳 웬디',
        '세븐틴 버논',' 샤이니 온유','다비치 이해리',' 뉴이스트 아론','러블리즈 이미주','GHOST9 최준성','틴탑 천지']


# 데이터 정제 시 데이터 부족으로 인하여 추가 진행 
# estp
name = ['드림노트 유아이','프리지아 송지아','NCT 성찬','Stray Kids 창빈']
# ESFP
name = ['워너원 하성운','이민정']
name = ['2PM 우영','박봄']
# entj
name = ['베이비소울','이정재']
# esfp
name = ['강혜원','케플러 김채현', '이달의 소녀 현진','배진영','더보이즈 상연','더보이즈 큐']
name = ['하성운','이민정']
# esfj
name = ['케플러 히카루','케플러 휴닝바히에','우주소녀 엑시','스트레이키즈 승민','스트레이키즈 리노','빅톤 허찬']
# estj
name = ['이다인','엘리스 소희','배우 남지현','에이비식스 박우진','펜타곤 여원','김민규']
name = ['한가인','장동민','스우파 모니카','이찬원']
name = ['김태희','류준열']
# entj
name = ['에버글로우 아샤','남보라']

# 웹크롤링
url = 'https://search.naver.com/search.naver?where=image'
driver =  webdriver.Chrome('c:/data/chromedriver.exe')
driver.get(url)
driver.implicitly_wait(2)

ex = []
img_url = []
for i in name:
    element = driver.find_element(By.CLASS_NAME,'box_window')
    element.clear() # 검색창 지우기
    element.send_keys(i) # 연애인 검색
    driver.implicitly_wait(2)
    element.submit() # 엔터 역활
    for i in range(10):
        driver.find_element(By.TAG_NAME,'body').send_keys(Keys.END) # 맨 밑으로 내리기
        time.sleep(5) # 타임 스립 5초
    html = driver.page_source
    soup = bs(html,'html.parser')

    for i in soup.select('img._image'):
        try:
            img_url.append(i.attrs['src'])
        except:
            ex.append(i)
            
for i in range(0,len(img_url)):
    req.urlretrieve(img_url[i],'c:/ESTP_NEW/'+str(i+10709)+'.jpg') # 저장 위치 변경 필수

----------------------------------CNN------------------------------------------

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input # vgg에서 스케일링에 사용됨.
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import ReduceLROnPlateau


# 사용 데이터
train_path = "c:/data/CNN 데이터_a/TRAIN"
validation_path = "c:/data/CNN 데이터_a/TRAIN"

training_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input, # 스케일 작업
    rotation_range=10, # 무작위 회전 10도 이내
    width_shift_range=0.2, # 수평 이미지 이동 범위 20% 이내
    height_shift_range=0.1, # 수직 이미지 이동 범위 10% 이내
    shear_range=0.1, # 해당 밀림 강도 내에서 이미지 변형(0.1 라디안)
    zoom_range=0.1, # 무작위 줌 범위 10% 이내
    horizontal_flip=True, # 입력을 무작위로 가로로 뒤집음.
    fill_mode='nearest') # 가장 가까운 픽샐을 찾아 늘림.

valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # 스케일 작업

training_generator = training_datagen.flow_from_directory(train_path,
                                  batch_size=1024,
                                  shuffle=True,
                                  target_size=(32,32),
                                  class_mode='categorical')

training_generator.classes
training_generator.class_indices

validation_generator = valid_datagen.flow_from_directory(validation_path,
                                  batch_size=1024,
                                  shuffle=True,
                                  target_size=(32,32),
                                  class_mode='categorical')

validation_generator.classes
validation_generator.class_indices 

VGG16_MODEL = VGG16(input_shape=(32,32,3), include_top=False, weights='imagenet') # 기존 모델의 가중치를 그대로 사용
VGG16_MODEL.summary()
VGG16_MODEL.trainable=False # 최적의 가중치를 유지하기 위해 훈련은 추가적으로 안함

model = Sequential([
    VGG16_MODEL,
    Flatten(),
    Dense(500, activation = 'relu'),
    Dense(16, activation='softmax')
    ])
model.summary()

# epochs 횟수동안 성능이 개선되지 않을 경우 Learning rate을 동적으로 감소 시키는 기능
rlp_cb = ReduceLROnPlateau(monitor='val_loss',mode='min',patience=1,factor=0.3, verbose=1)

# learning rate -> 학습률은 다소 높게 설정.
model.compile(optimizer = Adam(0.001),loss='categorical_crossentropy',metrics=['accuracy'])


# batch size -> 학습데이터가 16000개에 달하기 때문에 한 번에 많은 데이터를 학습하는 편이 좋다고 판단 -> 1024로 설정.
# rlp_cb를 통해 epochs 진행에 따라 성능이 개선되지 않을 시 학습률을 동적으로 감소시키도록 처리.
history = model.fit(training_generator, validation_data = validation_generator,
                    batch_size=1024,epochs=20,callbacks=[rlp_cb])

# 모델 저장
model.save('/Users/seunghanko/Downloads/mbtis.h5')
# 모델 불러오기
new_model = keras.models.load_model('c:/data/mbtis.h5')
new_model.summary()

-------------------------------음성 출력---------------------------------------

## 음성 함수 제작
# 김준수 윈도우 버전
# pip install gtts
# pip install pygame
from gtts import gTTS
import datetime
import playsound
import os
def speak(text):
    tts = gTTS(text=text, lang='en') # 영어로 음성 생성
    date_string = datetime.datetime.now().strftime("%d%m%Y%H%M%S") #저장 파일명
    filename = "voice"+date_string+".mp3"
    tts.save(filename) # 파일로 저장
    playsound.playsound(filename) # 음성 재생
    os.remove(filename) # 파일 삭제

# 고승한 맥버전
from gtts import gTTS
import pygame
def speak(text):
    tts = gTTS(text=text, lang='en') # 영어로 음성 생성
    filename = 'result.mp3'
    tts.save(filename) # 파일로 저장
    pygame.mixer.init()
    pygame.mixer.music.load(filename)# 음성 파일 로드
    pygame.mixer.music.play()# 음성 재생

    
-----------------------------CNN 테스트----------------------------------------

## 테스트 데이터
img2 = load_img('c:/data/doi.jpg')

x = img_to_array(img2)
x.shape # 이미지를 배열로 변경
x = tf.image.resize(x,[32,32])
x.shape # 사이즈 32*32로 변경
x = np.array([x])
x.shape # 형태를 4차원으로 변경

# 분석된 MBTI 구현
predict = new_model.predict(preprocess_input(x)) # 새로운 모델을 바탕으로 예측.
mbti_result = list(training_generator.class_indices.keys())[np.argmax(predict)] # 가장 기대확률이 높은 결과 MBTI를 출력
mbti_result = mbti_result[:4] # MBTI 스라이싱
speak(mbti_result) # 음성지원 코드



--------------------------KNN 데이터 정제 작업----------------------------------
## KNN 데이터 정제
# 담당 : 김동환/김준수

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import MultinomialNB
from konlpy.tag import Okt
from collections import Counter
from pandas import DataFrame, Series
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import copy
import operator
import seaborn as sns
from matplotlib import font_manager, rc
font_name=font_manager.FontProperties(fname='c:/windows/fonts/HMFMPYUN.TTF').get_name()
rc('font',family=font_name)

mbti = pd.read_csv('c:/data/MBTI_g.csv') # mbti 파일 읽어오기
jaso  = pd.read_csv('c:/data/자소전_b.csv') # 자소서 파일 읽어오기
jaso = jaso.iloc[:,1:] # 중복된 인덱스 제외

# 나이브 베이즈 코드
okt = Okt()
def okt_pos(arg):
    token_corpus = []
    for i in okt.pos(arg):
        if i[1] in ['Noun','Adjective']:
            token_corpus.append(i[0]+'/'+i[1]) # 형태소 합치기
    token_corpus = [word for word in token_corpus if len(word.split('/')[0]) >= 2]
    return token_corpus

# 학습데이터
cv = CountVectorizer(tokenizer=okt_pos) # okt활용하여 명사/형용사만 사전으로 만들기
x_train = cv.fit_transform(mbti['특성']) # 학습데이터
cv.get_feature_names() # 정보 확인
x_train.toarray()
y_train = mbti['MBTI']

tfidf = TfidfTransformer()
x_train = tfidf.fit_transform(x_train) # 위에서 fit작업이 완료되어 사전이 만들어져 있고 transform 작업만하면 됨

# 학습 모델
nb = MultinomialNB()

# 예측
a = []
for i in range(0,len(jaso['text'])):
    x_test = cv.transform(pd.Series(jaso['text'][i])) # 테스트데이터(자소서) 사전 변환
    x_test_tfidf = tfidf.transform(x_test) # tfidf모델로 변환
    a.append(nb.fit(x_train, y_train).predict(x_test_tfidf)) # 나이브베이즈 모델에 학습데이터 적용 및 테스트데이터 예측해서 a리스트에 저장
    

jaso_mbti = [j for i in a for j in i]  # 이중리스트 안에 배열에서 mbti만 추출
jaso_mbti = Series(jaso_mbti) # 구조 변환
Counter(jaso['work']) # 직무종류확인
work_mbti = pd.concat([jaso['work'],jaso_mbti],axis=1) # 데이터 열별로 합치기
work_mbti = work_mbti.rename(columns={0:'mbti'}) # 컬럼명 변경


# 자소서 예측한 mbti, 직무와 mbti별 추천된 직무를 수치화하여 knn알고리즘으로 비교 및 시각화 작업 수행
# mbti별 추천 직무 데이터 읽어오기
job = pd.read_csv('c:/data/KNN 직무_a.csv',encoding='cp949') # mbti별로 겹치는 추천 직무 있음

#  기존 자소서 mbti,지원직무에 추천직무 추가
work_mbti['recommend'] = '' 
c = 0
for i in Counter(job.mbti).keys():    
    work_mbti.loc[work_mbti['mbti'] == i,'recommend'] = job.loc[job['mbti']==i]['직무'][c]
    c += 1

------------------------------KNN 수치화---------------------------------------

## KNN 수치화
# 담당 : 김동환
from collections import Counter
from pandas import DataFrame, Series
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import copy
import operator
import seaborn as sns
from matplotlib import font_manager, rc
from sklearn.cluster import KMeans

# 라벨 변환작업
work_mbti_t = copy.deepcopy(work_mbti) # 메모리 공유하지 않고 변수안의 내용만 복사(새로운 변수로 사용하기위해서)
work_mbti_a = work_mbti_t[['mbti','work','recommend']] # 컬럼순서 변경
Counter(work_mbti_a.work) # 직무 종류 확인
work_mbti_a['work'] = work_mbti_a['work'].map({'하드웨어':0,'사무':1,'경비':2,'디자인':3,'CS':4,'마케팅':5,'연구개발':6,'소프트웨어':7,'생산':8,'영업':9,'건축':10,'무역':11}) # 라벨 변환
work_mbti_a['recommend'] = work_mbti_a['recommend'].map({'하드웨어':0,'사무':1,'경비':2,'디자인':3,'CS':4,'마케팅':5,'연구개발':6,'소프트웨어':7,'생산':8,'영업':9,'건축':10,'무역':11}) # 라벨 변환

# KNN 계산
work_mbti_a['result'] = np.sqrt((work_mbti_a['work'] -0)**2 + (work_mbti_a['recommend'] - 0)**2 ).astype(int) # KNN 계산식
work_mbti_t_d = Counter(work_mbti_a['result']) # 일치하는 값 : 0(일치) , 불일치 값 : 1~14나머지 값의 개수를 work_mbti_t_d변수에 저장

# 정렬
work_mbti_t_k = sorted(work_mbti_t_d.items(),key=operator.itemgetter(1),reverse=True) # value값(개수)으로 정렬

work_mbti_t_k_df = DataFrame(work_mbti_t_k) # 정렬된 값 데이터프레임에 저장
work_mbti_t_k_df.columns = ['차이','개수'] # 컬럼명 변환 

# 일치하는 개수와 불일치하는 개수 합 저장
n_ze = work_mbti_t_k_df.loc[work_mbti_t_k_df['차이'] !=0,'개수'].sum()  
ze = work_mbti_t_k_df.loc[work_mbti_t_k_df['차이'] ==0,'개수'][7]

# 시각화를 위한 데이터 구조 만들기 (새 데이터프레임에 저장한 일치직무, 불일치직무 넣기)
final = DataFrame([{'다른직무':n_ze,'일치직무':ze}])
final_t = final.T  # 열과 행 Transformation
final_t.columns= ['개수'] # 컬럼명 변환

-----------------------------시각화 그래프--------------------------------------

## 원그래프 시각화 그래프
# 담당 : 김동환

explode= [0,0.2] # 행별 구분되는 넓이 조정 값
wedgeprops={'width': 0.7, 'edgecolor': 'w', 'linewidth': 5}  # pie차트 가운데 흰색 원 삽입을 위한 값
colors = ['#ff9999','#8fd9b6'] # 색상옵션에 들어갈 값 
final_t['개수'].plot(kind='pie', # 종류 pie차트
                        autopct='%.1f%%', # 그래프 안에 들어갈 비율값
                        legend=True, # 범례
                        startangle=160, # 회전도
                        colors=colors, # 색상
                        explode=explode, # 행 구분 넓이 
                        wedgeprops = wedgeprops, # pie차트 중앙에 원 삽입
                        title='예측한 MBTI 지원직무와 추천직무 비교', # 제목
                        fontsize=12, # 글자크기
                        shadow=True) # 그림자
plt.legend(bbox_to_anchor=(1,1)) # bbox_to_anchor 옵션 : 범례 차트 밖으로 빼는 역할
plt.axis('off') # 축 이름 삭제

## 산점도 그래프
# k-means 작업 및 시각화
work_mbti_t = pd.read_csv("c:/data/직무 수치화 데이터.csv")
model = KMeans(n_clusters=14) # 군집화 모델 14개로 군집(mbti개수)
model.fit(work_mbti_t.iloc[:,3:]) 
model.labels_ # 라벨
model.cluster_centers_ # 클러스터 중심값
colormap = np.array(['red','blue','black','yellow','purple','orange','gray','green','brown','pink','ivory','lime','orchid','skyblue']) # 색상
plt.scatter(work_mbti_t['work'],work_mbti_t['recommend'],c=colormap[model.labels_],s=40) # 산점도(직무,mbti를 수치화한 데이터를 적용)
plt.title('직무 군집화')
plt.show()

-----------------------------데이터 파일 저장-----------------------------------

## 데이터 파일 저장
# 담당 : 김동환
work_mbti_a.to_csv('c:/data/직무 추가 데이터.csv',index=False) # 직무 추가 후 저장
work_mbti_t.to_csv('c:/data/직무 수치화 데이터.csv',index=False) # knn계산후 새 컬럼에 넣은 데이터
final_t.to_csv('c:/data/시각화 수치 데이터.csv',index=False) # 시각화 데이터 











































































































































































