{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_2파이썬(단층/다층 퍼셉트론, 딥러닝, 활성화 함수).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1+btPKnPyaKDq5nzmnTm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehdghks316/itwill_studyGroup_D/blob/main/5_2%ED%8C%8C%EC%9D%B4%EC%8D%AC(%EB%8B%A8%EC%B8%B5_%EB%8B%A4%EC%B8%B5_%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0%2C_%EB%94%A5%EB%9F%AC%EB%8B%9D%2C_%ED%99%9C%EC%84%B1%ED%99%94_%ED%95%A8%EC%88%98).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gnf7iBYN8NU"
      },
      "outputs": [],
      "source": [
        "★ 퍼셉트론(perceptron)\n",
        "- 1957년에 프랑크 로젠 브라트가 고안했다.\n",
        "- 사람의 뇌의 동작을 전기 신호  on/off로 흉내낼 수 있다는 이론\n",
        "- 특정한 자극이 있다면 그 자극이 어느 threshold(역치,임계값) 이상이어야지만 세포가 반응한다.\n",
        "- 다수의 신호를 입력받아 하나의 신호를 출력한다.\n",
        "- 0 : 신호가 없다.  1 : 신호가 있다.\n",
        "\n",
        "회귀식\n",
        "y = ax + b\n",
        "y = a1x1 + a2x2 + b\n",
        "\n",
        "퍼셉트론 동작\n",
        "y = wx\n",
        "x : 입력값(입력신호)\n",
        "w : weight(가중치)\n",
        "Θ : theta(임계값)\n",
        "y : 출력값\n",
        "\n",
        "y : 0  w1*x1 + w2*x2 <= Θ\n",
        "y : 1  w1*x1 + w2*x2 > Θ\n",
        "\n",
        "논리회로\n",
        "- 컴퓨터는 두가지 디지털 0,1을 입력해서 하나의 값을 출력하는 회로가 모여 만들어지는데 이 회로를\n",
        "gate라고 한다.\n",
        "\n",
        "AND gate\n",
        "x1(입력1)     x2(입력2)     y(출력)\n",
        "------------------------------------\n",
        "0               0           0\n",
        "0               1           0\n",
        "1               0           0\n",
        "1               1           1\n",
        "\n",
        "AND(0,0) => 0\n",
        "AND(0,1) => 0\n",
        "AND(1,0) => 0\n",
        "AND(1,1) => 1\n",
        "\n",
        "y : 0  w1*x1 + w2*x2 <= Θ\n",
        "y : 1  w1*x1 + w2*x2 > Θ\n",
        "\n",
        "AND(0,0) => 0\n",
        "    w1*0 + w2*0 <= Θ\n",
        "\n",
        "w1 = ?\n",
        "w2 = ?\n",
        "Θ = ?\n",
        "# w와 Θ값을 찾는 것이 목표\n",
        "def AND(arg1,arg2):\n",
        "    w1 = 0.5 \n",
        "    w2 = 0.5\n",
        "    theta = 0.5\n",
        "    tmp = w1 * arg1 + w2 * arg2\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "AND(0,0)\n",
        "AND(0,1)\n",
        "AND(1,0)\n",
        "AND(1,1)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "input\n",
        "def AND(arg1,arg2):\n",
        "    w1 = 0.5 \n",
        "    w2 = 0.5\n",
        "    theta = 0.5\n",
        "    w = np.array([w1,w2])\n",
        "    x = np.array([arg1,arg2])\n",
        "    tmp = np.sum(w*x)\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "    \n",
        "print('AND perceptron')\n",
        "for i in input:\n",
        "    print(str(i)+' => ' +str(AND(i[0],i[1])))\n",
        "    \n",
        "    \n",
        "OR gate\n",
        "x1(입력1)     x2(입력2)     y(출력)\n",
        "------------------------------------\n",
        "0               0           0\n",
        "0               1           1\n",
        "1               0           1\n",
        "1               1           1\n",
        "\n",
        "OR(0,0) => 0\n",
        "OR(0,1) => 1\n",
        "OR(1,0) => 1\n",
        "OR(1,1) => 1\n",
        "\n",
        "def OR(arg1,arg2):\n",
        "    w1 = 0.5 \n",
        "    w2 = 0.5\n",
        "    theta = 0\n",
        "    tmp = w1 * arg1 + w2 * arg2\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "OR(0,0)\n",
        "OR(0,1)\n",
        "OR(1,0)\n",
        "OR(1,1)\n",
        "\n",
        "import numpy as np\n",
        "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "input\n",
        "def OR(arg1,arg2):\n",
        "    w1 = 0.5 \n",
        "    w2 = 0.5\n",
        "    theta = 0\n",
        "    w = np.array([w1,w2])\n",
        "    x = np.array([arg1,arg2])\n",
        "    tmp = np.sum(w*x)\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "    \n",
        "print('OR perceptron')\n",
        "for i in input:\n",
        "    print(str(i)+' => ' +str(OR(i[0],i[1])))\n",
        "\n",
        "\n",
        "\n",
        "NOT AND gate\n",
        "x1(입력1)     x2(입력2)     y(출력)\n",
        "------------------------------------\n",
        "0               0           1\n",
        "0               1           1\n",
        "1               0           1\n",
        "1               1           0\n",
        "\n",
        "NAND(0,0) => 1\n",
        "NAND(0,1) => 1\n",
        "NAND(1,0) => 1\n",
        "NAND(1,1) => 0\n",
        "\n",
        "def NAND(arg1,arg2):\n",
        "    w1 = -0.5\n",
        "    w2 = -0.5\n",
        "    theta = -0.7\n",
        "    tmp = w1 * arg1 + w2 * arg2\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "NAND(0,0)\n",
        "NAND(0,1)\n",
        "NAND(1,0)\n",
        "NAND(1,1)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "input\n",
        "def NAND(arg1,arg2):\n",
        "    w1 = -0.5 \n",
        "    w2 = -0.5\n",
        "    theta = -0.7\n",
        "    w = np.array([w1,w2])\n",
        "    x = np.array([arg1,arg2])\n",
        "    tmp = np.sum(w*x)\n",
        "    if tmp <= theta:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "    \n",
        "print('AND perceptron')\n",
        "for i in input:\n",
        "    print(str(i)+' => ' +str(NAND(i[0],i[1])))\n",
        "\n",
        "\n",
        "XOR(exclusive OR) gate\n",
        "x1(입력1)     x2(입력2)     y(출력)\n",
        "------------------------------------\n",
        "0               0           1\n",
        "0               1           1\n",
        "1               0           1\n",
        "1               1           0\n",
        "\n",
        "NAND(0,0) => 1\n",
        "NAND(0,1) => 1\n",
        "NAND(1,0) => 1\n",
        "NAND(1,1) => 0\n",
        "    \n",
        "★ 단층퍼셉트론의 한계\n",
        "- 직선하나로 XOR gate의 출력을 구분할 수 없다.\n",
        "- 퍼셉트론(단층퍼셉트론)은 직선하나로 나눈 영역만 표현할 수 있다는 한계가 있다.\n",
        "- 1969 민스키가 기존 퍼셉트론의 문제점을 지적했는데 XORㅂNㄴ류를 못하는 문제점을 지적했다.\n",
        "\n",
        "\n",
        "★ 다층퍼셉트론(Multi layer perceptron)\n",
        "다층퍼셉트론(OR,NAND)로 AND 연산작업을 하면 XOR를 만들 수 있다.(1986)\n",
        "1. x1, x2를 통해 OR층을 만든다.\n",
        "2. x1, x2를 통해 NAND층을 만든다.\n",
        "3. 중간에 만든 OR층, NAND층을 AND 계산작업을 하면 XOR를 만들 수 있다.\n",
        "\n",
        "XOR(exclusive OR) gate\n",
        "x1(입력1)     x2(입력2)     OR층   NAND층   AND(OR,NAND) => y(출력)\n",
        "------------------------- ------  ------  -----------\n",
        "0               0           0       1           1\n",
        "0               1           1       1           1\n",
        "1               0           1       1           1\n",
        "1               1           1       0           0\n",
        "\n",
        "def XOR(arg1,arg2):\n",
        "    s1 = OR(arg1,arg2)\n",
        "    s2 = NAND(arg1,arg2)\n",
        "    s3 = AND(s1,s2)\n",
        "    return s3\n",
        "\n",
        "import numpy as np\n",
        "input = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "input\n",
        "\n",
        "print('XOR Multi layer perceptron')\n",
        "for i in input:\n",
        "    print(str(i)+' => ' +str(XOR(i[0],i[1])))\n",
        "\n",
        "\n",
        "★ 딥러닝(Deep Neural Network)\n",
        "- 생각할 수 있도록 고안된 인공지능\n",
        "- 사람의 뇌세포를 프로그램으로 표현한 기술\n",
        "- 인간의 신경망(neural network)이론을 이용한 인공신경망(ANN,Artifical Neural Network)의 일종으로\n",
        "계층구조로 구성하면서 입력층(input layer)과 출력층(output layer)사이에 하나 이상의 은닉층(hidden layer)을 가지고\n",
        "있는 심층신경망이다.(Deep Neural Network)\n",
        "\n",
        "            weight\n",
        "입력값(x) ----------  sum()  ---------------> 출력값(y)\n",
        "            bias\n",
        "            \n",
        "y(출력) = weight * x(입력값) + bias\n",
        "y(출력) = weight(회귀계수) * x(입력값) + bias(절편)\n",
        "\n",
        "★Activation Function(활성화함수)\n",
        "- synapse는 전달된 전기신호가 최소한의 자극값을 초과하면 활성화되어 다음 뉴런으로 전기신호를 전달한다.\n",
        "- 활성화 함수는 synapse를 모방하여 값이 작을때는 출력값을 작은값으로 막고 일정한 값을 초과하면 출력값이 급격히 커지는 함수를 이용한다.\n",
        "\n",
        "★ 은닉층에서 사용하는 활성화 함수\n",
        "1. 계단함수(step Function)\n",
        "- 입력값이 0을 넘으면 1을 출력하고 그외에는 0을 출력하는 함수\n",
        "\n",
        "def step_function(arg):\n",
        "    if arg > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "step_function(100)\n",
        "step_function(-100)\n",
        "step_function(np.array([100]))\n",
        "step_function(np.array([100,100,-200])) # 여러개 값은 위 함수식으로 안됨\n",
        "\n",
        "def step_function(arg):\n",
        "    return [1 if i > 0 else 0 for i in arg]\n",
        "step_function(np.array([100,100,-200])) #\n",
        "\n",
        "x = np.array([1,100,-200])\n",
        "y = x > 0\n",
        "y\n",
        "bool -> int 변환 : True -> 1, False -> 2\n",
        "y.astype(np.int64) # True를 1로 False를 2로 반환해줌\n",
        "np.sum(y)\n",
        "\n",
        "def step_function(arg):\n",
        "    y = np.array(arg) > 0 \n",
        "    return y.astype(np.int32)\n",
        "\n",
        "step_function(100) # array형식으로 바꾸는 작업이 있어야 출력(astype(np.int32)때문에)\n",
        "step_function(np.array([100]))\n",
        "step_function(np.array([100,100,-200]))\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "x = np.arange(-5,5,0.1)\n",
        "y = step_function(x)\n",
        "plt.plot(x,y)\n",
        "\n",
        "2. sigmoid\n",
        "- 0과 1 사이의 실수 값으로 전달하는 함수\n",
        "- e 자연상수 : 2.7182.....\n",
        "- 요즘 트렌드는 시그모이드 함수를 은닉층에서 사용하지 않는다. \n",
        "(이유는 우리가 구하곶 하는 weight값과 bias를 구하기 위해서 미분을 이용하다보면 sigmoid값이 없어져 버릴 수 있는 현상이 발생하기 때문에)\n",
        "- 출력층에서는 이진분류를 수행할 때 사용한다.\n",
        "\n",
        "x=10\n",
        "np.exp(-x)\n",
        "\n",
        "                1\n",
        "sigmoid = ---------------\n",
        "            1 + np.exp(-x)\n",
        "\n",
        "def sigmoid(arg):\n",
        "    return 1 / (1 + np.exp(-arg))\n",
        "\n",
        "sigmoid(100)\n",
        "sigmoid(-100)\n",
        "\n",
        "x = np.arange(-5,5,0.1)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x,y)\n",
        "\n",
        "3. Relu(Rectified Linear Unit) # 거의 relu 활성화함수를 많이 씀\n",
        "- 입력값이 0을 넘으면 그 입력값으로 출력하고 0이하면 0을 출력\n",
        "\n",
        "def relu(arg):\n",
        "    if arg > 0:\n",
        "        return arg\n",
        "    else :\n",
        "        return 0\n",
        "\n",
        "relu(100)\n",
        "relu(-1000)\n",
        "relu(np.array([10,-10,2]))\n",
        "\n",
        "def relu(arg):\n",
        "    return [i if i > 0 else 0 for i in arg]\n",
        "\n",
        "def relu(arg):\n",
        "    return np.maximum(arg,0) # arg값이 0이랑 비교해서 크면 arg값 작으면 0\n",
        "\n",
        "relu(np.array([10,-10,2]))\n",
        "\n",
        "x = np.arange(-5,5,0.1)\n",
        "y = relu(x)\n",
        "plt.plot(x,y)\n",
        "\n",
        "\n",
        "# 행렬의 곱\n",
        "x1 = np.array([[1,2],[3,4]])\n",
        "x2 = np.array([[5,6],[7,8]])\n",
        "x3 = np.array([[1,2,3],[4,5,6]])\n",
        "x4 = np.array([[5,6],[7,8],[9,10]])\n",
        "x5 = np.array([1,2])\n",
        "\n",
        "x1.shape\n",
        "x2.shape\n",
        "\n",
        "2 * 2 2 * 2\n",
        "np.dot(x1,x2)\n",
        "\n",
        "x3.shape\n",
        "x4.shape\n",
        "2 * 3 3 * 2\n",
        "np.dot(x3,x4)\n",
        "\n",
        "x4.shape\n",
        "x5.shape\n",
        "3 * 2 2\n",
        "np.dot(x4,x5)\n",
        "\n",
        "[문제] 그림을 보고 행렬의 곱으로 표현해보세요.\n",
        "x = np.array([1,2])\n",
        "weight = np.array([[1,3,5],[2,4,6]])\n",
        "np.dot(x,weight)\n",
        "relu(np.dot(x,weight))\n",
        "\n",
        "x = np.array([1,2])\n",
        "weight = np.array([[1,3,5],[2,4,6]])\n",
        "bias = np.array([0.2,0.5,0.7])\n",
        "np.dot(x,weight) + bias\n",
        "relu(np.dot(x,weight) + bias)\n",
        "\n",
        "[문제] 3층 신경망을 구현해보세요.\n",
        "x = np.array([0.1, 0.5])\n",
        "w1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
        "b1 = np.array([0.1,0.2,0.3])\n",
        "hidden1 = relu(np.dot(x,w1) + b1)\n",
        "\n",
        "w2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
        "b2 = np.array([0.1,0.2])\n",
        "hidden2 = relu(np.dot(hidden1,w2) + b2)\n",
        "\n",
        "w3 = np.array([[0.1,0.3],[0.2,0.4]])\n",
        "b3 = np.array([0.1,0.2])\n",
        "y = relu(np.dot(hidden2,w3) + b3)\n",
        "\n",
        "#함수로 만들기\n",
        "def neural(arg1,arg2):\n",
        "    x = np.array([arg1,arg2]) # 입력층\n",
        "    w1  = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
        "    b1 = np.array([0.1,0.2,0.3])\n",
        "    hidden1 = np.dot(x,w1) + b1 # 은닉층 1층\n",
        "    z1 = relu(hidden1)\n",
        "    \n",
        "    w2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
        "    b2 = np.array([0.1,0.2])\n",
        "    hidden2 = np.dot(z1,w2) + b2 # 은닉층 2층\n",
        "    z2 = relu(hidden2)\n",
        "    \n",
        "    w3 = np.array([[0.1,0.3],[0.2,0.4]])\n",
        "    b3 = np.array([0.1,0.2])\n",
        "    hidden3 = np.dot(z2,w3) + b3 # 출력층(3층)\n",
        "    y = relu(hidden3)\n",
        "    return y # 결과 반환\n",
        "\n",
        "neural(0.1,0.5)\n",
        "\n",
        "#--강사님\n",
        "\n",
        "은닉층 1 = weight * 입력값 + bias\n",
        "relu(은닉층 1)\n",
        "\n",
        "x = np.array([0.1,0.5]) # 입력층\n",
        "w1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
        "b1 = np.array([0.1,0.2,0.3])\n",
        "\n",
        "# 은닉층(1층)\n",
        "h1 = np.dot(x,w1) + b1\n",
        "z1 = relu(h1)\n",
        "# 은닉층(1층)\n",
        "a1 = 0.1 * 0.1 + 0.5 * 0.2 + 0.1\n",
        "a2 = 0.1 * 0.3 + 0.5 * 0.4 + 0.2\n",
        "a3 = 0.1 * 0.5 + 0.5 * 0.6 + 0.3\n",
        "\n",
        "w2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
        "b2 = np.array([0.1,0.2])\n",
        "# 은닉층(2층)\n",
        "h2 = np.dot(z1,w2) + b2\n",
        "z2 = relu(h2)\n",
        "\n",
        "w3 = np.array([[0.1,0.3],[0.2,0.4]])\n",
        "b3 = np.array([0.1,0.2])\n",
        "\n",
        "# 출력층(3층)\n",
        "z3 = np.dot(z2,w3) + b3\n",
        "y = relu(z3)\n",
        "y\n",
        "\n"
      ]
    }
  ]
}