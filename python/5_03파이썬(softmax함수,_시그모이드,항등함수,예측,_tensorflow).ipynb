{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_3파이썬(softmax함수, 시그모이드,항등함수,예측, tensorflow).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcXcRvxwvbNjDqgpFAvGGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehdghks316/itwill_studyGroup_D/blob/main/5_3%ED%8C%8C%EC%9D%B4%EC%8D%AC(softmax%ED%95%A8%EC%88%98%2C_%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%2C%ED%95%AD%EB%93%B1%ED%95%A8%EC%88%98%2C%EC%98%88%EC%B8%A1%2C_tensorflow).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1ZPMX12jFbN"
      },
      "outputs": [],
      "source": [
        "2022.5.3\n",
        "\n",
        "\n",
        "입력  weight      출력      정답\n",
        "1 --------------> 1.5       2\n",
        "      bias\n",
        "y_hat = sigmoid(weight * 1 + bias)\n",
        "y_hat(y^)\n",
        "2 y_hat = 0.5 loss(or cost, error) # 입력을 1을 넣었을 때 정답은 2이지만 출력된 결과는 1.5가 나왔다. 즉 손실값이 0.5이다.\n",
        "\n",
        "최종값이 2가 될 수 있도록 오차를 줄이기 위해서 weight값, bias값을 미분을 통해서 조정해야 한다.(값을 찾는다.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "★ 출력층에서 사용하는 활성화 함수\n",
        "- 분류(classification) : sigmoid, softmax function\n",
        "- 회귀(regression) : 항등함수(identity function)\n",
        "\n",
        "1. sigmoid\n",
        "- binary classification, 이진분류\n",
        " \n",
        "2. softmax function(소프트맥스 함수)\n",
        "- multi classification(다중 분류시 사용)\n",
        "- 0 ~ 1 사이의 숫자로 출력되는 함수\n",
        "- 출력층에는 다중 분류하는 개수만큼 \n",
        "- 확률값 처럼 사용\n",
        "\n",
        "예)\n",
        "    강아지     0.7\n",
        "    고양이     0.1     가장 높은 확률인 0.7인 강아지로 분류\n",
        "    사자       0.2\n",
        "------------------ 합\n",
        "                1    \n",
        "\n",
        "import numpy as np\n",
        "x = np.array([-1.2,0.9,0.4,2])\n",
        "s = np.exp(x)/np.sum(np.exp(x)) # softmax 함수식\n",
        "np.sum(s)\n",
        "np.argmax(s)\n",
        "\n",
        "def softmax_function(arg):\n",
        "    return np.exp(arg) / np.sum(np.exp(arg))\n",
        "\n",
        "softmax_function(x)\n",
        "\n",
        "x = np.array([100,1000,10000])\n",
        "x = np.array([100-10000,1000-10000,10000-10000])\n",
        "softmax_function(x)\n",
        "\n",
        "# softmax_function 오버플로우를 막기위해서 최대값을 빼준 다음에 계산작을 하기(값의 차이가 엄청 크면 오버플로우 발생)\n",
        "def softmax_function(arg):\n",
        "    return np.exp(arg) / np.sum(np.exp(arg-np.max(arg)))\n",
        "\n",
        "x = np.array([100,1000,10000])\n",
        "softmax_function(x)\n",
        "\n",
        "\n",
        "3. 항등함수(identity function)\n",
        "- 입력값을 받아서 그대로 출력하는 함수, 입력과 출력이 항상 같다.\n",
        "\n",
        "def identity_function(arg):\n",
        "    return arg\n",
        "\n",
        "\n",
        "[문제] 7를 입력하면 출력값을 예측해주세요.?\n",
        "\n",
        "입력(x)   출력(y)\n",
        "1           2\n",
        "2           4\n",
        "3           6\n",
        "4           8\n",
        "5           10\n",
        "6           12\n",
        "7           ?\n",
        "x = np.array([1,2,3,4,5,6])\n",
        "y = np.array([2,4,6,8,10,12])\n",
        "\n",
        "linear regression\n",
        "y = 기울기 * x + 절편\n",
        "\n",
        "최소제곱법(ordinary least sqare), 경사하강법\n",
        "            y증가량    합((x - x평균) * (y-y평균))\n",
        "기울기 = ---------- = ------------------\n",
        "            x증가량    합((x - x평균)**2)\n",
        "            \n",
        "절편 = y평균 - (x평균 * 기울기)\n",
        "\n",
        "x = np.array([1,2,3,4,5,6]) # 입력값\n",
        "y = np.array([2,4,6,8,10,12]) # 출력값 정답\n",
        "\n",
        "d = sum((x - np.mean(x))**2) # 합((x-x평균)**2)\n",
        "s = sum((x-np.mean(x)) * (y-np.mean(y))) #합((x - x평균) * (y-y평균))\n",
        "ss = s/d # 기울기, slope\n",
        "i = np.mean(y) - (np.mean(x)*ss) # 절편,intercept\n",
        "ss * 7 + i\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x,y)\n",
        "plt.plot(x,x*ss+i,c='red')\n",
        "\n",
        "from scipy import stats\n",
        "stats.linregress(x,y) # 기울기, 절편 함수 하나로 모두 구하기\n",
        "stats.linregress(x,y).slope # 기울기\n",
        "stats.linregress(x,y).intercept # 절편\n",
        "\n",
        "y(목표) = weight * 입력 + bias\n",
        "\n",
        "feed forward(순방향)\n",
        "==================>>>\n",
        "        weight = ?\n",
        "입력 --------------> 출력\n",
        "        bias = 1\n",
        "입력 : 1            출력(목표) : 4\n",
        "\n",
        "4  = weight * 1 + 1\n",
        "\n",
        "weight   예측값   오차(목표-예측값) 오차가 0에 가까운값의 weight 값을 사용\n",
        "1          2            2\n",
        "2          3            1\n",
        "2.5         3.5         0.5\n",
        "3           4           0\n",
        "\n",
        "        weight = 2\n",
        "입력 --------------> 출력\n",
        "        bias = ?\n",
        "입력 : 1            출력(목표) : 4\n",
        "\n",
        "4  = 2 * 1 + bias\n",
        "\n",
        "bias   예측값   오차(목표-예측값) 오차가 0에 가까운값의 bias 값을 사용\n",
        "1       3       1\n",
        "1.5     3.5     0.5\n",
        "2       4       0\n",
        "\n",
        "경사하강법(Gradient descendent method)\n",
        "- 미분계수 : 기울기, 평균변화율, 순간변화율\n",
        "- 한점에서 접선의 기울기\n",
        "\n",
        "MSE(Mean Squared Error)\n",
        "- 실제값과 에측값의 차이를 제곱해 평균한 값\n",
        "\n",
        "y = 2 # 실제값\n",
        "y_hat = 0.5 * 1 +0 # y_hat = weight*x + bias\n",
        "error = ((y_hat - y)**2).mean() # mse\n",
        "error # 2.25\n",
        "\n",
        "x = np.array([1])\n",
        "y = np.array([2])\n",
        "weight = 0.5\n",
        "bias = 0\n",
        "y_hat = weight * x + bias\n",
        "error = ((y_hat-y)**2).mean() # error가 최소가 될 수 있도록 weight값을 조정\n",
        "error # 2.25                -----> 0\n",
        "\n",
        "# 이 부분이 반복\n",
        "learning_rate = 0.25 # 경사하강에서 몇씩 줄이면서 학습할 것인가?(학습을 하다가 na값이 나오면 learning_rate를 잘못 조정한 것)\n",
        "weight = weight - learning_rate * ((y_hat -y)*x).mean() # 0.5 -> 0.875 -> 0.6875 -> 0.78125\n",
        "bias = bias - learning_rate * (y_hat-y).mean() # 0 -> 0.375 -> 0.9375 -> 1.03125\n",
        "\n",
        "y_hat = weight * x + bias # 0.5 -> 1.25 -> 1.625 -> 1.8125\n",
        "error = ((y_hat-y)**2).mean() \n",
        "error # 2.25  -> 0.5625 -> 0.140625 -> 0.03515\n",
        "\n",
        "# 최종결과\n",
        "weight = 0.78\n",
        "bias = 1.03\n",
        "y_hat = weight * x + bias\n",
        "y_hat = 1.8125\n",
        "\n",
        "\n",
        "#---------------\n",
        "위 내용을 프로그래밍 (경사하강법) # 혼자 코드 짤 수 있어야함\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_epoch = 1000\n",
        "erros = []\n",
        "\n",
        "x = np.array([1,2,3,4,5,6]) # 입력값\n",
        "y = np.array([2,4,6,8,10,12]) # 출력값 정답\n",
        "w = np.random.uniform(low=-1.0,high=1.0) #난수값 , 어떤 값을 처음에 넣어야할지 모르겠을 때 랜덤으로 넣고 아무값이나 난수값 하나 리턴하는 함수(예측을 하기 위해서 weight, bias를 어떤 값을 넣어야할지가 목표)\n",
        "b = np.random.uniform(low=-1.0,high=1.0)\n",
        "\n",
        "\n",
        "for epoch in range(n_epoch):    \n",
        "    # 예측값\n",
        "    y_hat = w * x + b \n",
        "    \n",
        "    # 손실함\n",
        "    loss = ((y_hat - y)**2).mean()\n",
        "    erros.append(loss)\n",
        "    if loss < 0.0005: # loss값이 0.0005보다 작아지면 나오기\n",
        "        break\n",
        "    \n",
        "    # 미분값 적용\n",
        "    w = w - learning_rate * ((y_hat-y)*x).mean()\n",
        "    b = b - learning_rate * (y_hat-y).mean()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print(\"{}, w={}, b={}, loss={}\".format(epoch,w,b,loss))\n",
        "        \n",
        "plt.plot(erros)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------\n",
        "★ Tensorflow\n",
        "- 구글이 오픈소스로 공개한 머신러닝 라이브러리\n",
        "- 다차원 행렬계산(tensor), 대규모 숫자 계산\n",
        "- 빅데이터 처리를 위한 병렬컴퓨터지원을 한다.\n",
        "- C++로 맏르어진 라이브러리\n",
        "- CPU, GPU \n",
        "- C++, PYTHON, JAVA\n",
        "- pip install tensorflow-cpu\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "t = tf.constant('tensorflow')\n",
        "print(t)\n",
        "t.numpy()\n",
        "\n",
        "x = tf.constant(1234)\n",
        "y = tf.constant(5678)\n",
        "add_op = x+y\n",
        "add_op.numpy()\n",
        "\n",
        "a = tf.constant(1,name='a') # 상수 선언, name옵션은 보이지는 않지만 코멘트를 달아놓는다는 느낌\n",
        "b = tf.constant(2,name='b')\n",
        "c = tf.constant(3,name='c')\n",
        "z = tf.Variable(0,name='z') # 변수 선언\n",
        "\n",
        "z = a + b * c\n",
        "y = a + b * c # 바로 변수 초기화( 초창기tensorflow에서는 안됨)\n",
        "\n",
        "x1 = tf.constant([[1,2,3],[4,5,6]]) \n",
        "x1.shape\n",
        "x2 = tf.constant([[1,2],[3,4],[5,6]])\n",
        "tf.matmul(x1,x2) # tf.matmul(배열1,2) : 행렬의 곱\n",
        "\n",
        "np.dot(x1,x2) # 초창기 버전에서는 np.array로 바꾸고 했어야했는데 현재 버전에서는 바로 수행 가능\n",
        "\n",
        "tf.math.add(10,20) # 더하기\n",
        "tf.add(100,200) # math 안 써도 수행됨\n",
        "\n",
        "tf.math.subtract(100,90) # 빼기\n",
        "tf.subtract(100,90) \n",
        "\n",
        "tf.math.multiply(2,3) # 곱하기\n",
        "tf.multiply(2,3)\n",
        "\n",
        "tf.math.truediv(3,6) # 나누기\n",
        "tf.truediv(3,6)\n",
        "\n",
        "tf.math.divide(3,6) # 나누기\n",
        "tf.divide(3,6) \n",
        "\n",
        "tf.math.mod(7,2) # 나머지\n",
        "tf.mod(7,2) # 오류 (지원x) -> 이런 것 때문에 대부분math를 써서 사용하는것에 익숙해지자\n",
        "\n",
        "\n",
        "[문제]tensorflow 상수를 이용해서 아래와 같이 결과를 출력하는 프로그램을 만드세요. \n",
        "Add : 6\n",
        "Multiply : 8\n",
        "\n",
        "def Add(arg1,arg2):\n",
        "    x1 = tf.constant(arg1)\n",
        "    x2 = tf.constant(arg2)\n",
        "    return print(f'Add :{tf.math.add(x1,x2)}')\n",
        "\n",
        "def Multiply(arg1,arg2):\n",
        "    x1 = tf.constant(arg1)\n",
        "    x2 = tf.constant(arg2)\n",
        "    return print(f'Multiply : {tf.multiply(x1,x2)}')\n",
        "\n",
        "Add(1,2)\n",
        "Multiply(1,2)\n",
        "\n",
        "class tens:\n",
        "    def __init__(self,x,y):\n",
        "        self.x = tf.constant(x)\n",
        "        self.y = tf.constant(y)\n",
        "        \n",
        "    def Add(self):\n",
        "        return tf.math.add(self.x,self.y)\n",
        "    def Multiply(self):\n",
        "        return tf.math.multiply(self.x,self.y)\n",
        "\n",
        "t = tens(20,30)\n",
        "t.Add()\n",
        "t.Multiply()\n"
      ]
    }
  ]
}
