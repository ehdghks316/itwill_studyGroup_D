{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_22파이썬(Randomforest,).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbnS4ivSvUvcxfqQptRbWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehdghks316/itwill_studyGroup_D/blob/main/4_22%ED%8C%8C%EC%9D%B4%EC%8D%AC(Randomforest%2C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfafVNXRqogG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "titanic = pd.read_csv('c:/data/titanic.csv')\n",
        "titanic.info()\n",
        "titanic.head()\n",
        "titanic.info()\n",
        "# 종속변수, 목표변수, 결과변수, 정답레이블 : survived 컬럼\n",
        "titanic.survived.unique()\n",
        "0  = 사망 , 1 = 생존\n",
        "\n",
        "# 설명변수, 입력변수, 독립변수\n",
        "    # 티켓등급\n",
        "titanic.pclass.unique()\n",
        "    # 성별\n",
        "titanic.gender.unique()\n",
        "    # 나이\n",
        "titanic.age.describe()\n",
        "    # 함께 탐승한 형제자매, 배우자 수\n",
        "titanic.sibsp.describe()\n",
        "    # 함께 탑승한 부모님, 자식수\n",
        "titanic.parch.describe()\n",
        "    # 티켓번호\n",
        "titanic.ticket\n",
        "    # 운임\n",
        "titanic.fare.describe()\n",
        "    # 객실번호\n",
        "titanic.cabin\n",
        "    # 탑승항구\n",
        "titanic.embarked.unique()\n",
        "S = Southampton, Q = Queenstown, C = Cherbourg\n",
        "\n",
        "# 2개의 문자값을 수치형으로 바꾸는 작업(female->0 male->1)\n",
        "1.\n",
        "titanic.gender.map({'female':0,'male':1})\n",
        "\n",
        "2.\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "gender_le = LabelEncoder()\n",
        "titanic.gender = gender_le.fit_transform(titanic['gender'])\n",
        "titanic.gender\n",
        "Counter(titanic.gender)\n",
        "\n",
        "# 열별로 null값의 수\n",
        "titanic.isnull().sum()\n",
        "\n",
        "# 특정 열의 null값 확인\n",
        "titanic.age.isnull().sum()\n",
        "\n",
        "titanic.age.describe()\n",
        "\n",
        "# age 중앙값\n",
        "titanic.age.median()\n",
        "\n",
        "# age null값을 중앙값으로 수정\n",
        "titanic.age.fillna(titanic.age.median(),inplace=True)\n",
        "titanic.age.isnull().sum()\n",
        "\n",
        "Counter(titanic.embarked)\n",
        "\n",
        "# one-hot-encoding\n",
        "     C  Q  S\n",
        "0    0  0  1\n",
        "1    1  0  0\n",
        "2    0  0  1\n",
        "3    0  0  1\n",
        "4    0  0  1\n",
        "pd.get_dummies(titanic.embarked,prefix='embarked') # one-hot-encoding 작업 수행, prefix=접두어\n",
        "     embarked_C  embarked_Q  embarked_S\n",
        "0             0           0           1\n",
        "1             1           0           0\n",
        "2             0           0           1\n",
        "3             0           0           1\n",
        "4             0           0           1\n",
        "..          ...         ...         ...\n",
        "886           0           0           1\n",
        "887           0           0           1\n",
        "888           0           0           1\n",
        "889           1           0           0\n",
        "890           0           1           0\n",
        "\n",
        "embarked_dummies = pd.get_dummies(titanic.embarked,prefix='embarked')\n",
        "\n",
        "titanic = pd.concat([titanic,embarked_dummies],axis=1) # concat : 열 or 행 단위로 붙이기\n",
        "titanic.info()\n",
        "\n",
        "feature_col = ['pclass','gender','age','embarked_S','embarked_Q']\n",
        "x = titanic[feature_col] # 학습할 데이터\n",
        "y = titanic.survived # 정답 데이터\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x,y)\n",
        "model.classes_\n",
        "z = pd.DataFrame({'features':feature_col,\n",
        "              'importance' : model.feature_importances_})\n",
        "\n",
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "z.plot()\n",
        "\n",
        "[문제204] 유방암 데이터를 의사결정나무를 이용해서 분류해주세요.\n",
        "wisc = pd.read_csv('c:/data/wisc_bc_data.csv')\n",
        "wisc.info()\n",
        "wisc\n",
        "# 정답레이블\n",
        "wisc.diagnosis\n",
        "\n",
        "# 정답레이블 수치화\n",
        "wisc.diagnosis = wisc.diagnosis.map({'B':'Benign','M':'Malignant'})\n",
        "Counter(wisc.diagnosis)\n",
        "\n",
        "# null값 확인\n",
        "wisc.isnull().sum()\n",
        "\n",
        "\n",
        "x = wisc.iloc[:,2:]\n",
        "y = wisc.iloc[:,1]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x,y)\n",
        "\n",
        "x.columns\n",
        "model.feature_importances_\n",
        "pd.DataFrame({'features':x.columns,\n",
        "              'importance':model.feature_importances_})\n",
        "\n",
        "#------------------------------------- 강사님\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = wisc.iloc[:,2:]\n",
        "y = wisc.diagnosis\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "wisc_model = DecisionTreeClassifier()\n",
        "wisc_model.fit(x_train,y_train)\n",
        "\n",
        "wisc_model.score(x_train,y_train)\n",
        "wisc_model.score(x_test,y_test)\n",
        "\n",
        "y_pred = wisc_model.predidct(x_test)\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n",
        "wisc_result = pd.DataFrame({'feature':x.columns,'importance':wisc_model.feature_importances_})\n",
        "wisc_result.sort_values(by='importance',ascending=False)\n",
        "\n",
        "#------------------------------\n",
        "dtree = DecisionTreeClassifier()\n",
        "parameters = {'max_depth':[5,6,7,8,9],'min_samples_split':[4,5,6,7,8,9,10]}\n",
        "grid_tree = GridSearchCV(dtree,param_grid=parameters,cv=5,refit=True,return_train_score=True)\n",
        "grid_tree.fit(x_train,y_train)\n",
        "scores_df = pd.DataFrame(grid_tree.cv_results_)\n",
        "scores_df[['params','mean_test_score','rank_test_score']]\n",
        "\n",
        "print('최적 파라미터',grid_tree.best_params_)\n",
        "print('최고 정확도',grid_tree.best_score_)\n",
        "\n",
        "y_pred = grid_tree.predict(x_test)\n",
        "accuracy_score(y_pred,y_test)\n",
        "\n",
        "tree model = grid_tree.best_estimator_\n",
        "accuracy_score(tree_model.predict(x_test),y__test)\n",
        "tree_model.feature_importances_\n",
        "wisc_result = pd.DataFrame({'feature':x.columns,'importance':tree_model.feature_importances_})\n",
        "wisc_result.sort_values(by='importance',ascending=False)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classifiaction_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "▶RandomForest\n",
        "- 매 실행시 마다 랜덤하게 관측치와 변수(컬럼)를 선택하므로 실행결과가 조금씩 달라지게 된다.\n",
        "- decision tree와 bagging을 결합한 알고리즘\n",
        "- 학습데이터에서 중복을(복원추출) 허용하여 랜덤샘플링을 통해서 의사결정나무모델을 구축\n",
        "  학습데이터 수 만큼 샘플링한다. 배깅(bagging, bootstrap aggregating)\n",
        "- 의사결정나무 모델 구축시 변수도 무작위 선택한다. 단 하나의 모델안에서 변수는 중복불가능\n",
        "- 의사결정나무 모델 결과의 투표를 통해서 클래스를 선택한다.\n",
        "\n",
        "\n",
        "iris = pd.read_csv('c:/data/iris.csv')\n",
        "iris.info()\n",
        "iris.sample(n=150,replace=True) # sample : 데이터에서 랜덤으로 추출, 150개를 복원추출\n",
        "\n",
        "import random\n",
        "\n",
        "col_idx = []\n",
        "\n",
        "for i in range(2):\n",
        "    idx = random.randint(0,3) # 0~3까지 랜덤하게 하나 뽑기\n",
        "    while idx in col_idx:\n",
        "        idx = random.randint(0,3)\n",
        "    col_idx.append(idx)\n",
        "\n",
        "col_idx\n",
        "\n",
        "data = iris.sample(n=150,replace=True)\n",
        "x_train = data[data.columns[col_idx]]\n",
        "y_train = data.Name\n",
        "\n",
        "iris_model = DecisionTreeClassifier()\n",
        "iris_model.fit(x_train,y_train)\n",
        "iris_model.score(x_train,y_train)\n",
        "\n",
        "iris_result = pd.DataFrame({'feature':x_train.columns,'importance':iris_model.feature_importances_})\n",
        "iris_result.sort_values(by='importance',ascending=False)\n",
        "\n",
        "pred_data = [5.1,3.5,1.4,0.2]\n",
        "pred_data[col_idx[0]]\n",
        "pred_data[col_idx[1]]\n",
        "\n",
        "q = []\n",
        "q.append(iris_model.predict([[pred_data[col_idx[0]],pred_data[col_idx[1]]]])[0])\n",
        "q\n",
        "\n",
        "Counter(q).most_common(1)[0][0]\n",
        "\n",
        "\n",
        "#--------------------------\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wisc = pd.read_csv('c:/data/wisc_bc_data.csv')\n",
        "wisc.info()\n",
        "wisc.diagnosis = wisc.diagnosis.map({'B':'Benign','M':'Malignant'})\n",
        "Counter(wisc.diagnosis)\n",
        "x = wisc.iloc[:,2:]\n",
        "y = wisc.diagnosis\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#oob_score(out-of-bag_score) 부트스트랩(랜덤하게 중복샘플링) 샘플링시 선택되지 않은 샘플\n",
        "model_rf = RandomForestClassifier(n_estimators=1000,oob_score=True)\n",
        "model_rf.fit(x_train,y_train)\n",
        "model_rf.score(x_train,y_train)\n",
        "model_rf.score(x_test,y_test) # decisiontree와의 차이 비교해보기\n",
        "model_rf.oob_score_\n",
        "\n",
        "confusion_matrix(y_test,model_rf.predict(x_test))\n",
        "\n",
        "\n",
        "rftree = RandomForestClassifier()\n",
        "parameters = {'max_depth':[5,6,7,8,9],'min_samples_split':[4,5,6,7,8,9,10],'max_features':[5,6,7,8,9,10],'n_estimators':[100,200,300,400,500]}\n",
        "grid_tree = GridSearchCV(rftree,param_grid=parameters,cv=5,refit=True,return_train_score=True,n_jobs=-1) # n_jobs=-1 컴퓨터의 모든 cpu를 다 사용해서 처리하겠어( 다른 프로그램들은 느려질 수 있음)\n",
        "grid_tree.fit(x_train,y_train) # 상당히 오래걸림\n",
        "scores_df = pd.DataFrame(grid_tree.cv_results_)\n",
        "scores_df[['params','mean_test_score','rank_test_score']]\n",
        "\n",
        "print('최적 파라미터',grid_tree.best_params_)\n",
        "print('최고 정확도',grid_tree.best_score_)\n",
        "\n",
        "y_pred = grid_tree.predict(x_test)\n",
        "accuracy_score(y_pred,y_test)\n",
        "\n",
        "tree model = grid_tree.best_estimator_\n",
        "accuracy_score(tree_model.predict(x_test),y__test)\n",
        "tree_model.feature_importances_\n",
        "wisc_result = pd.DataFrame({'feature':x.columns,'importance':tree_model.feature_importances_})\n",
        "wisc_result.sort_values(by='importance',ascending=False)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classifiaction_report(y_test,y_pred))"
      ]
    }
  ]
}
