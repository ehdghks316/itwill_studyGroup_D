{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_13파이썬(train_test_split,혼동행렬).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8//v56T37IZhb/NFI8AEg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehdghks316/itwill_studyGroup_D/blob/main/4_13%ED%8C%8C%EC%9D%B4%EC%8D%AC(train_test_split%2C%ED%98%BC%EB%8F%99%ED%96%89%EB%A0%AC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8eeoBeYXP50"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "survey = pd.read_csv('c:/data/naive_survey.csv',header=None, names=['sentens','class']) #컬럼이름이 없으면 header=None하고 names로 이름 설정\n",
        "survey\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(survey['sentens'],survey['class'],test_size=0.2) # 학습데이터와 테스트 데이터로 나누기\n",
        "len(x_train)\n",
        "len(x_test)\n",
        "Counter(y_train)\n",
        "Counter(y_test)\n",
        "\n",
        "# 학습데이터\n",
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "x_train = cv.fit_transform(x_train)\n",
        "cv.get_feature_names()\n",
        "x_train.toarray()\n",
        "\n",
        "# 테스트데이터\n",
        "x_test = cv.transform(x_test) # 위에서 fit작업이 완료되어 사전이 만들어져 있고 transform 작업만하면 됨\n",
        "x_test.toarray()\n",
        "\n",
        "# 학습 모델\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train,y_train)\n",
        "\n",
        "# 예측\n",
        "y_predict = nb.predict(x_test)\n",
        "y_predict == y_test # 정답 일치 확인\n",
        "sum(y_predict == y_test) # 정답이 몇개인지 확인\n",
        "sum(y_predict == y_test)/3 # 정답률\n",
        "\n",
        "# 정답률 함수\n",
        "accuracy_score(y_test,y_predict) # accuracy_score(테스트데이터 정답라벨, 예측한 테스트데이터)\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(survey['sentens'],survey['class'],test_size=0.2) # 학습데이터와 테스트 데이터로 나누기\n",
        "Counter(y_train)\n",
        "Counter(y_test)\n",
        "\n",
        "#한꺼번에 모든문장을 넣어서 형태소분석을 하는건 메모리에 문제 생길 수 있으니 \n",
        "#한 문장씩 형태소 분석하는 것 (찾아보기 이전에 수업에서 했었음)\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "def okt_pos(arg):\n",
        "    token_corpus = []\n",
        "    for i in okt.pos(arg):\n",
        "        if i[1] in ['Noun','Adjective']:\n",
        "            token_corpus.append(i[0])\n",
        "    token_corpus = [word for word in token_corpus if len(word) >= 2]\n",
        "    return token_corpus\n",
        "\n",
        "okt_pos(x_train[0])\n",
        "\n",
        "# 학습데이터\n",
        "cv = CountVectorizer(tokenizer=okt_pos)\n",
        "x_train = cv.fit_transform(x_train)\n",
        "cv.get_feature_names()\n",
        "x_train.toarray()\n",
        "\n",
        "# 테스트데이터\n",
        "x_test = cv.transform(x_test) # 위에서 fit작업이 완료되어 사전이 만들어져 있고 transform 작업만하면 됨\n",
        "x_test.toarray()\n",
        "\n",
        "# 학습 모델\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train,y_train)\n",
        "\n",
        "# 예측\n",
        "y_predict = nb.predict(x_test)\n",
        "y_predict == y_test # 정답 일치 확인\n",
        "sum(y_predict == y_test) # 정답이 몇개인지 확인\n",
        "sum(y_predict == y_test)/3 # 정답률\n",
        "\n",
        "# 정답률 함수\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "\n",
        "★★ 혼동행렬(confusion matrix)\n",
        "- 모델 성능을 평가할 때 사용되는 지표\n",
        "- 예측값이 실제값을 얼마나 정확하게 예측했는지를 보여주는 행렬\n",
        "\n",
        "# 혼동행렬 crosstab\n",
        "pd.crosstab(y_test,y_predict)\n",
        "\n",
        "\n",
        "        predict(예측)\n",
        "   col_0  긍정  부정\n",
        "   class        \n",
        "실 긍정      1   0\n",
        "제 부정      1   1\n",
        "\n",
        "            예측(긍정) 예측(부정)\n",
        "------------------------\n",
        "실제(긍정)      TP          FN\n",
        "실제(부정)      FP          TN\n",
        "\n",
        "TP(True Positive) : 참긍정, 긍정이라고 예측을 했는데 실제도 긍정\n",
        "TN(True Negative) : 참부정, 부정이라고 예측을 했는데 실제도 부정\n",
        "FP(False Positive) : 거짓긍정, 긍정이라고 예측을 했는데 실제는 부정\n",
        "FN(False Negative) : 거짓부정, 부정이라고 예측을 했는데 실제는 긍정 (제일 줄여야하는 부분 ex) 암이 아니라고 했는데 알고보니 암이다.)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "confusion_matrix(y_test,y_predict)\n",
        "array([[1, 0],\n",
        "       [1, 1]], dtype=int64)\n",
        "\n",
        "print(classification_report(y_test,y_predict)) # 포맷문자가 섞여있어서 print해줘야 깔끔\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          긍정       0.50      1.00      0.67         1\n",
        "          부정       1.00      0.50      0.67         2\n",
        "\n",
        "    accuracy                           0.67         3\n",
        "   macro avg       0.75      0.75      0.67         3\n",
        "weighted avg       0.83      0.67      0.67         3\n",
        "\n",
        "▶정확도(accuracy)\n",
        "- 모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는 지를 나타내는 지표\n",
        "\n",
        "정확도 = 예측결과와 실제값이 동일한 건수 / 전체 데이터 수\n",
        "        = (TP+TN) / (TP+TN+FP+FN)\n",
        "\n",
        "▶정밀도(precision) # 예측에서 실제\n",
        "- 정밀도는 긍정 클래스에 속한다고 예측한 값이 실제도 긍정클래스에 속하는 비율\n",
        "- 정밀도는 부정 클래스에 속한다고 예측한 값이 실제도 부정클래스에 속하는 비율\n",
        "\n",
        "긍정정밀도 = TP / (TP+FP)\n",
        "부정정밀도 = FN / (TN+FN)\n",
        "\n",
        "▶재현율(recall) # 실제에서 예측\n",
        "- 실제값 중에서 모델이 검출한 실제값의 비율을 나타내는 지표\n",
        "\n",
        "긍정재현율 = TP / (TP+FN)\n",
        "부정재현율 = TN / (FP+TN)\n",
        "\n",
        "▶f1-scor\n",
        "- 정밀도도 중요하고 재현율도 중요한데 둘 중 무엇을 사용해야 할지 고민될 때\n",
        "두 값을 조화평균 내서 하나의 수치로나타낸 지표\n",
        "# like 시간당 속도로 시속구하는 것 처럼 두 값을 조화평균내서 수치로\n",
        "\n",
        "긍정 f1-score = (긍정재현율*긍정정밀도*2) / (긍정재현율+긍정정밀도) \n",
        "부정 f1-score = (부정재현율*부정정밀도*2) / (부정재현율+부정정밀도) "
      ]
    }
  ]
}
