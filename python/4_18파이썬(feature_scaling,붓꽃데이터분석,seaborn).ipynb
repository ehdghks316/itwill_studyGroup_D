{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_18파이썬(feature scaling,붓꽃데이터분석,seaborn).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPV5gV8eFBlbmVwQj1ym1oF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehdghks316/itwill_studyGroup_D/blob/main/4_18%ED%8C%8C%EC%9D%B4%EC%8D%AC(feature_scaling%2C%EB%B6%93%EA%BD%83%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%2Cseaborn).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4INsYLPLLft"
      },
      "outputs": [],
      "source": [
        "[문제198] bmi 데이터를 이용해서 키 : 178 몸무게 : 71 일 때 분류해주세요.\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "bmi = pd.read_csv('c:/data/bmi.csv')\n",
        "x_train = np.array(bmi.iloc[:,0:2])\n",
        "label = bmi['label']\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "clf.fit(x_train,label)\n",
        "clf.predict([[178,71]])[0]\n",
        "clf.predict([[173,83]])[0]\n",
        "\n",
        "\n",
        "# 강사님\n",
        "bmi.iloc[:,0:2] # 설명변수, 입력변수, 독립변수 : 종속변수에 영향을 주는 변수\n",
        "bmi.label # 종속변수, 결과변수 : 영향을 받는 변수\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(bmi.iloc[:,0:2],bmi.label,test_size=0.2)\n",
        "x_train.shape\n",
        "y_train.shape\n",
        "x_test.shape\n",
        "y_test.shape\n",
        "\n",
        "Counter(y_train)\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.classes_\n",
        "\n",
        "y_predict = clf.predict(x_test)\n",
        "sum(y_predict == y_test)/len(y_test) # 정답률\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "clf.score(x_test,y_test)\n",
        "\n",
        "\n",
        "pd.crosstab(y_test,y_predict)\n",
        "col_0    fat  normal  thin\n",
        "label                     \n",
        "fat     1524      11     0\n",
        "normal     5    1180    10\n",
        "thin       0       6  1264\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "clf.predict(np.array([[178,71]]))[0]\n",
        "\n",
        "import pickle\n",
        "file = open(\"c:/data/clf_knn.pkl\",\"wb\")\n",
        "pickle.dump(clf,file)\n",
        "file.close()\n",
        "\n",
        "file = open(\"c:/data/clf_knn.pkl\",\"rb\")\n",
        "clf_knn = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "clf_knn.classes_\n",
        "clf_knn.predict(np.array([[178,71]]))[0]\n",
        "# 정확도 등 잘 나오면 모델을 저장해놓기\n",
        "\n",
        "[문제199] k값의 변화에 따른 정확도를 그래프로 시각화해주세요.\n",
        "# k값을 증가시키면서 정확도마다의 그래프 점을 표시\n",
        "clf = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager,rc\n",
        "font_name = font_manager.FontProperties(fname=\"c:/windows/fonts/HMKMMAG.TTF\").get_name()\n",
        "rc('font',family=font_name)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(bmi.iloc[:,0:2],bmi.label,test_size=0.2)\n",
        "accuracy = []\n",
        "for k in range(1,100,2):\n",
        "    clf = KNeighborsClassifier(n_neighbors=k)\n",
        "    clf.fit(x_train,y_train)\n",
        "    accuracy.append(clf.score(x_test,y_test))\n",
        "\n",
        "df = DataFrame(accuracy)    \n",
        "df.plot()\n",
        "plt.plot(range(1,100,2),accuracy)\n",
        "\n",
        "\n",
        "★ Feature Scaling\n",
        "- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "- 표준화(standardization)\n",
        "    평균 0, 표준편차 1인 표준정규분포를 가진 값으로 변환\n",
        "    \n",
        "         관측값 - 평균\n",
        "표준화 = -------------\n",
        "           표준편차\n",
        "\n",
        "- 정규화(normalization)\n",
        " 최소값과 최대값을 사용해서 0 ~ 1 사이의 데이터로 변환\n",
        "                 x - x.min()\n",
        " 정규화 = ---------------------\n",
        "             x.max() - x.min()\n",
        "\n",
        "x =np.arange(9,dtype=np.float) - 3\n",
        "x.shape\n",
        "x.reshape(9,1)\n",
        "np.reshape(x,(9,1))\n",
        "x = x.reshape(-1,1)\n",
        "x.shape\n",
        "pd.DataFrame(x).describe()\n",
        "x = np.vstack([x,[100]])\n",
        "pd.DataFrame(x).describe()\n",
        "\n",
        "y = (x - np.mean(x)) / np.std(x)\n",
        "pd.DataFrame(y).describe()\n",
        "np.mean(y)\n",
        "np.std(y)\n",
        "\n",
        "(x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "s = StandardScaler()\n",
        "s.fit_transform(x)\n",
        "\n",
        "s = StandardScaler().fit(x)\n",
        "r = s.transform(x)\n",
        "\n",
        "np.mean(r)\n",
        "np.std(r)\n",
        "\n",
        "s.mean_\n",
        "s.scale_\n",
        "np.sqrt(s.var_)\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "scale(x)\n",
        "\n",
        "np.mean(scale(x))\n",
        "np.std(scale(x))\n",
        "\n",
        "np.mean(x)\n",
        "np.std(x)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "m = MinMaxScaler()\n",
        "m.fit_transform(x)\n",
        "\n",
        "m = MinMaxScaler().fit(x) # fit은 정규화 작업을 위한 최소값과 최대값을 만드는 작업\n",
        "m.transform(x)\n",
        "m.data_min_\n",
        "m.data_max_\n",
        "\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "minmax_scale(x)\n",
        "\n",
        "np.max(x)\n",
        "np.min(x)\n",
        "\n",
        "[문제200] bmi 데이터를 이용해서 키 : 178  몸무게 : 71 일 때 분류해주세요.\n",
        "단 표준화로 변환한 후 수행하세요\n",
        "# 표준화 수행 후 테스트 데이터 나누기\n",
        "bmi\n",
        "s = StandardScaler().fit(bmi.iloc[:,0:2])\n",
        "std = s.transform(bmi.iloc[:,0:2])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(std,bmi.label,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "sum(clf.predict(x_test) == y_test) / len(y_test)\n",
        "\n",
        "clf.predict([[178,71]])[0]\n",
        "\n",
        "#강사님\n",
        "bmi = pd.read_csv('c:/data/bmi.csv')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standscaler = StandardScaler()\n",
        "standscaler.mean_\n",
        "standscaler.var_\n",
        "standscaler.scale_\n",
        "data = standscaler.fit_transform(bmi.iloc[:,0:2])\n",
        "data\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,bmi.label,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_predict = clf.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "clf.score(x_test,y_test)\n",
        "\n",
        "clf.predict(standscaler.transform([[178,71]]))[0]\n",
        "\n",
        "[문제201] bmi 데이터를 이용해서 키 : 178  몸무게 : 71 일 때 분류해주세요.\n",
        "단 정규화로 변환한 후 수행하세요.\n",
        "m = MinMaxScaler().fit(bmi.iloc[:,0:2])\n",
        "norm = m.transform(bmi.iloc[:,0:2])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(norm,bmi.label,test_size=0.2)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=3)\n",
        "clf2.fit(x_train,y_train)\n",
        "sum(clf2.predict(x_test)== y_test) / len(y_test)\n",
        "\n",
        "#강사님\n",
        "bmi = pd.read_csv('c:/data/bmi.csv')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "minmaxscaler = MinMaxScaler()\n",
        "\n",
        "data = minmaxscaler.fit_transform(bmi.iloc[:,0:2])\n",
        "data\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,bmi.label,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_predict = clf.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "clf.score(x_test,y_test)\n",
        "\n",
        "clf.predict(minmaxscaler.transform([[178,71]]))[0]\n",
        "\n",
        "[문제202] 붓꽃데이터입니다.KNN으로 분류해주세요.\n",
        "iris = pd.read_csv('c:/data/iris.csv')\n",
        "iris.info()\n",
        " 0   SepalLength : 꽃받침의 길이\n",
        " 1   SepalWidth  : 꽃받침의 폭\n",
        " 2   PetalLength : 꽃잎의 길이\n",
        " 3   PetalWidth  : 꽃잎의 너비\n",
        " 4   Name        : 붓꽃 이름\n",
        "     SepalLength  SepalWidth  PetalLength  PetalWidth            Name\n",
        "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
        "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
        "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
        "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
        "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
        "..           ...         ...          ...         ...             ...\n",
        "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
        "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
        "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
        "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
        "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
        "\n",
        "iris.Name.unique()\n",
        "Counter(iris.Name)\n",
        "# map : key value로 값으로 수정하기 좋은 함수/ field값의 전체를 수정할 때 좋은 효율\n",
        "iris_name_labels = iris.Name.map({'Iris-setosa' : 0, 'Iris-versicolor' : 1, 'Iris-virginica' : 2}) # 수치화해야됨 -> 그래프에 표현을 위해서\n",
        "Counter(iris_name_labels)\n",
        "\n",
        "plt.scatter(iris.SepalLength,iris.SepalWidth,c=iris_name_labels) # c옵션에 string형식으로는 안 들어가기에 수치화로 라벨을 수정함\n",
        "x = plt.scatter(iris.PetalLength,iris.PetalWidth,c=iris_name_labels)\n",
        "x\n",
        "x.legend(labels=iris.Name.unique(),loc='lower right')\n",
        "\n",
        "\n",
        "시각화 연습해보기 (boxplot, 막대 등등 옵션들도 다 적용해보고 범례로 구분하기)\n",
        "iris.iloc[:,0]\n",
        "\n",
        "\n",
        "# 강사님 sepal\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(iris.iloc[:,0:2],iris.Name,test_size=0.2)\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.predict(x_test)\n",
        "clf.score(x_test,y_test)\n",
        "\n",
        "pd.crosstab(y_test,clf.predict(x_test))\n",
        "\n",
        "test = np.array([[1.0,0.1],[5.1,1.8]])\n",
        "test.shape\n",
        "clf.predict(test)\n",
        "\n",
        "# petal\n",
        "x_train,x_test,y_train,y_test = train_test_split(iris.iloc[:,2:4],iris.Name,test_size=0.2)\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.predict(x_test)\n",
        "clf.score(x_test,y_test)\n",
        "\n",
        "pd.crosstab(y_test,clf.predict(x_test))\n",
        "\n",
        "test = np.array([[1.0,0.1],[5.1,1.8]])\n",
        "test.shape\n",
        "clf.predict(test)\n",
        "\n",
        "setosa = iris[iris.Name=='Iris-setosa']\n",
        "versicolor = iris[iris.Name=='Iris-versicolor']\n",
        "virginica = iris[iris.Name=='Iris-virginica']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(10,10)\n",
        "ax.scatter(setosa['PetalLength'],setosa['PetalWidth'],label='Iris-setosa',marker='v',facecolor='blue')\n",
        "ax.scatter(versicolor['PetalLength'],versicolor['PetalWidth'],label='Iris-versicolor',marker='s',facecolor='red')\n",
        "ax.scatter(virginica['PetalLength'],virginica['PetalWidth'],label='Iris-virginica',marker='d',facecolor='gray')\n",
        "ax.legend()\n",
        "\n",
        "★ seaborn : 산점도를 더 쉽게 그릴 수 있는 라이브러리\n",
        "import seaborn as sns\n",
        "sns.scatterplot(data=iris,x='PetalLength',y='PetalWidth',hue='Name')\n",
        "\n",
        "sns.pairplot(iris)\n",
        "\n",
        "\n",
        "[문제203] 유방암 데이터 입니다. KNN 알고리즘을 이용해서 분류해주세요.\n",
        "wisc = pd.read_csv('c:/data/wisc_bc_data.csv')\n",
        "wisc.info()\n",
        "wisc.isnull().sum() # 데이터들 중 null이 있는지 확인해보기(현장에서 직접 확인)\n",
        "\n",
        "wisc.diagnosis.unique() \n",
        "B -> Benign(양성)\n",
        "M -> Malignant(악성)\n",
        "\n",
        "# kNN 알고리즘 수행 순서\n",
        "1. 값의 크기가 제각각이면 정규화 or 표준화 하기\n",
        "2. 정규화 or 표준화 수행한 데이터를  학습데이터와 테스트데이터로 분류\n",
        "3. KNeighborsClassifier(n_neighbors=k) -> knn알고리즘을 수행하기 위한 클래스를 인스턴스화\n",
        "4. fit함수로 모델링(학습데이터,학습데이터의 정답라벨)\n",
        "5. predict(테스트데이터로 예측 수행)\n",
        "6. 정확도 확인\n",
        "7. 시각화\n",
        "\n",
        "# 표준화 후 분류 _mean\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "standardscaler = StandardScaler()\n",
        "data = standardscaler.fit_transform(wisc.iloc[:,2:12])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,wisc.diagnosis,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=20)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.predict(x_test)\n",
        "clf.score(x_test,y_test)  # 정확도 : 0.929.....\n",
        "\n",
        "# 정규화 후 분류 _mean\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmaxscaler = MinMaxScaler()\n",
        "data = minmaxscaler.fit_transform(wisc.iloc[:,2:12])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,wisc.diagnosis,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=20)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.predict(x_test)\n",
        "clf.score(x_test,y_test) # 정확도 : 0.947.....\n",
        "\n",
        "# 전체 데이터( 모든 컬럼 ) 표준화 후 분류\n",
        "standardscaler = StandardScaler()\n",
        "data = standardscaler.fit_transform(wisc.iloc[:,2:])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,wisc.diagnosis,test_size=0.2) \n",
        "clf = KNeighborsClassifier(n_neighbors=20)\n",
        "clf.fit(x_train,y_train)\n",
        "sum(clf.predict(x_test) ==y_test) /  len(y_test)\n",
        "clf.score(x_test,y_test) # 정확도 : 0.964\n",
        "\n",
        "# 전체 데이터 정규화 후 분류\n",
        "minmaxscaler = MinMaxScaler()\n",
        "data = minmaxscaler.fit_transform(wisc.iloc[:,2:])\n",
        "data\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,wisc.diagnosis,test_size=0.2)\n",
        "clf = KNeighborsClassifier(n_neighbors=23)\n",
        "clf.fit(x_train,y_train)\n",
        "sum(clf.predict(x_test) ==y_test) / len(y_test)\n",
        "clf.score(x_test,y_test) # 정확도 : 0.982\n",
        "\n",
        "\n",
        "# 산점도\n",
        "import seaborn as sns\n",
        "sns.scatterplot(data=iris,x='PetalLength',y='PetalWidth',hue='Name')\n",
        "sns.pairplot(iris)\n",
        "\n",
        "sns.scatterplot(data=wisc,x='radius_mean',y='texture_mean',hue='diagnosis')\n",
        "sns.pairplot(wisc.iloc[:,1:13])\n",
        "\n",
        "data = wisc.iloc[:1:]\n",
        "\n",
        "cn = Counter(data['diagnosis'])\n",
        "cn['B'] /569*100\n",
        "cn['M'] /569*100\n",
        "\n",
        "np.sqrt(569) # k값에 어떤 값을 넣어야할지 잘 모르겠을 때 전체데이터에 루트 씌운 값 중 홀수값\n",
        "pd.crosstab(y_test,clf.predict(x_test))\n",
        "idx = x_test[y_test != clf.predict(x_test)].index # 오분류 데이터\n",
        "data.loc[idx]\n",
        "\n"
      ]
    }
  ]
}
